<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/09/27/CTR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/27/CTR/" class="post-title-link" itemprop="url">CTR</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-27 18:06:48" itemprop="dateCreated datePublished" datetime="2021-09-27T18:06:48+08:00">2021-09-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-26 15:17:05" itemprop="dateModified" datetime="2022-01-26T15:17:05+08:00">2022-01-26</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="MLPS"><a href="#MLPS" class="headerlink" title="MLPS"></a>MLPS</h4><p>MPLS（Multiprotocol Label Switch）是使用标签为了做出数据转发决策的数据包转发技术。利用 MPLS 技术，只需一次（当数据包进入 MPLS 域时）即可完成第 3 层报头分析。标签检查可推动后续的数据包转发。MPLS 可为以下应用带来益处：虚拟专用网络 (VPN)<br>流量工程 (TE)<br>服务质量 (QoS)<br>任何基于 MPLS 的传输 (AToM)<br>另外，它还可减少核心路由器上的转发开销。MPLS 技术适用于任何网络层协议。</p>
<h4 id="embedding"><a href="#embedding" class="headerlink" title="embedding"></a>embedding</h4><p>​        简单来说，embedding就是用一个低维的向量表示一个物体，可以是一个词，或是一个商品，或是一个电影等等。这个embedding向量的性质是能使距离相近的向量对应的物体有相近的含义，比如 Embedding(复仇者联盟)和Embedding(钢铁侠)之间的距离就会很接近，但 Embedding(复仇者联盟)和Embedding(乱世佳人)的距离就会远一些。　　<br>　　除此之外Embedding甚至还具有数学运算的关系，比如Embedding（马德里）-Embedding（西班牙）+Embedding(法国)≈Embedding(巴黎)<br>　　从另外一个空间表达物体，甚至揭示了物体间的潜在关系，上次体会这样神奇的操作还是在学习傅里叶变换的时候，从某种意义上来说，Embedding方法甚至具备了一些本体论的哲学意义。<br>　　言归正传，Embedding能够用低维向量对物体进行编码还能保留其含义的特点非常适合深度学习。在传统机器学习模型构建过程中，我们经常使用one hot encoding对离散特征，特别是id类特征进行编码，但由于one hot encoding的维度等于物体的总数，比如阿里的商品one hot encoding的维度就至少是千万量级的。这样的编码方式对于商品来说是极端稀疏的，甚至用multi hot encoding对用户浏览历史的编码也会是一个非常稀疏的向量。而深度学习的特点以及工程方面的原因使其不利于稀疏特征向量的处理（这里希望大家讨论一下为什么?）。因此如果能把物体编码为一个低维稠密向量再喂给DNN，自然是一个高效的基本操作。</p>
<h4 id="pooling"><a href="#pooling" class="headerlink" title="pooling"></a>pooling</h4><p>池化过程在一般卷积过程后。池化（pooling） 的本质，其实就是采样。Pooling 对于输入的 Feature Map，选择某种方式对其进行降维压缩，以加快运算速度。</p>
<h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>激活函数是用来加入非线性因素的，提高神经网络对模型的表达能力，解决线性模型所不能解决的问题。</p>
<h4 id="sigmoid和softmax"><a href="#sigmoid和softmax" class="headerlink" title="sigmoid和softmax"></a>sigmoid和softmax</h4><p>sigmoid：<img src="/2021/09/27/CTR/image-20210927183028016.png" alt="image-20210927183028016"></p>
<p>softmax:<img src="/2021/09/27/CTR/image-20210927183115523.png" alt="image-20210927183115523"></p>
<p>sigmoid将一个real value映射到（0,1）的区间（当然也可以是（-1,1）），这样可以用来做二分类。而softmax把一个k维的real value向量（a1,a2,a3,a4…）映射成一个（b1,b2,b3,b4…）其中bi是一个0-1的常数，然后可以根据bi的大小来进行多分类的任务，如取权重最大的一维。</p>
<h4 id="神经网络的Attention机制"><a href="#神经网络的Attention机制" class="headerlink" title="神经网络的Attention机制"></a>神经网络的Attention机制</h4><p>注意力机制也称为：“神经网络的注意力”，或者更简单的：“注意力”。</p>
<p>人脑在工作时，其实是由一定的注意力的，比如我们在浏览器上搜索时，大部分的注意力都集中在搜索结果的左上角，这说明大脑在处理信号的时候是有一定权重划分的，而注意力机制的提出正是模仿了大脑的这种特性。神经网络的注意力就是说，神经网络具有将注意力集中到一部分输入（或特征）的能力。</p>
<p>（1）为什么引入注意力机制呢？</p>
<p>计算能力的限制：目前计算能力依然是限制神经网络发展的瓶颈，当输入的信息过多时，模型也会变得更复杂，通过引入注意力，可以减少处理的信息量，从而减小需要的计算资源。<br>优化算法的限制：虽然局部连接、权重共享以及 pooling 等优化操作可以让神经网络变得简单一些，有效缓解模型复杂度和表达能力之间的矛盾；但是，如循环神经网络中的长序列输入，信息“记忆”能力并不高。<br>（2）注意力机制的分类</p>
<p>注意力机制一般分为两种：</p>
<p>聚焦式（Focus）注意力：是一种自上而下的有意识的注意力，“主动注意” 是指有预定目的、依赖任务的、主动有意识地聚焦于某一对象的注意力；<br>显著性（Saliency-Based）注意力：是一种自下而上的无意识的注意力，“被动注意” 是基于显著性的注意力，是由外界刺激驱动的注意，不需要主动干预，也和任务无关；池化（Max Pooling） 和 门控（Gating） 可以近似地看作是自下而上的基于显著性的注意力机制。</p>
<p>在神经网络结构中加入注意力模型主要是基于三点考虑：首先是这些模型在众多的任务中取得了非常好的性能，比方说机器翻译、问答系统、情感分析、词性标注选民分析和问答系统。然后，在提升模型性能的同时，注意力机制增加了神经网络结构的可解释性。由于传统的神经网络是一个黑盒模型，因此提高其可解释性对机器学习模型的公平性、可靠性和透明性的提高至关重要。第三，其能够帮助缓解递归神经网络中的一些缺陷，比方说随着输入序列长度的增加导致的性能下降和对输入的顺序处理所导致的计算效率低下。</p>
<h4 id="DIN模型"><a href="#DIN模型" class="headerlink" title="DIN模型"></a>DIN模型</h4><p>基准模型：基准模型就是比较常见的多层神经网络，即：（1）先对每个特征进行Embedding操作，得到一系列Embedding向量；（2）将不同Group的特征拼接组合起来之后得到一个固定长度的用户Embedding向量，和候选商品Embedding向量；（3）然后将（2）中的向量输入后续的全连接网络，最后输出pCTR值。具体网络结构见下图：</p>
<p><img src="/2021/09/27/CTR/image-20210927194204860.png" alt="image-20210927194204860"></p>
<p>base模型缺点：（1）用户的历史行为特征和当前的候选广告特征在全都拼起来给神经网络之前，是一点交互的过程都没有。</p>
<p>（2）拼起来之后给神经网络，虽然有了交互，但也丢失了部分信息，并引入了噪声。</p>
<p>DIN模型：DIN模型在基准模型的基础上，增加了注意力机制，就是模型在对候选商品预测的时候，对用户不同行为的注意力是不一样的。“相关”的行为历史看重一些，“不相关”的历史甚至可以忽略。下图展示了DIN模型的网络结构图。DIN的模型结构中增加了 Activation Unit模块，该模块主要提取当前候选商品与历史行为中的商品的权重值。<img src="/2021/09/27/CTR/image-20210927194403979.png" alt="image-20210927194403979"></p>
<h4 id="单层注意力模型与多层注意力模型"><a href="#单层注意力模型与多层注意力模型" class="headerlink" title="单层注意力模型与多层注意力模型"></a>单层注意力模型与多层注意力模型</h4><p>在最一般的情形下，注意力权重是仅仅是由注意力模型的原始的输入序列算出来的，这一注意力模型可被称为<strong><em>单层注意力模型</em></strong>。另一方面，我们可对输入序列进行多次抽象，这样可以使得底层抽象的上下文向量成为下一次抽象的查询状态。这种对输入数据叠加若干层注意力模块实现对序列数据多层抽象的方法可被称为<strong>多层注意力模型</strong>。更具体地来说，多层注意力模型又可按照模型的权重是自顶向下学习还是自底向上学习的方式进行划分。</p>
<p>多层注意力机制的一个典型应用是通过对文本进行两层抽象实现对文本的分类。这一模型称为“层次和注意力模型(Hierarchical Attention Model,HAM)”。文本是由不同的句子组合而成的，而每个句子又包含不同的单词，HAM能够对文章这种自然的层次化结构进行抽取。具体来说，其首先对每个句子建立一个注意力模型，该注意力模型的输入是每个句子中的基本单词，从而得到这个句子的特征表示；然后将句子的特征的表示输入到后续的注意力模型中来构建整段文本的特征表示。这一最后得到的整段文本的特征表示可以用于后面分类任务分类器的输入。</p>
<h4 id="特征表示的数量"><a href="#特征表示的数量" class="headerlink" title="特征表示的数量"></a>特征表示的数量</h4><p>在大多数的应用场景下，我们只会对输入数据进行一种特征表示。然而在有些场景下，对输入数据进行单一的特征表示可能不能够为后续的过程提供足够的信息。在这种情形下，我们可以对同样的输入数据进行多种特征表示。利用注意力机制可以为这些不同的特征表示指定相关的权重，从而丢弃掉输入数据中的噪声信息和重复冗余信息。我们称这种模型为<strong><em>多表示注意力模型\</em></strong>。这种多表示注意力模型能够决定不同特征表示的权重从而有助于后面对这一表示的应用。最后得到的输入的特征表示是多个特征表示的加权组合，这一模型的一个优势在于针对不同的后处理任务能够决定哪些特征表示更适合当前的任务场景。</p>
<p>基于类似的想法，还有一种称为<strong><em>多维度注意力模型\</em></strong>的方法。其核心观点是对特征表示向量的各个维度之间的依赖关系进行建模，这样我们便能够选择特征中更为有用的属性来帮助我们处理后续的任务。这一思想在自然语言处理领域至关重要因为相同的单词往往会出现多义性。</p>
<h4 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h4><p>本质是一个概率值，简单来说就是随机抽出一对样本（一个正样本一个负样本），然后用训练得到的分类器对这两个样本进行预测，预测得到正样本的概率大于负样本的概率的概率。</p>
<h4 id="GAUC"><a href="#GAUC" class="headerlink" title="GAUC"></a>GAUC</h4><p>优点：实现了用户级别的AUC计算</p>
<p>缺点：用户行为没有那么多的时候，GAUC会抖动，所以大部分公司还是会采用AUC</p>
<h4 id="multi-hot编码"><a href="#multi-hot编码" class="headerlink" title="multi-hot编码"></a><strong>multi-hot编码</strong></h4><p>在做用户画像或为用户做兴趣标签的时候，往往会遇到这样的问题，就是multi-hot特征的处理。 multi-hot编码之后每个id对应的是多个的1，而且不同样本中1的个数还不一样。 对multi-hot特征的处理无非也是一种稀疏矩阵的降维压缩，因此可以使用embedding的方法。对于某个属性对应的分类特征,可能该特征下有多个取值,比如一个特征表示对哪些物品感兴趣,那么这个特征不是单个值,而是有多个取值。 例如我们现在有3个样本： - 样本1 在该属性下取值有1,2两种特征 - 样本2 在该属性下有2一种特征 - 样本3 在该属性下有3,4 两种特征。我们以multi-hot编码的形式来定义特征应为 - 样本1 [1,1,0,0] - 样本2 [0,1,0,0] - 样本3 [0,0,1,1] 但是这种变量不能够直接用 embedding_lookup 去做, embedding_lookup 只接受只有一个1的onehot编码,那么为了完成这种情况的embedding需要两个步骤: </p>
<ol>
<li>将输入属性转化为类型one-hot编码的形式, 在tensorflow中这个过程是通过 tf.SparseTensor 来完成的,实际上就是构建了一个字典矩阵,key为坐标,value为1或者0表示是否有值,对于一个样本 如样本1来说就是构建了一个矩阵[[1,1,0,0]]表示有物品1和2,这个矩阵的规模为 [batch_size,num_items] ,这个过程即为 multi-hot 编码</li>
<li>将构建好的类似于one-hot编码的矩阵与embedding矩阵相乘, embedding矩阵的规模为 [num_items, embedding_size] ,相乘之后得到的输出规模为 [batchi_size, embedding_size] , 即对多维多属性的特征构建了embedding vector</li>
</ol>
<h2 id="CTR模型整理"><a href="#CTR模型整理" class="headerlink" title="CTR模型整理"></a>CTR模型整理</h2><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>参考部分所列出的为遵循原论文所整理，若原论文中有源码则均以附出，实现基本均为tf实现。</p>
<p>pytorch统一接口部分所给出的链接，是一个pytorch实现的ctr库。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/shenweichen/DeepCTR</span><br><span class="line">https://github.com/DSXiangLi/CTR</span><br><span class="line">https://github.com/shenweichen/DeepCTR-Torch</span><br><span class="line">https://github.com/qiaoguan/deep-ctr-prediction</span><br></pre></td></tr></table></figure>
<h3 id="Convolutional-Click-Prediction-Model-卷积点击预测模型CCPM"><a href="#Convolutional-Click-Prediction-Model-卷积点击预测模型CCPM" class="headerlink" title="Convolutional Click Prediction Model(卷积点击预测模型CCPM)"></a>Convolutional Click Prediction Model(卷积点击预测模型CCPM)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[CIKM 2015]A Convolutional Click Prediction Model</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://wnzhang.net/share/rtb-papers/cnn-ctr.pdf</span><br></pre></td></tr></table></figure>
<h4 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h4><p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Avazu：包括数天的广告点击数据，按时间顺序排列。在每一份点击数据中，有17个数据字段</span><br><span class="line">如广告ID，网站ID，点击等。</span><br><span class="line">Yoochoose：包含了一个在线零售商的许多浏览和购买事件的会议。其中每个会话封装了单个用户的点击事件。</span><br></pre></td></tr></table></figure>
<p>结果分析</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CCPM和其他竞争性方法在单一广告印象和连续广告印象上的点击预测性能相比较优。(FM,LR.RNN)</span><br></pre></td></tr></table></figure>
<p>超参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">the parameter impacts of the filter width w and the number of feature map m in corresponding layer are studied</span><br><span class="line">filter width 与feature map</span><br><span class="line">具体在论文第四页有提及，没有说明修正位置、默认值以及可设置范围。</span><br></pre></td></tr></table></figure>
<h3 id="Factorization-supported-Neural-Network-因子分解支持的神经网络FNN"><a href="#Factorization-supported-Neural-Network-因子分解支持的神经网络FNN" class="headerlink" title="Factorization-supported Neural Network(因子分解支持的神经网络FNN)"></a>Factorization-supported Neural Network(因子分解支持的神经网络FNN)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ECIR 2016]Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1601.02376.pdf</span><br></pre></td></tr></table></figure>
<p>带有演示数据的源代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/wnzhang/deep-ctr</span><br></pre></td></tr></table></figure>
<h4 id="算法细节-1"><a href="#算法细节-1" class="headerlink" title="算法细节"></a>算法细节</h4><p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iPinYou：iPinYou数据集是一个公开的真实世界的显示广告数据集，其中有每个广告显示信息和相应的</span><br><span class="line">用户点击反馈。</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.使用随机梯度下降法来学习所有模型的大部分参数。</span><br><span class="line">2.学习率，从1、0.1、0.01、0.001到0.0001</span><br><span class="line">3.尝试了每个领域的负样本数m=1、2和4，并发现m=2在大多数情况下产生最好的结果。</span><br><span class="line">4.对于激活函数(如公式(3)和(2))，我们尝试了线性函数、sigmoid函数和tanh函数，并发现tanh函数的结果是最优的。</span><br><span class="line">5.通过固定3、4和5个隐藏层来研究架构，具有3个隐藏层（即总共5层）的架构在AUC性能方面是最好的。</span><br><span class="line">6.每个隐藏层的训练范围是隐含单元的范围从100到500，增量为100。</span><br></pre></td></tr></table></figure>
<h3 id="Product-based-Neural-Network-PNN"><a href="#Product-based-Neural-Network-PNN" class="headerlink" title="Product-based Neural Network(PNN)"></a>Product-based Neural Network(PNN)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ICDM 2016]Product-based neural networks for user response prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1611.00144.pdf</span><br></pre></td></tr></table></figure>
<p>可重复的实验代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/Atomu2014/product-nets </span><br><span class="line">tensorflow</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Criteo：一个著名的广告技术行业的基准数据集。</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.在这个数据集上应用了负向下采样。定义下采样率为w，预测的CTR为p，重新校准的CTR q</span><br><span class="line">2.在实验中比较了7个模型，它们是用TensorFlow4实现(LR,FM,FNN,CCPM,IPNN,OPNN,PNN),用随机梯度下降法（SGD）进行训练。采用了dropout作为正则化方法来防止训练神经网络时的过度拟合。</span><br><span class="line">3.we set dropout rate at 0.5 on networkhidden layers.将网络隐层的滤除率设置为0.5。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h4><p> Follow the instructions and update the soft link <code>data</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XXX/product-nets$ ln -sfn XXX/make-ipinyou-data/2997 data</span><br></pre></td></tr></table></figure>
<p>run <code>main.py</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd python</span><br><span class="line">python main.py</span><br></pre></td></tr></table></figure>
<h3 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide &amp; Deep"></a>Wide &amp; Deep</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[DLRS 2016]Wide &amp; Deep Learning for Recommender Systems</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1606.07792.pdf</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.模型训练时为每个分类特征学习一个 32 维嵌入向量</span><br></pre></td></tr></table></figure>
<h3 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[IJCAI 2017]DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.ijcai.org/proceedings/2017/0239.pdf</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Criteo：包括4500万用户的点击记录。</span><br><span class="line">Company</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.for FNN and PNN: (1)dropout: 0.5; (2) network structure: 400-400-400; (3) optimizer: Adam; (4) activation function: tanh for IPNN, relu forother deep models.</span><br><span class="line">2.研究了不同深度模型的不同超参数，对公司数据集的影响。顺序是：1）激活函数；2）辍学率；3）每层的神经元数量；4）隐藏层数量；5）网络形状。dropout设置为1.0、0.9、0.8、0.7。每层的神经元数量200，400，800。网络形状：constant, increasing,decreasing, and diamond. </span><br></pre></td></tr></table></figure>
<p>注：这篇文章对于超参数进行了大量实验</p>
<h3 id="Piece-wise-Linear-Model"><a href="#Piece-wise-Linear-Model" class="headerlink" title="Piece-wise Linear Model"></a>Piece-wise Linear Model</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[arxiv 2017]Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/abs/1704.05194</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.LS-PLM是一个分片线性模型，割数m控制模型的容量。尝试m=6、12、24、36。m=12的测试AUC明显好于m=6，而m=24，36的改善相对较小。</span><br><span class="line">温和。因此，在下面的所有实验中，LS-PLM模型的参数m被设定为12。</span><br></pre></td></tr></table></figure>
<h3 id="Deep-amp-Cross-Network"><a href="#Deep-amp-Cross-Network" class="headerlink" title="Deep &amp; Cross Network"></a>Deep &amp; Cross Network</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ADKDD 2017]Deep &amp; Cross Network for Ad Click Predictions</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/abs/1708.05123</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Criteo Display Ads2</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.batch size is set at 512</span><br><span class="line">2.gradient clip norm was set at 100.</span><br><span class="line">3.隐层的数量从2到5不等。</span><br><span class="line">4.隐藏层大小从32到1024</span><br><span class="line">5.初始学习率从0.0001到0.001，增量为0.0001</span><br></pre></td></tr></table></figure>
<p>最佳超参数选择</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The optimal hyperparameter seings were 2 deep layers of size 1024 and 6 cross layers for</span><br><span class="line">the DCN model, 5 deep layers of size 1024 for the DNN, 5 residual units with input dimension 424 and cross dimension 537 forthe DC, and 42 cross features for the LR model</span><br></pre></td></tr></table></figure>
<p>注：本文对于超参数有详细的实验，具体请参考原文。所列不全。</p>
<h3 id="Attentional-Factorization-Machine-AFM"><a href="#Attentional-Factorization-Machine-AFM" class="headerlink" title="Attentional Factorization Machine(AFM)"></a>Attentional Factorization Machine(AFM)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[IJCAI 2017]Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.ijcai.org/proceedings/2017/0435.pdf</span><br></pre></td></tr></table></figure>
<p>一个对该论文的实现</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/hexiangnan/attentional_factorization_machine</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Frappe ：被用于情境感知推荐，它包含了96,203个不同情境下的用户应用日志。该数据集包含96,203个用户在不同情境下的使用日志。</span><br><span class="line">MovieLens：被用于个性化标签推荐</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.对于AFM，Frappe和MovieLens上的最佳滤波率是0.2和0.5</span><br></pre></td></tr></table></figure>
<h4 id="to-use"><a href="#to-use" class="headerlink" title="to use"></a>to use</h4><p>代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">AFM.py</span><br><span class="line">FM.py</span><br><span class="line">LoadData.py</span><br></pre></td></tr></table></figure>
<p>数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ml-tag</span><br><span class="line">ml-tag.train.libfm</span><br><span class="line">ml-tag.validation.libfm</span><br><span class="line">ml-tag.test.libfm</span><br></pre></td></tr></table></figure>
<p>训练</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># step into the code folder</span><br><span class="line">cd code</span><br><span class="line"># train FM model with optimal parameters</span><br><span class="line">python FM.py --dataset ml-tag --epoch 20 --pretrain -1 --batch_size 4096 --hidden_factor 16 --lr 0.01 --keep 0.7</span><br><span class="line"># train AFM model with optimal parameters</span><br><span class="line">python AFM.py --dataset ml-tag --epoch 20 --pretrain 1 --batch_size 4096 --hidden_factor [16,16] --keep [1.0,0.5] --lamda_attention 100.0 --lr 0.1</span><br></pre></td></tr></table></figure>
<p>注：该复现非原作者</p>
<p>参考文章</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://zhuanlan.zhihu.com/p/110375283</span><br></pre></td></tr></table></figure>
<h3 id="Neural-Factorization-Machine"><a href="#Neural-Factorization-Machine" class="headerlink" title="Neural Factorization Machine"></a>Neural Factorization Machine</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[SIGIR 2017]Neural Factorization Machines for Sparse Predictive Analytics</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1708.05027.pdf</span><br></pre></td></tr></table></figure>
<p>论文开源代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/hexiangnan/neural_factorization_machine</span><br></pre></td></tr></table></figure>
<p> 数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Frappe：包含96,203个应用程序在不同背景下的用户使用日志。</span><br><span class="line">MovieLens</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.学习率都在[0.005, 0.01, 0.02, 0.05]，在[0, 0.1, 0.2, ..., 0.9]的辍学率</span><br><span class="line">2.辍学率为NFM最重要的超参数，后设置为0.5</span><br><span class="line">3.ReLU作为激活函数</span><br></pre></td></tr></table></figure>
<p>to use</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python NeuralFM.py --dataset frappe --hidden_factor 64 --layers [64] --keep_prob [0.8,0.5] --loss_type square_loss --activation relu --pretrain 0 --optimizer AdagradOptimizer --lr 0.05 --batch_norm 1 --verbose 1 --early_stop 1 --epoch 200</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">We use the same input format as the LibFM toolkit (http://www.libfm.org/).</span><br><span class="line"></span><br><span class="line">Split the data to train/test/validation files to run the codes directly (examples see data/frappe/).</span><br></pre></td></tr></table></figure>
<h3 id="xDeepFM"><a href="#xDeepFM" class="headerlink" title="xDeepFM"></a>xDeepFM</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[KDD 2018]xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1803.05170.pdf</span><br></pre></td></tr></table></figure>
<p>源代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/Leavingseason/xDeepFM</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Criteo：一个著名的行业基准数据集用于开发预测广告点击率的模型，并且可以公开访问</span><br><span class="line">Dianping：中国最大的消费者评论网站。</span><br><span class="line">Bing News：微软的必应搜索引擎的一部分</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.学习率被设置为0.001</span><br><span class="line">2.每一层的神经元数量的默认设置是。(1) 400个用于DNN层；(2)Criteo数据集的CIN层为200，大众点评和必应的CIN层为100。</span><br><span class="line">3.对于超参数设置不同数据集有不同设置，详见论文第8页Q3</span><br></pre></td></tr></table></figure>
<h3 id="Deep-Interest-Network"><a href="#Deep-Interest-Network" class="headerlink" title="Deep Interest Network"></a>Deep Interest Network</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[KDD 2018]Deep Interest Network for Click-Through Rate Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1706.06978.pdf</span><br></pre></td></tr></table></figure>
<p>源代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/zhougr1993/DeepInterestNetwork</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Amazon</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.学习率从1开始，衰减率设置为0.1。</span><br><span class="line">2.小批量学习率从0.001开始，衰减率设置为0.001。</span><br></pre></td></tr></table></figure>
<p>注：DIN这篇论文中，代码质量较差，不建议使用该版本，在后期DIEN论文中会进行调整。</p>
<h3 id="Deep-Interest-Evolution-Network"><a href="#Deep-Interest-Evolution-Network" class="headerlink" title="Deep Interest Evolution Network"></a>Deep Interest Evolution Network</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[AAAI 2019]Deep Interest Evolution Network for Click-Through Rate Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1809.03672.pdf</span><br></pre></td></tr></table></figure>
<p>源代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/mouna99/dien</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public and industrial datasets</span><br></pre></td></tr></table></figure>
<h4 id="to-use-1"><a href="#to-use-1" class="headerlink" title="to use"></a>to use</h4><p>准备数据</p>
<p>法一</p>
<p>从亚马逊网站获取数据，并使用脚本进行处理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh prepare_data.sh</span><br></pre></td></tr></table></figure>
<p>法二，推荐</p>
<p>解压后直接使用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tar -jxvf data.tar.gz</span><br><span class="line">mv data/* .</span><br><span class="line">tar -jxvf data1.tar.gz</span><br><span class="line">mv data1/* .</span><br><span class="line">tar -jxvf data2.tar.gz</span><br><span class="line">mv data2/* .</span><br></pre></td></tr></table></figure>
<p>训练模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py train [model name] </span><br></pre></td></tr></table></figure>
<h3 id="AutoInt"><a href="#AutoInt" class="headerlink" title="AutoInt"></a>AutoInt</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[CIKM 2019]AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/abs/1810.11921</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Criteo：一个CTR预测的基准数据集，它有4500万用户的点击广告的记录。</span><br><span class="line">Avazu：包含用户的移动行为，包括一个显示的移动广告是否被用户点击。</span><br><span class="line">KDD12</span><br><span class="line">MovieLens-1M</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.在&#123;0.1 - 0.9&#125;范围内为MovieLens-1M数据集选择辍学率</span><br><span class="line">2.文章分析了Influence of Residual Structure，nfluence of Network Depths.Influence of Different Dimensions.</span><br></pre></td></tr></table></figure>
<h3 id="ONN"><a href="#ONN" class="headerlink" title="ONN"></a>ONN</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[arxiv 2019]Operation-aware Neural Networks for User Response Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1904.12579.pdf</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Criteo</span><br><span class="line">Tencent Ad</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.非线性隐藏层的数量对于Criteo数据集，隐藏的大小被设置为[400, 400, 400]，而非线性隐藏层的数量被设置为3。</span><br><span class="line">2.对于腾讯广告数据集，隐藏尺寸被设置为[200，200, 200]. </span><br><span class="line">3.Adam学习率是通过网格搜索从[0.0001,0.00025, 0.0005, 0.00075, 0.001]，</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="FiBiNET"><a href="#FiBiNET" class="headerlink" title="FiBiNET"></a>FiBiNET</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[RecSys 2019]FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1905.09433.pdf</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Criteo</span><br><span class="line">Avazu：由数天的广告点击数据组成。</span><br></pre></td></tr></table></figure>
<p>细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">对于嵌入层，Criteo数据集的嵌入层维度被设置为10，Avazu数据集的嵌入层维度被设置为50。</span><br><span class="line">Avazu数据集为50。对于优化方法，我们使用Adam。</span><br><span class="line">对于Criteo数据集和Avazu数据集，小型批次大小为1000，Avazu数据集为500。</span><br><span class="line">学习率被设置为0.0001。对于所有的深度模型，层的深度设置为3，所有的激活函数都是RELU，每层的神经元数量为400。</span><br><span class="line">每层的神经元数量在Criteo数据集为400个，在Avazu数据集为2000个。</span><br><span class="line">数据集的每层神经元数量为400个，Avazu数据集为2000个，辍学率设置为0.5。对于SENET部分，两个FC的激活函数为</span><br><span class="line">对于SENET部分，两个FC中的激活函数是RELU函数，还原率设置为3。 </span><br></pre></td></tr></table></figure>
<h3 id="IFM"><a href="#IFM" class="headerlink" title="IFM"></a>IFM</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[IJCAI 2019]An Input-aware Factorization Machine for Sparse Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.ijcai.org/Proceedings/2019/0203.pdf</span><br></pre></td></tr></table></figure>
<p>源代码链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/gulyfish/Input-aware-Factorization-Machine</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Frappe</span><br><span class="line">MovieLens</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.学习率：0.01</span><br><span class="line">2. the number of hidden layers，the dropout ratio， activation functions</span><br><span class="line">3.IFM的性能在开始时随着网络的增加而提高。然而，当网络的深度大于2(Frappe)或3(Movielens)时，模型的性能开始下降。</span><br><span class="line">4.Fraith的Frappe和MovieLens的最佳辍学率分别为0.3和0.4，</span><br><span class="line">5.ReLU更适合这两个数据集</span><br></pre></td></tr></table></figure>
<p>注：本文进行了详细的超参数实验</p>
<h3 id="DCN-V2"><a href="#DCN-V2" class="headerlink" title="DCN V2"></a>DCN V2</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[arxiv 2020]DCN V2: Improved Deep &amp; Cross Network and Practical Lessons for Web-scale Learning to Rank Systems</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/abs/2008.13535</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Criteo</span><br><span class="line">MovieLen-1M</span><br><span class="line">Production</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. learning rate was tuned from 10−4 to 10−1 ，再到10-4到5×10-4</span><br><span class="line">2.隐蔽层的数量在&#123;1，2，3，4&#125;之间，大小为&#123;562, 768, 1024&#125;。</span><br><span class="line">3.正则化参数𝜆的范围为&#123;0, 3 × 10−5, 10−4&#125;</span><br><span class="line">4.研究的超参数：depth of cross layers，matrix rank of DCN-Mix，number of experts in DCN-Mix</span><br></pre></td></tr></table></figure>
<h3 id="DIFM"><a href="#DIFM" class="headerlink" title="DIFM"></a>DIFM</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[IJCAI 2020]A Dual Input-aware Factorization Machine for CTR Prediction</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.ijcai.org/Proceedings/2020/0434.pdf</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Avazu</span><br><span class="line">Criteo</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.所有模型的学习都是通过使用Adam（学习率：0.001）</span><br><span class="line">2.Criteo和Avazu的嵌入大小分别被设定为20和40。</span><br><span class="line">3.批量大小对这两个数据集都设置为2000</span><br><span class="line">4.所研究的超参数：the number of attention heads n，the attention key size dk， activation functions (the vector-wise part)，the number of hidden layers in DNNs</span><br><span class="line">5.the number of attention heads n，进行了从1-16的实验，最后将数量固定在16</span><br><span class="line">6.the attention key size dk，在Avazu上将注意因子的大小从20增加到100时，Avazu数据集的模型性能稳步提高，而在Criteo数据集上，80是一个更合适的注意因子大小设置。为避免模型过于复杂，我们将Avazu的注意力系数固定为100，Criteo为80。</span><br><span class="line">7.Relu作为向量部分的神经元的激活函数</span><br><span class="line">8.对于Avazu最好的性能是我们只使用一个隐藏层，对于Criteo数据集采用两个</span><br></pre></td></tr></table></figure>
<h3 id="AFN"><a href="#AFN" class="headerlink" title="AFN"></a>AFN</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[AAAI 2020]Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions</span><br></pre></td></tr></table></figure>
<p>论文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/pdf/1909.03276.pdf</span><br></pre></td></tr></table></figure>
<p>源代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/WeiyuCheng/AFN-AAAI-20</span><br></pre></td></tr></table></figure>
<p>数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Criteo</span><br><span class="line">Avazu</span><br><span class="line">Movielens</span><br><span class="line">Frappe</span><br></pre></td></tr></table></figure>
<p>各种细节</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.超参数Number of logarithmic neurons，Depth of hidden layers，Number of neurons in hidden layers</span><br><span class="line">2.Number of neurons in hidden layers超过600性能开始下降touse</span><br></pre></td></tr></table></figure>
<p>to use</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">数据集</span><br><span class="line">cd src</span><br><span class="line">python download_criteo_and_avazu.py</span><br><span class="line">代码</span><br><span class="line">cd src</span><br><span class="line">sh ./run_experiments.sh</span><br></pre></td></tr></table></figure>
<h2 id="pytorch统一接口"><a href="#pytorch统一接口" class="headerlink" title="pytorch统一接口"></a>pytorch统一接口</h2><p>链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/shenweichen/DeepCTR-Torch</span><br></pre></td></tr></table></figure>
<p><img src="/2021/09/27/CTR/image-20220118172936135.png" alt="image-20220118172936135"></p>
<h3 id="统一视角"><a href="#统一视角" class="headerlink" title="统一视角"></a>统一视角</h3><p>DeepCTR通过对现有的基于深度学习的点击率预测模型的结构进行抽象总结，在设计过程中采用模块化的思路，各个模块自身具有高复用性，各个模块之间互相独立。 基于深度学习的点击率预测模型按模型内部组件的功能可以划分成以下4个模块：输入模块，嵌入模块，特征提取模块，预测输出模块。</p>
<p><img src="/2021/09/27/CTR/image-20220118173022237.png" alt="image-20220118173022237"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/09/25/%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/25/%E7%88%AC%E8%99%AB/" class="post-title-link" itemprop="url">爬虫</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-25 19:49:32" itemprop="dateCreated datePublished" datetime="2021-09-25T19:49:32+08:00">2021-09-25</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/31/%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/31/%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">初等模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-07-31 09:33:39 / Modified: 10:43:57" itemprop="dateCreated datePublished" datetime="2021-07-31T09:33:39+08:00">2021-07-31</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="初等模型"><a href="#初等模型" class="headerlink" title="初等模型"></a>初等模型</h1><h3 id="双层玻璃的功效"><a href="#双层玻璃的功效" class="headerlink" title="双层玻璃的功效"></a>双层玻璃的功效</h3><p>北方城镇的有些建筑物窗户是双层的，窗户上装两层玻璃且中间留有一定的空隙，两层厚度为d的玻璃夹着一层厚度为l的空气。我们要建立一个模型来描述热量通过窗户的传导过程，并将双层玻璃制成同样多材料的单层玻璃，进行，热量传导对比，对双层玻璃能够减少多少热量损失给出定量分析结果。</p>
<h4 id="模型假设"><a href="#模型假设" class="headerlink" title="模型假设"></a>模型假设</h4><p>（1）热量的传播过程只有传导，没有对流。即假定窗户的密封性能很好，两层玻璃之间的空气是不流动的。</p>
<p>（2）室内温度T1和室外温度T2保持不变，热传导过程已处于稳定状态，即沿热传导方向，单位时间内通过单位面积的热量是常数。</p>
<p>（3）玻璃材料均匀，热传导系数是常数。</p>
<h4 id="模型构成"><a href="#模型构成" class="headerlink" title="模型构成"></a>模型构成</h4><p>在上述假设下热传导过程遵从以下物理定律：</p>
<p>厚度为d的均匀介质，两侧温度差为<img src="/2021/07/31/%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B/wpsFA62.tmp.wmf" alt="img">，则单位时间内由温度高的一侧向温度低的一侧通过单位面积的热量Q与<img src="/2021/07/31/%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B/wpsFA62.tmp-1627698544223.wmf" alt="img">成正比，与d成反比，即<img src="/2021/07/31/%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B/wpsB5F9.tmp.wmf" alt="img"></p>
<p>k为热传导系数。</p>
<p>其余步骤省略。</p>
<h4 id="模型应用"><a href="#模型应用" class="headerlink" title="模型应用"></a>模型应用</h4><p>这个模型具有一定应用价值。制作双层玻璃窗虽然工艺复杂会增加一些费用，但它减少的热量损失确实相当可观的。通常，建筑规范要求g=l/d≈4.按照这个模型，Q1/Q2≈3%，即双层窗比用同样多的玻璃材质制成的单层窗节约热量97%左右。不难发现，之所以有如此高的功效主要是由于层间空气的极低的热传导系数k2,而这要求空气是干燥，不流通的。作为模型假设这个条件在实际情况下当然不能完全满足，所以实际上双层窗户的功效会比上述结果差一些。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/29/Latex/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/29/Latex/" class="post-title-link" itemprop="url">Latex</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-07-29 08:16:31 / Modified: 09:52:16" itemprop="dateCreated datePublished" datetime="2021-07-29T08:16:31+08:00">2021-07-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Latex入门教程"><a href="#Latex入门教程" class="headerlink" title="Latex入门教程"></a>Latex入门教程</h2><p>在编辑框中输入一下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">% 这里是导言区</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">Hello, world!</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>
<p>则会有如下显示</p>
<p><img src="/2021/07/29/Latex/image-20210729082909909.png" alt="image-20210729082909909"></p>
<p>同时会自动生成PDF文件在<code>.tex</code>文件所保存的目录下。</p>
<p>此处的第一行<code>\documentclass&#123;article&#125;</code>中包含了一个<strong>控制序列</strong>（或称命令 / 标记）。所谓<strong>控制序列</strong>，是以反斜杠<code>\</code>开头，以第一个<em>空格或非字母</em> 的字符结束的一串文字，他们并不被输出，但是他们会影响输出文档的效果。这里的控制序列是<code>documentclass</code>，它后面紧跟着的<code>&#123;article&#125;</code>代表这个控制序列有一个必要的参数，该参数的值为<code>article</code>. 这个控制序列的作用，是调用名为 “article” 的<strong>文档类</strong>。</p>
<p>其后出现了控制序列<code>begin</code>，这个控制序列总是与<code>end</code>成对出现。这两个控制序列以及他们中间的内容被称为<strong>“环境”</strong>；他们之后的第一个必要参数总是一致的，被称为环境名。</p>
<p>只有在 “document” 环境中的内容，才会被正常输出到文档中去或是作为控制序列对文档产生影响。因此，在<code>\end&#123;document&#125;</code>之后插入任何内容都是无效的。</p>
<p><code>\begin&#123;document&#125;</code>与<code>\documentclass&#123;article&#125;</code>之间的部分被称为<strong>导言区</strong>。导言区中的控制序列，通常会影响到整个输出文档。</p>
<h3 id="中英混排"><a href="#中英混排" class="headerlink" title="中英混排"></a>中英混排</h3><p>在编辑框中输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">\documentclass[UTF8]&#123;ctexart&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">你好，world!</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>
<p>会产生以下结果</p>
<p><img src="/2021/07/29/Latex/image-20210729083704740.png" alt="image-20210729083704740"></p>
<p>相较于之前的例子，代码有了细微的差别：</p>
<p>1.文档类从 <code>article</code> 变为 <code>ctexart</code></p>
<p>2.增加了文档类选项 <code>UTF8</code></p>
<h3 id="组织文章"><a href="#组织文章" class="headerlink" title="组织文章"></a>组织文章</h3><p><code>article</code>/<code>ctexart</code> 中，定义了五个控制序列来调整行文组织结构。他们分别是：</p>
<p>\section{.}</p>
<p>\subsection{.}</p>
<p>\subsubsection{.}</p>
<p>\paragraph{.}</p>
<p>\subparagraph{.}</p>
<p>在编辑框输入以下文本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">\documentclass[UTF8]&#123;ctexart&#125;</span><br><span class="line">\title&#123;你好，world!&#125;</span><br><span class="line">\author&#123;李凯杰&#125;</span><br><span class="line">\date&#123;\today&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">	\maketitle</span><br><span class="line">	\section&#123;你好中国&#125;</span><br><span class="line">	中国在 East Asia.</span><br><span class="line">	\subsection&#123;Hello Beijing&#125;</span><br><span class="line">	北京是 capital of China.</span><br><span class="line">	\subsubsection&#123;Hello Dongcheng District&#125;</span><br><span class="line">	\paragraph&#123;Tian&#x27;anmen Square&#125;</span><br><span class="line">	is in the center of Beijing</span><br><span class="line">	\subparagraph&#123;Chairman Mao&#125;</span><br><span class="line">	is in the center of 天安门广场。</span><br><span class="line">	\subsection&#123;Hello 北京&#125;</span><br><span class="line">	\paragraph&#123;北京&#125; is an international city。</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>
<p>会产生以下结果：</p>
<p><img src="/2021/07/29/Latex/image-20210729084810750.png" alt="image-20210729084810750"></p>
<h3 id="文献引用"><a href="#文献引用" class="headerlink" title="文献引用"></a>文献引用</h3><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>为了使用 AMS-LaTeX 提供的数学功能，我们需要在导言区加载<code>amsmath</code>宏包：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\usepackage&#123;amsmath&#125;</span><br></pre></td></tr></table></figure>
<p>数学模式</p>
<p>LaTeX 的数学模式有两种：行内模式 (inline) 和行间模式 (display)。前者在正文的行文中，插入数学公式；后者独立排列单独成行。</p>
<p>在行文中，使用<script type="math/tex">...</script>可以插入行内公式，使用<code>\[ ... \]</code>可以插入行间公式，如果需要对行间公式进行编号，可以使用<code>equation</code>环境： \begin{equaion} … \end{equation}</p>
<p>Latex在线工具编辑器：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.codecogs.com/latex/eqneditor.php</span><br></pre></td></tr></table></figure>
<h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p>Latex在线表格编辑器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.tablesgenerator.com/</span><br></pre></td></tr></table></figure>
<h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>在 LaTeX 中插入图片，有很多种方式。最好用的应当属利用<code>graphicx</code>宏包提供的<code>\includegraphics</code>命令。比如你在你的 TeX 源文件同目录下，有名为 a.jpg 的图片，你可以用这样的方式将它插入到输出文档中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;graphicx&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\includegraphics&#123;a.jpg&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>
<p>图片可能很大，超过了输出文件的纸张大小，或者干脆就是你自己觉得输出的效果不爽。这时候你可以用</p>
<p><code>\includegraphics</code>控制序列的可选参数来控制。比如</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\includegraphics[width = .8\textwidth]&#123;a.jpg&#125;</span><br></pre></td></tr></table></figure>
<p>这样图片的宽度会被缩放至页面宽度的百分之八十，图片的总高度会按比例缩放。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/26/%E6%B8%B8%E6%88%8F%E5%A4%96%E6%98%9F%E4%BA%BA%E5%85%A5%E4%BE%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/26/%E6%B8%B8%E6%88%8F%E5%A4%96%E6%98%9F%E4%BA%BA%E5%85%A5%E4%BE%B5/" class="post-title-link" itemprop="url">游戏外星人入侵</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-07-26 15:10:45 / Modified: 16:50:07" itemprop="dateCreated datePublished" datetime="2021-07-26T15:10:45+08:00">2021-07-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/26/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/" class="post-title-link" itemprop="url">数据可视化</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-07-26 15:08:11 / Modified: 15:10:26" itemprop="dateCreated datePublished" datetime="2021-07-26T15:08:11+08:00">2021-07-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/12/Python%E5%A4%87%E5%BF%98%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/12/Python%E5%A4%87%E5%BF%98%E5%BD%95/" class="post-title-link" itemprop="url">Python备忘录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-12 15:32:04" itemprop="dateCreated datePublished" datetime="2021-07-12T15:32:04+08:00">2021-07-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-07-19 16:43:19" itemprop="dateModified" datetime="2021-07-19T16:43:19+08:00">2021-07-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Python编程备忘录"><a href="#Python编程备忘录" class="headerlink" title="Python编程备忘录"></a>Python编程备忘录</h2><h3 id="变量和简单数据类型"><a href="#变量和简单数据类型" class="headerlink" title="变量和简单数据类型"></a>变量和简单数据类型</h3><h4 id="变量的命名和使用"><a href="#变量的命名和使用" class="headerlink" title="变量的命名和使用"></a>变量的命名和使用</h4><p>（1）变量名只能包含字母，数字和下划线。</p>
<p>（2）变量名不能包含空格，但能使用下划线来分割其中字符。</p>
<p>（3）关键字和函数名不能忘用作变量。</p>
<p>（4）变量名应简单又具有描述性。</p>
<h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><p>python中单引号和双引号引起来的都是字符串。</p>
<p>name.title()以首字母大写显示。</p>
<p>name.upper()全部大写。</p>
<p>name.lower()全部小写。</p>
<p>用f(format)来合并字符串。name=f“{firstname} {lastname}”</p>
<p>name.strip()来消除空白。该删除为暂时，要永久需关联到变量。</p>
<p>name.rstrip()消除右边空白。</p>
<p>name.lstrip()消除左边空白。</p>
<p>name1=name.rstrip()。</p>
<h4 id="整数"><a href="#整数" class="headerlink" title="整数"></a>整数</h4><p>用两个乘号表示乘方运算。3**2=9</p>
<p>将任意两个数相除时，结果总是浮点数，即便这两个数都是整数且能整数。</p>
<p>在其他任意运算中，只要有操作数是浮点数，默认得到的总是浮点数。</p>
<p>给多个变量赋值：x,y,z=0,0,0</p>
<p>用全大写将某个变量视为常量。</p>
<h3 id="列表简介"><a href="#列表简介" class="headerlink" title="列表简介"></a>列表简介</h3><p>python中，用[]表示列表，用逗号分隔其中元素。</p>
<p>在python中，索引为负数表示访问倒数第几个元素。</p>
<p>name.append(‘xyz’)在列表末尾添加元素。</p>
<p>name.insert(0,’xyz’)在索引0处插入元素。</p>
<p>用del name[0]永久删除索引0处的元素。</p>
<p>用pop暂时删除末尾元素，加入数字可删除任意位置。name.pop() name.pop(1)</p>
<p>用remove永久删除特定元素。name.remove(‘xyz’)。但是remove只删除第一个指定的值，若多次出现需循环删除。</p>
<h4 id="组织列表"><a href="#组织列表" class="headerlink" title="组织列表"></a>组织列表</h4><p>用cars.sort()对列表进行永久排序。</p>
<p>若要按相反的顺序排序，则向方法传递参数reverse=True,cars.sort(reverse.True)</p>
<p>用cars.sorted()对列表进行临时排序。</p>
<p>用cars.reverse()倒着打印列表，且会永久性的修改列表的顺序。</p>
<p>用len(cars)可确定列表的长度。</p>
<h3 id="操作列表"><a href="#操作列表" class="headerlink" title="操作列表"></a>操作列表</h3><p>range（1,4）只会打印1 2 3</p>
<p>若range只输入一个参数，则将从0开始。</p>
<p>可给range指定第三个参数，设定为步长。</p>
<h4 id="列表解析"><a href="#列表解析" class="headerlink" title="列表解析"></a>列表解析</h4><p>将for循环和创建新元素的代码合并成一行，并自动附加新元素。</p>
<p>squares=[value**2 for value in range(1,11)]</p>
<h4 id="使用列表的一部分"><a href="#使用列表的一部分" class="headerlink" title="使用列表的一部分"></a>使用列表的一部分</h4><h5 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h5><p>与range函数一样，指定索引，cars[0:3]，将返回索引0,1,2的元素</p>
<p>若不指定，cars[:3]，将从头开始索引，而cars[3:]将从第四个元素索引到末尾</p>
<p>若访问后三位元素，可cars[-3:]</p>
<p>也可加入第三个值，告诉Python间隔多少提取一个元素</p>
<h5 id="复制列表"><a href="#复制列表" class="headerlink" title="复制列表"></a>复制列表</h5><p>省略起始索引与终止索引，cars1=cars[:]</p>
<p>若只是单纯赋值，cars1=cars，则将两个指向同一个列表</p>
<h4 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h4><p>python将不可变的列表称为元组</p>
<p>元组使用圆括号而非中括号进行标识</p>
<p>如果你要定义的元组只包含一个元素，必须加上逗号，my_t=(3,)</p>
<p>虽然不能修改元组的元素，但可以给存储元组的变量赋值</p>
<p>dimensions=(200,50)</p>
<p>dimensions=(400,100)</p>
<p>这是合法的，相当于将一个新元组关联到变量dimension</p>
<h3 id="if语句"><a href="#if语句" class="headerlink" title="if语句"></a>if语句</h3><h4 id="条件测试"><a href="#条件测试" class="headerlink" title="条件测试"></a>条件测试</h4><p>python在检查是否相等时区分大小写</p>
<p>检查多个条件用 and 和 or</p>
<p>要判断特定值是否已包含在列表中，可使用关键字in</p>
<p>检查不包含，可用 not in</p>
<h3 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h3><p>在python中，字典是一系列键值对。每个键都与一个值相关联，你可以使用键来访问相关联的值。</p>
<p>字典用在花括号中的一系列键值对表示。</p>
<p>键值对是两个相关联的值，指定键时，Python将返回与之相关联的值。键和值之间用冒号分割，而键值对之间用逗号分割。</p>
<p>要获取与键相关联的值，可依次指定字典名和放在方括号内的值。</p>
<p>对于字典中不需要的信息，可用del语句将相应的键值对彻底删除。使用del语句时，必须要指定字典名和要删除的键。</p>
<p>可使用get来访问值，可避免指定键不存在的情况。</p>
<p>eg:point_value -alien.get(‘points’,’sorry’)</p>
<h5 id="遍历字典"><a href="#遍历字典" class="headerlink" title="遍历字典"></a>遍历字典</h5><p>for k,v in users.items()//遍历键值对</p>
<p>for k in users.keys()//遍历键</p>
<p>for v in users.values()//遍历值    </p>
<h3 id="用户输入和while循环"><a href="#用户输入和while循环" class="headerlink" title="用户输入和while循环"></a>用户输入和while循环</h3><p>要返回循环开头，并根据条件测试结果决定是否继续执行循环，可使用continue。</p>
<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>使用def定义函数</p>
<p>def user():</p>
<h5 id="关键字实参"><a href="#关键字实参" class="headerlink" title="关键字实参"></a>关键字实参</h5><p>def pet(type,name)</p>
<p>不使用pet(hamster,harry)</p>
<p>使用关键字实参pet(type=’hamster’,name=’harry’)//无视顺序</p>
<h5 id="默认值"><a href="#默认值" class="headerlink" title="默认值"></a>默认值</h5><p>编写函数时，可给每个形参指定默认值，在调用时，若未指定实参，则使用默认形参。</p>
<p>def pet(type=’dog’,name)</p>
<h5 id="传递任意数量的实参"><a href="#传递任意数量的实参" class="headerlink" title="传递任意数量的实参"></a>传递任意数量的实参</h5><p>def make(*pizza)://即可接受任意数量的实参</p>
<h5 id="使用任意数量的关键字实参"><a href="#使用任意数量的关键字实参" class="headerlink" title="使用任意数量的关键字实参"></a>使用任意数量的关键字实参</h5><p>def make(**pizza)://接受任意数量键值对</p>
<h4 id="将函数存储在模块中"><a href="#将函数存储在模块中" class="headerlink" title="将函数存储在模块中"></a>将函数存储在模块中</h4><p>导入整个模块 import pizza</p>
<p>导入模块中特定函数 from pizza import makepizza1,makepizza2</p>
<p>可使用as给模块或者函数指定别名</p>
<p>from pizza import make as m</p>
<p>使用<em>号可导入模块中所有函数 from pizza import </em></p>
<h3 id="类"><a href="#类" class="headerlink" title="类"></a>类</h3><p>类中的 __init()方法会自动运行，并且开头和结尾各有两个下划线。</p>
<h4 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h4><p>class elecar(car):</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/30/%E9%9B%86%E5%90%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/30/%E9%9B%86%E5%90%88/" class="post-title-link" itemprop="url">集合</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-06-30 10:18:34 / Modified: 13:41:05" itemprop="dateCreated datePublished" datetime="2021-06-30T10:18:34+08:00">2021-06-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="java集合框架"><a href="#java集合框架" class="headerlink" title="java集合框架"></a>java集合框架</h3><h4 id="集合接口与实现分离"><a href="#集合接口与实现分离" class="headerlink" title="集合接口与实现分离"></a>集合接口与实现分离</h4><p>与现代的数据结构类库的常见做法一样，java集合类库也将接口与实现分离。下面用我们熟悉的数据结构——队列来说明是如何分离的。</p>
<p>队列接口指出可以在队列的尾部添加元素，在队列的头部删除元素，并且可以查找队列中元素的个数。当需要收集对象，并按照“先进先出”方式检索对象时就应该使用队列。</p>
<p><img src="/2021/06/30/%E9%9B%86%E5%90%88/image-20210630104036075.png" alt="image-20210630104036075"></p>
<p>队列接口的最简形式可能类似下面这样：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public interface Queue&lt;E&gt;</span><br><span class="line">&#123;</span><br><span class="line">    void add(E element);</span><br><span class="line">    E remove();</span><br><span class="line">    int size();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个接口并没有说明队列是如何实现的。队列通常有两种实现方式：一种是使用循环数组；另一种是使用链表。</p>
<p><img src="/2021/06/30/%E9%9B%86%E5%90%88/image-20210630104055147.png" alt="image-20210630104055147"></p>
<p>每一个实现都可以用一个实现了Queue接口的类表示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">public class CircularArrayQueue&lt;E&gt; implements Queue&lt;E&gt;</span><br><span class="line">&#123;</span><br><span class="line">   private int head;</span><br><span class="line">   private int tail;</span><br><span class="line">   CircularArrayQueue(int capacity)&#123;...&#125;</span><br><span class="line">   public void add(E element)&#123;...&#125;</span><br><span class="line">   public E remove()&#123;...&#125;</span><br><span class="line">   public int size()&#123;...&#125;</span><br><span class="line">   private E[] elements;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public class LinkedListQueue&lt;E&gt; implements Queue&lt;E&gt;</span><br><span class="line">&#123;</span><br><span class="line">   private Link head;</span><br><span class="line">   private Link tail;</span><br><span class="line">   </span><br><span class="line">   LinkedListQueue()&#123;...&#125;</span><br><span class="line">   public void add(E element)&#123;...&#125;</span><br><span class="line">   public E remove()&#123;...&#125;</span><br><span class="line">   public int size()&#123;...&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当在程序中使用队列时，一旦已经构造了集合，就不需要知道究竟使用了哪种实现。因此，只有在构造集合对象时，才会使用具体的类。可以使用接口类型存放集合引用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Queue&lt;Customer&gt; expresslane = new CircularArrayQueue&lt;&gt;(100);</span><br><span class="line">expressLane.add(new Customer(&quot;Harry&quot;));</span><br></pre></td></tr></table></figure>
<p>利用这种方法，一旦改变了想法，就可以很轻松地使用另外一种不同的实现。只需要对程序的一个地方1做出修改，即调用构造器的地方。如果觉得LinkedListQueue是个更好的选择，就将代码修改为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Queue1&lt;Customer&gt; expressLane =new LinkedListQueue&lt;&gt;();</span><br><span class="line">expressLane.add(new Customer(&quot;Harry&quot;));</span><br></pre></td></tr></table></figure>
<p>为什么选择这种实现，而不选择那种实现呢？接口本身并不能说明哪种实现的效率究竟如何。循环数组要比链表更高效，因此多数人优先选择循环数组。不过，通常来讲，这样做也需要付出一定代价。</p>
<p>循环数组是一个有界集合，即容量有限。如果程序中要收集的对象数量没有上限，就最好使用链表来实现。</p>
<h4 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h4><p>Iterator接口包含4个方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public interface Iterator&lt;E&gt;</span><br><span class="line">&#123;</span><br><span class="line">   E next();</span><br><span class="line">   boolean hasNext();</span><br><span class="line">   void remove();</span><br><span class="line">   default void forEachRemaining(Consumer&lt;?super E&gt; action);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过反复调用next方法，可以逐个访问集合中的每个元素。但是，如果到达了集合的末尾，next方法将抛出一个NoSuchElementException。因此，需要在调用next之前调用hasNext方法。如果迭代器对象还有多个可以访问的元素，这个方法就返回true。如果想要查看集合中的所有元素，就请求一个迭代器，党hasNext返回true时就反复地调用next方法。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Collection&lt;String&gt; c=...;</span><br><span class="line">Iterator&lt;String&gt; iter=c.iterator();</span><br><span class="line">while(iter.hasNext())</span><br><span class="line">&#123;</span><br><span class="line">  String element-iter.next();</span><br><span class="line">  do something with element</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>用”for each”循坏可以更加简练地表示同样的循环操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for(String element : c)</span><br><span class="line">&#123;</span><br><span class="line">   do something with element</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译器简单地将”for each”循环转换为带有迭代器的循坏。</p>
<p>“for each”循环可以处理任何实现了Iterable接口的对象，这个接口只包含一个抽象方法:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public interface Iterable&lt;E&gt;</span><br><span class="line">&#123;</span><br><span class="line">   Iterator&lt;E&gt; iterator();</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>访问元素的顺序取决于集合类型。如果迭代处理一个ArrayList，迭代器将从索引0开始，每迭代一次，索引值加1.不过，如果访问HashSet中的元素，会按照一种基本上随机的顺序获得元素。虽然可以确保在迭代过程中能够遍历到集合中的所有元素，但是无法预知访问各元素的顺序。这通常并不是什么问题，因为对于计算总和或统计匹配之类的计算，顺序并不重要。</p>
<p>Java集合类库中的迭代器与其他类库中的迭代器在概念上有着重要的区别。在传统的集合类库中，例如，C++的标准模版库，迭代器是根据数组索引建模的。如果给定这样一个迭代器，就可以查看指定位置上的元素，就像知道数组索引i就可以查看数组元素a[i]一样。不需要查找元素，就可以将迭代器向前移动一个位置。这与不需要执行查找操作就可以通过i++将数组索引向前移动一样。但是，Java迭代器并不是这样操作的。查找操作与位置变更是紧密相连的。查找一个元素的唯一方法是调用next,而在执行查找操作的同时，迭代器的位置随之向前移动。<br>因此，应该将Java迭代器认为是位于两个元素之间。当调用next时，迭代器就越过下一个元素，并返回刚刚越过的那个元素的引用。</p>
<p><img src="/2021/06/30/%E9%9B%86%E5%90%88/image-20210630113409750.png" alt="image-20210630113409750"></p>
<p>Iterator接口的remove方法将会删除上次调用next方法时返回的元素。在大多数情况下，这是有道理的，在决定删除某个元素之前应该先看一下这个元素。不过，如果想要删除指定位置上的元素，仍然需要越过这个元素：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;String&gt; it =c.iterator();</span><br><span class="line">it.next;</span><br><span class="line">it.remove();</span><br></pre></td></tr></table></figure>
<p>更重要的是，next方法和remove方法调用之间存在依赖性。如果调用remove之前没有调用next，将是不合法的。如果这样做，将会抛出一个IllegalStateException异常。</p>
<p>如果想删掉两个相邻的元素，不能直接这样调用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">it.remove();</span><br><span class="line">it.remove();</span><br></pre></td></tr></table></figure>
<p>实际上，必须先调用next越过要删除的元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">it.remove();</span><br><span class="line">it.next();</span><br><span class="line">it.remove();</span><br></pre></td></tr></table></figure>
<h3 id="具体集合"><a href="#具体集合" class="headerlink" title="具体集合"></a>具体集合</h3><h4 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h4><p>链表是一个有序集合。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ListIterator&lt;E&gt; ListIterator()</span><br></pre></td></tr></table></figure>
<p>返回一个列表迭代器，用来访问列表中的元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ListIterator&lt;E&gt; listIterator(int index)</span><br></pre></td></tr></table></figure>
<p>返回一个列表迭代器，用来访问列表中的元素，第一次调用这个迭代器的next会返回给定索引的元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void add(int i,E element)</span><br></pre></td></tr></table></figure>
<p>在给定位置添加一个元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void addAll(int i,Collection&lt;?extends E&gt;elements)</span><br></pre></td></tr></table></figure>
<p>将一个集合中的所有元素添加到给定位置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E remove(int i)</span><br></pre></td></tr></table></figure>
<p>删除给定位置的元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E get(int i)</span><br></pre></td></tr></table></figure>
<p>获取给定位置的元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E set(int i,E element)</span><br></pre></td></tr></table></figure>
<p>用一个新元素替换给定位置的元素，并返回原来那个元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int indexOf(Object element)</span><br></pre></td></tr></table></figure>
<p>返回与指定元素相等的元素在列表中第一次出现的位置，如果没有这样的元素就返回-1.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int lastIndexOf(Object element)</span><br></pre></td></tr></table></figure>
<p>返回与指定元素相等的元素在列表中最后一次出现的位置，如果没有这样的元素将返回-1.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void add(E newElement)</span><br></pre></td></tr></table></figure>
<p>在当前位置添加一个元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void set(E newElement)</span><br></pre></td></tr></table></figure>
<p>用新元素替换next或previous访问的上一个元素。如果在上一个next或previous调用之后列表结构被修改了，将抛出一个IllegalStateException异常。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boolean hasPrevious()</span><br></pre></td></tr></table></figure>
<p>当反向迭代列表时，如果还有可以访问的元素，返回true。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E previous()</span><br></pre></td></tr></table></figure>
<p>返回前一个对象。如果已经到达了列表的头部，就抛出一个NoSuchElementException异常。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int nextIndex()</span><br></pre></td></tr></table></figure>
<p>返回下一次调用next方法时将返回的元素的索引。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int previousIndex()</span><br></pre></td></tr></table></figure>
<p>返回下一次调用previous方法时将返回的元素的索引。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LinkedList()</span><br></pre></td></tr></table></figure>
<p>构造一个空链表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LinkedList(Collection&lt;?extends E&gt;elements)</span><br></pre></td></tr></table></figure>
<p>构造一个链表，并将集合中所有的元素添加到这个链表中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">void addFirst(E element)</span><br><span class="line">void addLast(E element)</span><br></pre></td></tr></table></figure>
<p>将某个元素添加到列表的头部或尾部。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">E getFirst()</span><br><span class="line">E getLast()</span><br></pre></td></tr></table></figure>
<p>返回列表头部或尾部的元素。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">E removeFirst()</span><br><span class="line">E removeLast()</span><br></pre></td></tr></table></figure>
<p>删除并返回列表头部或尾部的元素。</p>
<h4 id="散列表"><a href="#散列表" class="headerlink" title="散列表"></a>散列表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HashSet()</span><br></pre></td></tr></table></figure>
<p>构造一个空散列集。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HashSet(Collection&lt;?extends E&gt;elements)</span><br></pre></td></tr></table></figure>
<p>构造一个散列集，并将集合中所有元素添加到这个散列集中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HashSet(int initialCapacity)</span><br></pre></td></tr></table></figure>
<p>构造一个空的具有指定容量的散列集。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HashSet(int initialCapacity,float loadFactor)</span><br></pre></td></tr></table></figure>
<p>构造一个有指定容量和装填因子的空散列集。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int hashCode()</span><br></pre></td></tr></table></figure>
<p>返回这个对象的散列码。</p>
<h4 id="树集"><a href="#树集" class="headerlink" title="树集"></a>树集</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TreeSet()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TreeSet(Comparator&lt;?super E&gt; compartor)</span><br></pre></td></tr></table></figure>
<p>构造一个空数集。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TreeSet(Collection&lt;?extends E&gt;elements)</span><br><span class="line">TreeSet(SortedSet&lt;E&gt; s)</span><br></pre></td></tr></table></figure>
<p>构造一个树集，并增加一个集合或有序集中的所有元素。</p>
<h4 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">V get(Object key)</span><br></pre></td></tr></table></figure>
<p>获取与键关联的值；返回与键关联的对象，或者映射中如果没有这个对象，就返回NULL。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">V put(K key,V value)</span><br></pre></td></tr></table></figure>
<p>将关联的一对键和值放到映射中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void putAll(Map&lt;?extends K,?extends V&gt;entries)</span><br></pre></td></tr></table></figure>
<p>将给定映射中的所有映射条目添加到这个映射中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boolean containsKey(Object key)</span><br></pre></td></tr></table></figure>
<p>如果在映射中已经有这个键，返回true。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boolean containsValue(Object value)</span><br></pre></td></tr></table></figure>
<p>如果映射中已经有这个值，返回true。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/29/%E6%B3%9B%E5%9E%8B%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/29/%E6%B3%9B%E5%9E%8B%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/" class="post-title-link" itemprop="url">泛型程序设计</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-06-29 21:03:24" itemprop="dateCreated datePublished" datetime="2021-06-29T21:03:24+08:00">2021-06-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-06-30 10:15:30" itemprop="dateModified" datetime="2021-06-30T10:15:30+08:00">2021-06-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="为什么要使用泛型程序设计"><a href="#为什么要使用泛型程序设计" class="headerlink" title="为什么要使用泛型程序设计"></a>为什么要使用泛型程序设计</h3><p><strong>泛型程序设计</strong>意味着编写的代码可以对多种不同类型的对象重用。</p>
<h4 id="谁想成为泛型程序员"><a href="#谁想成为泛型程序员" class="headerlink" title="谁想成为泛型程序员"></a>谁想成为泛型程序员</h4><p>使用像 ArrayList的泛型类很容易。大多数Java程序员都使用 ArrayList<String>这样的类型，就好像它们已经构建在语言之中，像 String[]数组一样。(当然，数组列表比数组要好一些，因为它可以自动扩展。)<br>但是，实现一个泛型类并没有那么容易。对于类型参数，使用这段代码的程序员可能想要内置( plug in)所有的类。他们希望在没有过多的限制以及混乱的错误消息的状态下，做所有的事情。因此，一个泛型程序员的任务就是预测出所用类的未来可能有的所有用途。<br>这一任务难到什么程度呢?下面是标准类库的设计者们肯定产生争议的一个典型问题。 ArrayList类有一个方法addAll用来添加另一个集合的全部元素。程序员可能想要将 ArrayList<Manager>中的所有元素添加到 ArrayList&lt; Employee&gt;中去。然而，反过来就不行了。如果只能允许前一个调用，而不能允许后一个调用呢?Java语言的设计者发明了一个具有独创性的新概念，通配符类型( wildcard type),它解决了这个问题。通配符类型非常抽象，然而，它们能让库的构建者编写出尽可能灵活的方法。<br>泛型程序设计划分为3个能力级别。基本级别是，仅仅使用泛型类——典型的是像 ArrayList这样的集合——不必考虑它们的工作方式与原因。大多数应用程序员将会停留在这一级别上，直到出现了什么问题。当把不同的泛型类混合在一起时，或是在与对类型参数一无所知的遗留的代码进行衔接时，可能会看到含混不清的错误消息。如果这样的话，就需要学习Java泛型来系统地解决这些问题，而不要胡乱地猜测。当然，最终可能想要实现自己的泛型类与泛型方法。<br>应用程序员很可能不喜欢编写太多的泛型代码。JDK开发人员已经做出了很大的努力，为所有的集合类提供了类型参数。凭经验来说，那些原本涉及许多来自通用类型(如 Object或 Comparable接口)的强制类型转换的代码一定会因使用类型参数而受益。</Manager></String></p>
<h3 id="定义简单泛型"><a href="#定义简单泛型" class="headerlink" title="定义简单泛型"></a>定义简单泛型</h3><p><strong>泛型类</strong>就是有一个或多个类型变量的类。</p>
<p>注释：类型变量使用大写形式，且比较短，这是很常见的。在ava库中，使用变量E表示集合的元素类型，K和V分别表示表的关键字与值的类型。T(需要时还可以用临近的字母U和S)表示“任意类型”。</p>
<h3 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h3><p>定义一个带有类型参数的简单方法。 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class ArrayAlg</span><br><span class="line">&#123;</span><br><span class="line"> public static &lt;T&gt; T getMiddle(T... a)</span><br><span class="line">&#123;</span><br><span class="line"> return a[a.length /2];</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>这个方法是在普通类中定义的，而不是在泛型类中定义的。然而，这是一个泛型方法，可以从尖括号和类型变量看出这一点。注意，类型变量放在修饰符(这里是 public static)的后面，返回类型的前面。<br>泛型方法可以定义在普通类中，也可以定义在泛型类中。<br>当调用一个泛型方法时，在方法名前的尖括号中放入具体的类型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String middle ArrayAlg. &lt;String&gt; (&quot;John&quot;, &quot;Q&quot;, &quot;Public&quot;);</span><br></pre></td></tr></table></figure>
<p>在这种情况(实际也是大多数情况)下，方法调用中可以省略<String>类型参数。编译器有足够的信息能够推断出所调用的方法。它用names的类型(即 String[])与泛型类型T[]进行匹配并推断出T一定 String是。也就是说，可以调用</String></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String middle ArrayAlg. getMiddle(&quot;John&quot;, &quot;Q.&quot;, &quot;Public&quot;);</span><br></pre></td></tr></table></figure>
<p>几乎在大多数情况下，对于泛型方法的类型引用没有问题。偶尔，编译器也会提示错误，此时需要解译错误报告。看一看下面这个示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">double middle= ArrayAlg.getMiddle(3.14,1729,0);</span><br></pre></td></tr></table></figure>
<p>错误消息会以晦涩的方式指出(不同的编译器给出的错误消息可能有所不同):解释这句代码有两种方法，而且这两种方法都是合法的。简单地说，编译器将会自动打包参数为1个 Double和2个 Integer对象，而后寻找这些类的共同超类型。事实上；找到2个这样的超类型： Number和 Comparable接口，其本身也是一个泛型类型。在这种情况下，可以采取的补救措施是将所有的参数都写为double值。</p>
<h3 id="类型限定的变量"><a href="#类型限定的变量" class="headerlink" title="类型限定的变量"></a>类型限定的变量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">有时，类或方法需要对类型变量加以约束。下面是一个典型的例子。我们要计算数组中的最小元素：</span><br><span class="line"> class ArrayAlg</span><br><span class="line"> &#123;</span><br><span class="line">    public static &lt;T&gt; T min( a)//almost correct</span><br><span class="line">   &#123;</span><br><span class="line">        if (a = null ||a.length==0) return null;</span><br><span class="line">        T smallest a[0];</span><br><span class="line">        for (int 1; i a. length; i++)</span><br><span class="line">            if (smallest. compareTo(a[i])&gt; 0) smallest=a[i];</span><br><span class="line">        return smallest;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;  </span><br></pre></td></tr></table></figure>
<p>但是，这里有一个问题。请看一下min方法的代码内部。变量 smallest类型为T,这意味着它可以是任何一个类的对象。怎么才能确信T所属的类有 compareTo方法呢?<br>解决这个问题的方案是将T限制为实现了 Comparable接口(只含一个方法compareTo的标准接口)的类。可以通过对类型变量T设置限定( bound)实现这一点：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public static &lt;T extends Comparable&gt; T min(T[] a)...</span><br></pre></td></tr></table></figure>
<p>实际上 Comparable接口本身就是一个泛型类型。目前，我们忽略其复杂性以及编译器产生的警告。<br>现在，泛型的min方法只能被实现了 Comparable接口的类(如String、 LocalDate等)的数组调用。由于 Rectangle类没有实现 Comparable接口，所以调用min将会产生一个编译错误。</p>
<p>读者或许会感到奇怪——在此为什么使用关键字 extends而不是 implements?毕竞， Comparable是一个接口。下面的记法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;T extends Boundinglype&gt;</span><br></pre></td></tr></table></figure>
<p>表示T应该是绑定类型的子类型(subtype)。T和绑定类型可以是类，也可以是接口。选择关键字 extends的原因是更接近子类的概念，并且Java的设计者也不打算在语言中再添加一个新的关键字(如sub)。<br>一个类型变量或通配符可以有多个限定，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">T extends Comparable &amp; Serializable</span><br></pre></td></tr></table></figure>
<p>限定类型用“&amp;”分隔，而逗号用来分隔类型变量。<br>在java的继承中，可以根据需要拥有多个接口超类型，但限定中至多有一个类。如果用一个类作为限定，它必须是限定列表中的第一个。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/29/%E6%8E%A5%E5%8F%A3%E4%B8%8E%E5%86%85%E9%83%A8%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/29/%E6%8E%A5%E5%8F%A3%E4%B8%8E%E5%86%85%E9%83%A8%E7%B1%BB/" class="post-title-link" itemprop="url">接口与内部类</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-06-29 19:47:49 / Modified: 21:00:45" itemprop="dateCreated datePublished" datetime="2021-06-29T19:47:49+08:00">2021-06-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><h4 id="接口的概念"><a href="#接口的概念" class="headerlink" title="接口的概念"></a>接口的概念</h4><p>接口中的所有方法都自动是public方法。因此，在接口中声明方法时，不必提供关键字public。</p>
<h4 id="接口的属性"><a href="#接口的属性" class="headerlink" title="接口的属性"></a>接口的属性</h4><p>接口不是类。具体来说，不能用new运算符实例化一个接口：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x =new Comparable(...);/erron</span><br></pre></td></tr></table></figure>
<p>不过，尽管不能构造接口的对象，却能声明接口的变量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Comparable x;//ok</span><br></pre></td></tr></table></figure>
<p>接下来，如同使用instanceof检查一个对象是否属于某个特定类一样，也可以使用instanceof检查一个对象是否实现了某个特定的接口：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if(anObject instanceof Comparable)&#123;...&#125;</span><br></pre></td></tr></table></figure>
<p>与建立类的继承层次一样，也可以扩展接口。。这里允许有多条接口链，从通用性较高的接口扩展到专用性较高的接口。例如，假设有一个名为Moveable的接口：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public interface Moveable</span><br><span class="line">&#123;</span><br><span class="line">void move(double x,double y);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后，可以假设一个名为Powered的接口扩展了以上接口：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public interface Powered extends Moveable</span><br><span class="line">&#123;</span><br><span class="line">double milePerGallon();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>虽然在接口中不能包含实例字段，但是可以包含常量。</p>
<h4 id="解决默认方法冲突"><a href="#解决默认方法冲突" class="headerlink" title="解决默认方法冲突"></a>解决默认方法冲突</h4><p>如果先在一个接口中将一个方法定义为默认方法，然后又在超类或另一个接口中定义同样的方法，会发生什么情况？java的规则如下：</p>
<p>（1）超类优先。如果超类提供了一个具体方法，同名而且参数相同的默认方法会被忽略。</p>
<p>（2）接口冲突。如果一个接口提供了一个默认方法，另一个接口1提供了一个同名而且参数类型（不论是否是默认参数）相同的方法，必须覆盖这个方法来解决冲突。</p>
<h4 id="回调"><a href="#回调" class="headerlink" title="回调"></a>回调</h4><p><strong>回调</strong>是一种常见的程序设计模式。在这种模式中，可以指定某个特定事件发生时应该采取的动作。</p>
<h3 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h3><p>内部类是定义在另一个类中的类。使用的原因主要有两点：</p>
<p>（1）内部类可以对同一个包中的其他类隐藏。</p>
<p>（2）内部类方法可以访问定义这个类的作用域中的数据，包括原本私有的数据。</p>
<h3 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h3><p>利用代理可以在运行时创建实现了一组给定接口的新类。只有在编译时期无法确定需要实现哪个接口时才有必要使用代理。对于编写应用程序的程序员来说，这种情况很少见，所以如果对这种高级技术不感兴趣，可以跳过本节内容。不过，对于某些系统应用程序，代带来的灵活性可能十分重要。</p>
<h4 id="何时使用代理"><a href="#何时使用代理" class="headerlink" title="何时使用代理"></a>何时使用代理</h4><p>假设你想构造一个类的对象，这个类实现了一个多个接口，但是在编译时你可能并不知道这些接口到底是什么。这个问题确实有些难度。要想构造一个具体的类，只需要使用 newInstance方法或者使用反射找出构造器。但是，不能实例化接口。需要在运行的程序中定义一个新类。<br>为了解决这个问题，有些程序会生成代码，将这些代码放在一个文件中，调用编译器， 然后再加载得到的类文件。很自然地，这样做速度会比较慢，并且需要将编译器连同程序 一起部署。而代理机制则是一种更好的解决方案。代理类可以在运行时创建全新的类。这样的代理类能够实现你指定的接口。具体地，代理类包含以下方法：</p>
<p>●指定接口所需要的全部方法。<br>●object类中的全部方法，例如， toString、 equals等。</p>
<p>不过，不能在运行时为这些方法定义新代码。实际上，必须提供一个调用处理器。调用处理器是实现了 InvocationHandler接口的类的对象。这个接口只有一个方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Object invoke(Object proxy, Method method, Object[] args)</span><br></pre></td></tr></table></figure>
<p>无论何时调用代理对象的方法，调用处器的 invoke方法都会被调用，并向其传递Method对象和原调用的参数。之后调用处理必须确定如何处理这个调用。</p>
<h4 id="创建代理对象"><a href="#创建代理对象" class="headerlink" title="创建代理对象"></a>创建代理对象</h4><p>要想创建一个代理对象，需要使用 Proxy类 newProxyInstance方法。这个方法有三个参数：<br>●一个类加载器。作为java安全模型的一部分，可以对平台和应用类、 从因特网下载的类等使用不同的类加载器。<br>●一个 Class对象数组，每个元素对应需要实现的各个接口。<br>●一个调用处理器。<br>还有两个需要解决的问题。如何定义处理器?另外，对于得到的代理对象能够做些什么?当然，这两个问题的答案取决于我们想要用代理机制解决什么问题。使用代理可能出于很多目的，例如：</p>
<p>●将方法调用路由到远程服务器。<br>●在运行的程序中将用户界面事件与动作关联起来。<br>●为了调试，跟踪方法调用。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">36</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
