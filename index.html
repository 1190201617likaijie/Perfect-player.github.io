<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">中断和异常处理-读书笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-10 19:10:10" itemprop="dateCreated datePublished" datetime="2022-04-10T19:10:10+08:00">2022-04-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-11 09:20:50" itemprop="dateModified" datetime="2022-04-11T09:20:50+08:00">2022-04-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="中断和异常处理"><a href="#中断和异常处理" class="headerlink" title="中断和异常处理"></a>中断和异常处理</h1><h2 id="中断和异常处理概述"><a href="#中断和异常处理概述" class="headerlink" title="中断和异常处理概述"></a>中断和异常处理概述</h2><p>中断和异常是表明在系统、处理器的某个地方存在一个条件的事件，或当前执行的程序或任务中存在需要处理器注意的情况。它们通常会强制将进程从当前运行的程序或任务转移到一个特殊的软件程序或任务上，称为中断处理程序或异常处理程序。处理器为响应中断或异常而采取的行动被称为中断或异常处理。<br>中断在程序执行过程中随机发生，以响应来自硬件的信号。系统硬件使用中断来处理处理器外部的事件，如服务外围设备的请求。软件也可以通过执行INT n指令来产生中断。当处理器在执行指令时检测到一个错误条件，如除以0，就会发生异常。处理器检测各种错误条件，包括违反保护规定、页面故障和内部机器故障。<br>奔腾4、英特尔至强、P6系列和奔腾处理器的机器，当检测到内部硬件错误和总线错误时，也允许产生一个机器检查异常。<br>当处理器执行一个中断或异常处理程序时，当前运行的程序或任务被暂停。当处理程序的执行完成后，处理器恢复被中断的程序或任务的执行。除非无法从异常中恢复，或者中断导致当前运行的程序被终止，否则被中断的程序或任务的恢复不会失去程序的连续性。<br> 在实模式下，中断向量表占据内存最低的1KB，共256个表项。每个表项4子节，包含一个2子节的段地址和2子节的偏移，即中断处理程序的入口地址。但是在保护模式下，中断向量表可以在内存中自由浮动。就像GDT被GDTR指向一样，中断向量表被IDTR(Interrupt Descriptor Table Register，中断描述符表寄存器)指向。该表和GDT非常类似。首先，GDTR和IDTR在格式上完全相同，均包含一个32bit的基地址和16bit的界限。相比之下，CPU中的另外两个关键寄存器LDTR和TR则表现出了相似性，都是16bit大小，分别包含指向LDT和TSS的选择子。从表项上来看，除了指出中断处理程序的目标地址(16bit选择子和32bit偏移)外，IDT表项还为了进行特权级检测而加入的DPL域。此外，IDT表项还包含一个P比特。</p>
<h2 id="有关中断和异常了解性的内容"><a href="#有关中断和异常了解性的内容" class="headerlink" title="有关中断和异常了解性的内容"></a>有关中断和异常了解性的内容</h2><h3 id="中断和异常向量"><a href="#中断和异常向量" class="headerlink" title="中断和异常向量"></a>中断和异常向量</h3><p>为了帮助处理异常和中断，每个架构上定义的异常和每个中断条件都被分配了一个唯一的识别号，称为向量号。处理器使用分配给一个异常或中断的向量号作为中断描述符表（IDT）的索引。该表提供了一个异常或中断处理程序的入口点。矢量号的允许范围是0到255。在0到31的范围内的向量号是由英特尔64和IA-32架构为架构定义的异常和中断保留了向量号。并非所有的向量号在这个范围内，并不是所有的向量号都有一个当前定义的功能。<br>在32到255范围内的向量号被指定为用户定义的中断，不被Intel64和IA-32架构保留。这些中断通常被分配给外部I/O设备，使这些设备能够向处理器发送中断。</p>
<h3 id="中断源和异常源"><a href="#中断源和异常源" class="headerlink" title="中断源和异常源"></a>中断源和异常源</h3><h4 id="中断来源"><a href="#中断来源" class="headerlink" title="中断来源"></a>中断来源</h4><p>处理器接收来自两个来源的中断。</p>
<ul>
<li>外部（硬件产生的）中断。</li>
<li>软件产生的中断</li>
</ul>
<h5 id="外部中断"><a href="#外部中断" class="headerlink" title="外部中断"></a>外部中断</h5><p>外部中断是通过处理器上的引脚或通过本地APIC接收的。Pentium 4、Intel Xeon、P6系列和Pentium处理器的主要中断引脚是LINT[1:0]引脚，它与本地APIC相连。启用时，LINT[1:0]引脚可以通过APIC的本地向量表(LVT)进行编程，以便与处理器的任何异常或故障相关联。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410193839865.png" alt="image-20220410193839865"></p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410193850982.png" alt="image-20220410193850982"></p>
<h5 id="可屏蔽的硬件中断"><a href="#可屏蔽的硬件中断" class="headerlink" title="可屏蔽的硬件中断"></a>可屏蔽的硬件中断</h5><p>任何通过INTR引脚或通过本地APIC传递给处理器的外部中断被称为可屏蔽硬件中断。可以通过INTR引脚传送的可屏蔽硬件中断包括所有IA-32体系结构定义的从0到255的中断向量；那些可通过本地APIC传送的中断包括中断向量16到255。</p>
<h5 id="软件产生的中断"><a href="#软件产生的中断" class="headerlink" title="软件产生的中断"></a>软件产生的中断</h5><p>INT n指令允许通过提供一个中断向量作为操作数，从软件内部产生中断。例如，INT 35指令强制调用35号中断的中断处理程序。任何从0到255的中断向量都可以作为该指令的参数。如果使用了处理器预定义的NMI向量，那么处理器的反应将与正常产生的的NMI中断产生的反应不一样。如果在这条指令中使用了2号向量（NMI向量），就会调用NMI中断处理程序，但处理器的NMI处理硬件没有被激活。用INT n指令在软件中产生的中断不能被EFLAGS寄存器中的IF标志所屏蔽。</p>
<h4 id="异常来源"><a href="#异常来源" class="headerlink" title="异常来源"></a>异常来源</h4><p>处理器接收来自三个来源的异常。</p>
<ul>
<li>处理器检测到的程序错误异常。</li>
<li>软件产生的异常。</li>
<li>机器检查的异常。</li>
</ul>
<h5 id="程序错误异常"><a href="#程序错误异常" class="headerlink" title="程序错误异常"></a>程序错误异常</h5><p>当处理器在应用程序或操作系统或执行程序的执行过程中检测到程序错误时，会产生一个或多个异常。英特尔64和IA-32架构为每个处理器检测到的异常定义了一个向量号。</p>
<h5 id="软件产生的异常"><a href="#软件产生的异常" class="headerlink" title="软件产生的异常"></a>软件产生的异常</h5><p>INTO, INT 3, 和 BOUND 指令允许在软件中产生异常。这些指令允许异常条件的检查在指令流中执行。例如，INT 3产生一个断点异常。INT n指令可以用来模拟软件中的异常；但是有一个限制。如果INT n提供了一个架构定义的异常的向量，处理器会产生一个中断到正确的向量(来访问异常处理程序），但不会在堆栈上推送错误代码。</p>
<h5 id="机器检查异常"><a href="#机器检查异常" class="headerlink" title="机器检查异常"></a>机器检查异常</h5><p>P6系列和奔腾处理器提供内部和外部机器检查机制，用于检查内部芯片硬件和总线交易的操作。这些机制取决于执行情况。当检测到机器检查错误时，处理器发出机器检查异常信号（向量18）并返回一个错误代码。</p>
<h3 id="异常的分类：故障、陷阱和中止"><a href="#异常的分类：故障、陷阱和中止" class="headerlink" title="异常的分类：故障、陷阱和中止"></a>异常的分类：故障、陷阱和中止</h3><p>异常被归类为故障、陷阱或中止，这取决于它们的报告方式以及引起异常的指令是否能在不损失程序或任务连续性的情况下重新启动。</p>
<ul>
<li><strong>故障</strong></li>
</ul>
<p>故障是一种通常可以被纠正的异常，一旦被纠正，就可以在不损失程序或任务连续性的情况下重新启动程序。<br>当一个故障被报告时，处理器将机器状态恢复到在开始执行故障指令之前的状态。故障处理程序的返回地址（保存在CS和EIP寄存器的保存内容）指向故障指令，而不是指向故障指令之后的指令。</p>
<ul>
<li><p><strong>陷阱</strong> </p>
<p>陷阱是在执行陷阱指令后立即报告的异常。陷阱允许程序或任务的执行继续进行而不损失程序的连续性。陷阱处理程序的返回地址指向陷阱指令后要执行的指令。</p>
</li>
<li><p><strong>终止</strong> </p>
<p>终止是一种异常，它并不总是报告引起异常的指令的精确位置，并且不允许重新启动引起异常的程序或任务。中止是用来报告严重的错误，例如硬件错误和系统表中不一致的或非法的值。</p>
</li>
</ul>
<p><strong>注意</strong></p>
<p>一个通常被报告为故障的异常子集是不能重新启动的。这种异常会导致损失一些处理器的状态。例如，在执行POPAD指令时，堆栈框架执行POPAD指令时，堆栈框架越过了堆栈段的末端，导致报告了一个故障。在这种情况下，异常处理程序看到指令指针(CS:EIP)已经被恢复，就像POPAD 指令没有被执行。然而，内部处理器状态（通用寄存器）将被修改。这种情况被认为是编程错误</p>
<h3 id="程序或任务的重新执行"><a href="#程序或任务的重新执行" class="headerlink" title="程序或任务的重新执行"></a>程序或任务的重新执行</h3><p>为了允许在处理异常或中断后重新启动程序或任务，所有的异常(除了中止)都保证在指令边界上报告异常。所有的中断都被保证为在一个指令边界上进行。<br>对于故障类异常，返回指令指针（在处理器产生异常时保存）指向发生故障的指令。因此，当一个程序或任务在处理完故障后被重新启动时，发生故障的指令被重新启动（重新执行）。重启出错指令通常用于处理当对操作数的访问被阻止时产生的异常。这种类型的故障最常见的例子是页面故障异常（#PF），它发生在程序或任务引用位于不在内存中的页面上的操作数时。<br>当页面故障异常发生时，异常处理程序可以将该页面加载到内存中，并通过重启来恢复程序或任务的执行。为了确保重启对当前执行的程序或任务来说是透明的，处理器保存了必要的寄存器和堆栈指针 ，以允许重新启动到执行故障指令之前的状态。<br>对于陷阱类异常，返回指令的指针指向陷阱指令之后的指令。如果在转移执行的指令中检测到一个陷阱，返回指令指针反映了转移。例如，如果在执行JMP指令时检测到一个陷阱，返回指令的指针指向JMP指令的目的地，而不是JMP指令之后的下一个地址。所有的陷阱异常都允许程序或任务的重新启动而不会失去连续性。例如，溢出异常就是一个陷阱异常。在这里，返回指令的指针指向INTO指令之后的指令，该指令测试了EFLAGS.OF（溢出）标志。这个异常的陷阱处理程序解决了溢出的问题。从陷阱处理程序返回后，程序或任务在INTO指令之后的指令继续执行。<br>终止类异常不支持程序或任务的可靠重启。终止处理程序被设计为收集关于终止异常发生时处理器状态的诊断信息，然后尽可能优雅地关闭应用程序和系统。<br>中断程序严格地支持重新启动被中断的程序和任务而不损失连续性。返回为中断保存的返回指令指针指向要在指令边界执行的下一条指令 。如果刚刚执行的指令有一个重复的前缀，那么中断就会在当前迭代结束时进行，寄存器被设置为执行下一个迭代。</p>
<h3 id="开启和禁止中断"><a href="#开启和禁止中断" class="headerlink" title="开启和禁止中断"></a>开启和禁止中断</h3><p>处理器会抑制一些中断的产生，这取决于处理器的状态和EFLAGS寄存器中的IF和RF标志的状态。</p>
<h4 id="屏蔽可屏蔽硬件中断"><a href="#屏蔽可屏蔽硬件中断" class="headerlink" title="屏蔽可屏蔽硬件中断"></a>屏蔽可屏蔽硬件中断</h4><p>IF标志可以禁止对处理器INTR引脚上或通过本地APIC接收的可屏蔽硬件中断进行服务。当IF标志清除时，处理器会抑制传递到INTR引脚或通过本地APIC的中断产生内部中断请求；当IF标志被设置时，传递到INTR或通过本地APIC引脚的中断被作为正常的外部中断处理。<br>IF标志不影响传递到NMI引脚的非屏蔽中断（NMI）或通过本地APIC传递的交付模式NMI消息，也不影响处理器产生的异常。与EFLAGS寄存器中的其他标志一样，处理器在响应硬件复位时清除IF标志。<br>事实上，可屏蔽的硬件中断组包括保留的中断和异常向量0到32可能会引起混淆。从结构上看，当IF标志被设置时，矢量0到32的中断可以通过INTR引脚传递给处理器，而矢量16到32的中断则可以通过本地接口传递。然后，处理器将产生一个中断并调用中断或异常处理程序，该处理程序由矢量编号指向。<br>IF标志可以通过STI（设置中断使能标志）和CLI（清除中断使能标志）指令来设置或清除。这些指令只有在CPL等于或小于IOPL的情况下才能执行。如果在CPL大于IOPL的情况下执行这些指令，会产生一般保护异常（#GP）。<br>IF标志也受到以下操作的影响。</p>
<ul>
<li>PUSHF指令将所有的标志存储在堆栈上，在那里可以检查和修改它们。POPF指令可以用来将修改后的标志加载到EFLAGS寄存器中。</li>
<li>任务开关、POPF和IRET指令加载EFLAGS寄存器；因此，它们可以用来修改IF标志的设置。</li>
<li>当一个中断通过中断门处理时，IF标志会被自动清除，这就禁止了可屏蔽的硬件中断。</li>
</ul>
<h4 id="屏蔽指令断点"><a href="#屏蔽指令断点" class="headerlink" title="屏蔽指令断点"></a>屏蔽指令断点</h4><p>EFLAGS寄存器中的RF（恢复）标志控制处理器对指令断点条件的响应。当设置时，它阻止指令断点产生调试异常（#DB）；当清除时，指令断点将产生调试异常。RF标志的主要功能是防止处理器在以下情况下进入调试异常循环 。</p>
<h4 id="切换堆栈时屏蔽异常和中断"><a href="#切换堆栈时屏蔽异常和中断" class="headerlink" title="切换堆栈时屏蔽异常和中断"></a>切换堆栈时屏蔽异常和中断</h4><p>为了切换到一个不同的堆栈段，软件经常使用一对指令，例如：<br>MOV SS, AX<br>MOV ESP, StackTop<br>如果在段选择器被加载到SS寄存器之后，但在ESP寄存器被加载之前，发生了中断或异常。ESP寄存器中，这两部分进入堆栈空间的逻辑地址在中断或异常处理过程中是不一致的。为了防止这种情况的发生，处理器在MOV到SS指令或POP到SS指令之后，处理器抑制中断、调试异常和单步陷阱异常，直到到达下一条指令后的指令边界。所有其他的故障仍然可以被产生。如果LSS指令被用来修改SS寄存器的内容（推荐的方法），这个问题就不会发生。</p>
<h3 id="异常和中断的优先级"><a href="#异常和中断的优先级" class="headerlink" title="异常和中断的优先级"></a>异常和中断的优先级</h3><p>如果在一个指令边界有一个以上的异常或中断等待处理，处理器会以可预测的顺序处理它们。下表显示了异常和中断源类别之间的优先级。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410202420157.png" alt="image-20220410202420157"></p>
<p><strong>注意</strong>：虽然在表中列出的这些类别的优先级在整个架构中是一致的，但是每个类别中的例外情况是与实现有关的，可能因处理器不同而不同。处理器首先处理来自具有最高优先级的类的未决异常或中断，将执行转移到处理程序的第一条 指令。较低优先级的异常被丢弃；较低优先级的中断被搁置。当中断处理程序将执行返回到程序或任务中出现异常和/或中断的位置时，被丢弃的异常会重新产生。</p>
<h2 id="中断描述符表"><a href="#中断描述符表" class="headerlink" title="中断描述符表"></a>中断描述符表</h2><p>中断描述符表（IDT）将每个异常或中断向量与用于服务相关异常或中断的门描述符联系起来。与GDT和LDT一样，IDT是一个由8字节描述符组成的数组。。与GDT不同，IDT的第一个条目可以包含一个描述符。为了<br>为了形成对IDT的索引，处理器将异常或中断向量按8（门描述符的字节数）的比例进行调整。因为只有256个中断或异常向量，IDT不需要包含多于256个描述符。它可以包含少于256个描述符，因为描述符只需要用于可能发生的中断和可能出现的异常向量需要描述符。IDT中所有空的描述符槽都应该将描述符的当前标志设置为0。<br>IDT的基地址应该在8字节的边界上对齐，以最大限度地提高缓存行的性能 。极限值以字节为单位，并与基地址相加，得到最后一个有效字节的地址。极限值为0时，正好是一个有效的字节。因为IDT条目总是8个字节长，所以极限值应该是始终是8的整数倍（即8N-1）。<br>IDT可以驻留在线性地址空间的任何地方。如图6-1所示，处理器使用IDTR寄存器来定位IDT 。这个寄存器持有32位的基地址和16位的IDT限制。<br>LIDT（加载IDT寄存器）和SIDT（存储IDT寄存器）指令分别加载和存储IDTR的内容。LIDT指令将IDTR寄存器中的基地址和限值加载到一个内存操作数中。这条指令只有在CPL为0时才能被执行。它通常由操作系统的初始化代码在创建IDT时使用。操作系统也可以用它来改变一个IDT到另一个IDT。<br>SIDT指令将IDTR中存储的基数和极限值复制到内存中。这条指令可以在任何权限级别下执行。如果一个向量引用的描述符超过了IDT的限制，就会产生一个一般保护异常（#GP）。<br><strong>注意</strong><br>由于中断只传递给处理器内核一次，一个不正确配置的IDT可能导致不完整的中断处理和/或中断传递的阻塞。在设置IDTR基础/限制/访问字段和门描述符中的每个字段时，需要遵循IA-32架构的规则。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410202728708.png" alt="image-20220410202728708"></p>
<h2 id="IDT-描述符"><a href="#IDT-描述符" class="headerlink" title="IDT 描述符"></a>IDT 描述符</h2><p>IDT可能包含三种门描述符中的任何一种。</p>
<ul>
<li>任务门描述符</li>
<li>中断门描述符</li>
</ul>
<p>陷阱门描述符<br>图6-2显示了任务门、中断门和陷阱门描述符的格式。任务门的格式在IDT中使用的任务门的格式与在GDT或LDT中使用的任务门的格式相同。任务门包含一个异常和/或中断处理任务的TSS的段选择器。<br>中断和陷阱门与调用门非常相似。它们包含一个远指针(段选择器和偏移量)，处理器用它来把程序的执行转移到异常或中断处理程序代码中的一个处理程序。<br>这些门的不同之处在于处理器处理EFLAGS寄存器中的IF标志的方式。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410205107225.png" alt="image-20220410205107225"></p>
<h2 id="中断与异常处理"><a href="#中断与异常处理" class="headerlink" title="中断与异常处理"></a>中断与异常处理</h2><p>处理器处理对异常处理程序和中断处理程序的调用的方式类似于处理对过程或任务的CALL指令来处理对过程或任务的调用。当响应一个异常或中断时，处理器使用异常或中断向量作为IDT中描述符的索引。如果该索引指向一个中断门或陷阱门，处理器调用异常或中断处理程序，其方式类似于调用门的CALL。如果 index 指向一个任务<br>门，处理器将执行一个任务切换到异常或中断处理任务，其方式类似于 CALL到一个任务门</p>
<h3 id="异常或中断处理程序"><a href="#异常或中断处理程序" class="headerlink" title="异常或中断处理程序"></a>异常或中断处理程序</h3><p>中断门或陷阱门引用了一个异常或中断处理程序，该程序在当前执行的任务的上下文中运行（见图6-3）。该门的段选择器指向一个段描述符，该段描述符位于GDT或当前LDT中的一个可执行代码段。门描述符的偏移字段指的是<br>异常或中断处理程序的开头。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410205743923.png" alt="image-20220410205743923"></p>
<p>当处理器执行一个对异常或中断处理程序的调用时。</p>
<ul>
<li>如果处理程序要在一个较低的权限级别上执行，就会发生堆栈切换。<br>当堆栈切换发生时 :<br>a. 处理程序使用的堆栈的段选择器和堆栈指针是从当前执行任务的TSS中获得的。在这个新的堆栈中，处理程序推送了被中断的堆栈段选择器和堆栈指针。<br>b. 然后，处理器将EFLAGS、CS和EIP寄存器的当前状态保存在新的堆栈中（见图6-4）。<br>c. 如果一个异常导致错误代码被保存，它将被推到EIP值之后的新栈上。</li>
<li>如果处理程序要在与被中断程序相同的权限级别下执行。<br>a. 处理器将EFLAGS、CS和EIP寄存器的当前状态保存在当前堆栈中（见图6-4）。<br>b. 如果一个异常导致错误代码被保存，那么它将在EIP值之后被推到当前堆栈中。</li>
</ul>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410210127965.png" alt="image-20220410210127965"></p>
<p>要从一个异常或中断处理程序中返回，处理程序必须使用IRET（或IRETD）指令。IRET指令与RET指令类似，只是它将保存的标志恢复到EFLAGS寄存器中。只有当CPL为0时，EFLAGS寄存器的IOPL字段才被恢复。</p>
<h4 id="异常和中断处理程序的保护"><a href="#异常和中断处理程序的保护" class="headerlink" title="异常和中断处理程序的保护"></a>异常和中断处理程序的保护</h4><p>异常和中断处理程序的特权级别保护与通过调用门调用普通程序的保护相似。处理器不允许将执行转移到一个异常或中断处理程序中。试图违反这一规则会导致一般保护异常（#GP）。异常处理程序和中断处理程序的保护机制在以下方面有所不同：</p>
<ul>
<li>因为中断和异常向量没有RPL，RPL在隐式调用异常和中断处理程序的隐式调用不检查RPL。</li>
<li>只有在异常或中断产生的时候，处理器才会检查中断或陷阱门的DPL，如果有一个INT n, INT 3, 或 INTO 指令产生的异常或中断，处理器才会检查中断或陷阱门的 DPL。这里，CPL必须小于或等于门的DPL。这一限制防止了运行在权限级别3的应用程序或程序使用软件中断来访问关键的异常处理程序。中断来访问关键的异常处理程序，例如页面故障处理程序，条件是这些处理程序被放在更有权限的代码段中。对于硬件产生的中断和处理器检测到的异常，处理器忽略了中断和陷阱门的DPL。</li>
</ul>
<p>由于异常和中断通常不会在可预测的时间发生，这些特权规则有效地对异常和中断处理程序可以运行的权限级别进行了限制。以下两种技术都可以用来避免违反权限级别：</p>
<ul>
<li>异常或中断处理程序可以放在一个符合要求的代码段中。这种技术可以用于处理程序，这些处理程序只需要访问堆栈上的数据（例如，划分错误异常）。如果处理程序需要来自数据段的数据，数据段需要从权限级别3访问，这将使其不受保护。</li>
<li>处理程序可以被放置在一个特权级别为0的不符合要求的代码段中。这个处理程序将始终运行，不管被中断的程序或任务是在哪个CPL下运行。</li>
</ul>
<h4 id="异常或中断处理程序的标志用法"><a href="#异常或中断处理程序的标志用法" class="headerlink" title="异常或中断处理程序的标志用法"></a>异常或中断处理程序的标志用法</h4><p>当通过中断门或陷阱门访问异常或中断处理程序时，处理器在将EFLAGS寄存器的内容保存在堆栈中后，清除EFLAGS寄存器中的TF标志。(在调用异常和中断处理程序时，处理器也会清除EFLAGS寄存器中的VM、RF和NT标志，然后将它们保存在堆栈中。）清除TF标志可以防止指令跟踪影响中断响应。A 后续的IRET指令将TF（以及VM、RF和NT）标志恢复到堆栈中EFLAGS寄存器的保存内容中的值。<br>中断门和陷阱门的唯一区别是处理器处理IF标志的方式。当通过中断门访问一个异常或中断处理程序时，处理器会清除IF标志以防止 其他中断干扰当前的中断处理程序。随后的IRET指令将IF标志恢复到堆栈上EFLAGS寄存器的保存内容中的值。通过陷阱门访问处理程序并不影响IF标志。</p>
<h3 id="中断任务"><a href="#中断任务" class="headerlink" title="中断任务"></a>中断任务</h3><p>当异常或中断处理程序通过IDT中的任务门被访问时，会产生一个任务切换。处理异常或中断的单独任务有几个优点。</p>
<ul>
<li>被中断的程序或任务的整个上下文被自动保存。</li>
<li>一个新的TSS允许处理程序在处理异常或中断时使用一个新的权限级别0的堆栈。如果异常或中断发生时，当前权限级别0的堆栈被破坏，通过任务门访问处理程序可以通过为处理程序提供一个新的权限级别0的堆栈来防止系统崩溃。</li>
<li>处理程序可以通过给它一个单独的地址空间来进一步与其他任务隔离。这可以通过以下方式实现给它一个单独的LDT。</li>
</ul>
<p>用一个单独的任务来处理中断的缺点是，在任务切换时必须保存大量的机器状态，使得它比使用中断门要慢，从而导致中断延迟的增加。<br>IDT中的任务门引用GDT中的TSS描述符（见图6-5）。切换到处理程序任务的方式与普通任务切换相同。返回到被中断的任务的链接 被存储在处理程序任务的TSS的前一个任务链接域中。如果一个异常导致一个错误代码，这个错误代码被复制到新任务的堆栈中。<br>在操作系统中使用异常或中断处理任务时，实际上有两种机制可以用来调度任务：软件调度器（操作系统的一部分）和硬件调度器（处理器的中断机制的一部分）。软件调度器需要容纳中断任务当中断被激活时，可能会被调度。<br><strong>注意</strong><br>由于IA-32体系结构的任务不是可重入的，一个中断处理程序任务在它完成处理中断和执行IRET指令时，必须禁用中断。这个动作可以防止在中断任务的TSS仍被标记为忙时发生另一个中断，这将导致一般保护（#GP）异常。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220411091420768.png" alt="image-20220411091420768"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">保护模式内存管理-读书笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-03 10:09:18" itemprop="dateCreated datePublished" datetime="2022-04-03T10:09:18+08:00">2022-04-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-04 20:56:32" itemprop="dateModified" datetime="2022-04-04T20:56:32+08:00">2022-04-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="保护模式内存管理"><a href="#保护模式内存管理" class="headerlink" title="保护模式内存管理"></a>保护模式内存管理</h1><h2 id="内存管理概览"><a href="#内存管理概览" class="headerlink" title="内存管理概览"></a>内存管理概览</h2><p>IA-32架构的内存管理设施分为两部分：分段和分页。<br>分段提供了一种隔离单个代码、数据和堆栈模块的机制，以便多个程序（或任务）可以在同一个处理器上运行而不互相干扰。分页提供了一种机制来实现传统的需求分页、虚拟内存系统，其中程序执行环境的部分被映射到物理内存中。分页也可以用来提供多个任务之间的隔离。<br>在保护模式下操作时，必须使用某种形式的分段。没有模式位可以禁用分段。然而，分页的使用是可选的。这两种机制（分段和分页）可以被配置为支持简单的单程序（或单任务）系统，或使用共享内存的多处理器系统。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403145257014.png" alt="image-20220403145257014"></p>
<p>如图所示，分段提供了一种机制来划分处理器的可寻址内存空间（称为线性地址空间），分成更小的受保护的地址空间，称为段。分段可以可以用来保存程序的代码、数据和堆栈，或者保存系统数据结构（如TSS或LDT）。<br>如果一个处理器上有多个程序（或任务）在运行，每个程序可以被分配到它自己的段组。然后，处理器强制执行这些段之间的界限，并确保一个程序不会因为写进另一个程序的段而干扰程序的执行。分段机制还允许对段进行打字。</p>
<p>段落机制也允许段的类型化，这样可以限制对特定类型的段进行的操作。一个系统中的所有段都包含在处理器的线性地址空间中。要在一个特定的段中找到一个字节必须提供一个逻辑地址（也称为远指针）。</p>
<p>一个<strong>逻辑地址</strong>包括一个段选择器和一个偏移量。段选择器是一个段的唯一标识符。在其他方面，它提供了一个<br>在描述符表（如全局描述符表，GDT）中的偏移量，该数据结构称为段描述符。每个网段都有一个网段描述符，它指定了网段的大小，网段的访问权限和段的大小，段的访问权限和特权级别，段的类型，以及段的第一个字节在线性地址空间中的位置（称为段的基址）。逻辑地址的偏移部分被添加到段的基地址中，以定位段的第一个字节。<br>基准地址加上偏移量就形成了处理器线性地址中的一个<strong>线性地址</strong>。<br>如果不使用分页，处理器的线性地址空间将直接被映射到处理器的物理地址空间。<strong>物理地址空间</strong>被定义为处理器可以在其地址总线上产生的地址范围。由于多任务计算系统通常定义的线性地址空间远远大于在物理内存中一次性包含的经济可行性，因此需要一些 “虚拟化 “线性地址空间的方法。这种线性地址空间的虚拟化是通过处理器的分页机制处理的。<br>分页支持 “虚拟内存 “环境，用少量的物理内存（RAM和ROM）和一些磁盘存储来模拟大的线性地址空间。当使用分页时，每个段被划分为若干页（通常每页大小为4KB），这些页存储在物理内存或磁盘上。操作系统或执行器维护一个页面目录和一组页面表，以跟踪这些页面。<em>当一个程序（或任务）试图访问线性地址空间中的一个地址位置时，处理器会使用页目录和页表来将线性地址转换为物理地址</em>，然后执行所要求的操作（读或写）在内存位置上。<br>如果被访问的页面当前不在物理内存中，处理器会中断程序的执行。(通过产生一个页面故障异常)。然后，操作系统或执行程序将该页从磁盘读入物理内存，并继续执行程序。<br>当分页在操作系统或执行系统中被正确实现时，物理内存和磁盘之间的换页对于程序的正确执行是透明的。即使是为16位IA32处理器编写的程序，在虚拟8086模式下运行时也可以进行分页（透明）。</p>
<h3 id="linux下的内存管理"><a href="#linux下的内存管理" class="headerlink" title="linux下的内存管理"></a>linux下的内存管理</h3><p>Linux系统中的物理存储空间和虚拟存储空间的地址范围分别都是从0x00000000到0xFFFFFFFF，共4GB，但物理存储空间与虚拟存储空间布局完全不同。Linux运行在虚拟存储空间，并负责把系统中实际存在的远小于4GB的物理内存根据不同需求映射到整个4GB的虚拟存储空间中。Linux主要工作在保护模式下。80X86从逻辑地址到物理地址变换中经过了两个阶段。第一阶段使用分段机制把程序的逻辑地址变换成处理器可寻址内存空间（称为线性地址空间）中的地址。第二阶段的分页机制把线性地址转换成物理地址。第一阶段的分段变换机制是必须使用的，但是第二阶段的分页机制是可选择的。如果没有开启分页机制，那么分段机制产生的线性地址空间就直接映射到处理器的物理地址空间上。</p>
<h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><p><strong>物理地址</strong>： 放在寻址总线上的地址，用于内存芯片级内存单元寻址。放在寻址总线上，如果是读，电路根据这个地址每位的值就将相应地址的物理内存中的数据放到数据总线中传输。如果是写，电路根据这个地址每位的值就将相应地址的物理内存中放入数据总线上的内容。物理内存是以字节(8位)为单位编址的，是地址变换的最终结果地址，物理地址由32位或36位无符号整数表示。</p>
<p><strong>逻辑地址</strong>：是指由程序产生的与段相关的偏移地址部分，每一个逻辑地址都由一个段和偏移量组成。在进行C语言指针编程中，可以读取指针变量本身值(&amp;操作)，实际上这个值就是逻辑地址，它是相对于你当前进程数据段的地址，不和绝对物理地址相干。只有在Intel实模式下，逻辑地址才和物理地址相等（因为实模式没有分段或分页机制,Cpu不进行自动地址转换）；逻辑也就是在Intel 保护模式下程序执行代码段限长内的偏移地址（假定代码段、数据段如果完全一样）。</p>
<p><strong>线性地址：</strong>是逻辑地址到物理地址变换之间的中间层。程序代码会产生逻辑地址，或者说是段中的偏移地址，加上相应段的基地址就生成了一个线性地址，是一个32位无符号整数，可以用来表示高达4GB的地址，也就是说，高达4294967296个内存单元，以十六进制表示，0x00000000到oxffffffff。如果启用了分页机制，那么线性地址可以再经变换以产生一个物理地址。若没有启用分页机制，那么线性地址直接就是物理地址。Intel 80386的线性地址空间容量为4G（2的32次方即32根地址总线寻址）。</p>
<p><strong>虚拟内存</strong>：是指计算机呈现出要比实际拥有的内存大得多的内存量。因此它允许程序员编制并运行比实际系统拥有的内存大得多的程序。这使得许多大型项目也能够在具有有限内存资源的系统上实现。一个很恰当的比喻是：你不需要很长的轨道就可以让一列火车从上海开到北京。你只需要足够长的铁轨（比如说3公里）就可以完成这个任务。采取的方法是把后面的铁轨立刻铺到火车的前面，只要你的操作足够快并能满足要求，列车就能象在一条完整的轨道上运行。这也就是虚拟内存管理需要完成的任务。在现在操作系统中，都使用了MMU的存储管理技术，而MMU管理的地址是虚拟地址，虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。有时我们也把逻辑地址称为虚拟地址。因为和虚拟内存空间的概念类似，逻辑地址也是和实际物理内存容量无关的。</p>
<h4 id="逻辑地址如何转换为线性地址"><a href="#逻辑地址如何转换为线性地址" class="headerlink" title="逻辑地址如何转换为线性地址"></a>逻辑地址如何转换为线性地址</h4><p> 完整的内存管理，包含保护和地址变换两个关键部分。80386的工作模式包括实地址模式和虚地址模式（保护模式）。Linux主要工作在保护模式下。80X86从逻辑地址到物理地址变换中经过了两个阶段。第一阶段使用分段机制把程序的逻辑地址变换成处理器可寻址内存空间（称为线性地址空间）中的地址。第二阶段的分页机制把线性地址转换成物理地址。第一阶段的分段变换机制是必须使用的，但是第二阶段的分页机制是可选择的。如果没有开启分页机制，那么分段机制产生的线性地址空间就直接映射到处理器的物理地址空间上。</p>
<p>  一个逻辑地址由两部份组成，<strong>段标识符: 段内偏移量</strong>。段标识符是由一个16位长的字段组成，称为段选择符。其中前13位是一个索引号。后面3位包含一些硬件细节，表示具体的是代码段寄存器还是栈段寄存器抑或是数据段寄存器，如图1所示。索引号就是“段描述符(segment descriptor)”的索引，段描述符具体地址描述了一个段。很多个段描述符，就组了一个数组，叫“段描述符表”，这样，<strong>可以通过段标识符的前13位，直接在段描述符表中找到一个具体的段描述符</strong>，这句话很关键，说明段标识符的具体作用，每一个段描述符由8个字节组成，如图2所示，与主题最密切的就是Base字段，她表示的是包含段的首字节的线性地址，也就是一个段的开始位置的线性地址。完全引用书中的一句话，一些全局的段描述符，就放在“全局段描述符表(GDT)”中，一些局部的，例如每个进程自己的，就放在所谓的“局部段描述符表(LDT)”中。那究竟什么时候该用GDT，什么时候该用LDT呢？这是由段选择符中的T1字段表示的，=0，表示用GDT，=1表示用LDT，GDT在内存中的地址和大小存放在CPU的GDTR控制寄存器中，而LDT则在IDTR寄存器中。这个过程中有几个基本的概念，一定要理清楚，如段选择符、段描述符、局部段描述符表、全局段描述符表。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403152513453.png" alt="image-20220403152513453"></p>
<p>上图显示了一个逻辑地址是怎样转换成相应线性地址的，给定一个完整的逻辑地址[段选择符：段内偏移地址]</p>
<p> 1、看段选择符的T1=0还是1，即<strong>先检查段选择符中的TI字段，以决定段描述符保存在哪一个描述符表中</strong>，知道当前要转换是GDT中的段（在这种情况下，分段单元从GDTR寄存器中得到GDT的线性基地址），还是LDT中的段（在这种情况下，分段单元从LDTR寄存器中得到GDT的线性基地址），再根据相应寄存器，得到其地址和大小。<br>2、<strong>由于一个段描述符是8字节长，因此她在GDT或LDT内的相对地址是由段选择符的最高13位的值乘以8得到</strong>，拿出段选择符中前13位，可以在这个数组中，查找到对应的段描述符，这样，它的Offset，即偏移地址就知道了。<br>3、把Base + offset，就是要转换的线性地址了。<br>    对于软件来讲，原则上就需要把硬件转换所需的信息准备好，就可以让硬件来完成这个转换了。下图逻辑地址转换为线性地址实例，段选择符为0x7B，指向用户数据段，段起始地址为0x00000000，逻辑偏移地址为0x80495B0，最终的线性地址为Base + offset=0x80495B0。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403153532441.png" alt="image-20220403153532441"></p>
<h4 id="线性地址转物理地址"><a href="#线性地址转物理地址" class="headerlink" title="线性地址转物理地址"></a>线性地址转物理地址</h4><p>CPU通过地址来访问内存中的单元，地址有虚拟地址和物理地址之分，如果CPU没有MMU（Memory  Management Unit，内存管理单元），或者有MMU但没有启用，CPU核在取指令或访问内存时发出的地址将直接传到CPU芯片的外部地址引脚上，直接被内存芯片（以下称为物理内存，以便与虚拟内存区分）接收，这称为物理地址（Physical Address，以下简称PA），如下图所示。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403155046532.png" alt="image-20220403155046532"></p>
<p>如果CPU启用了MMU，CPU核发出的地址将被MMU截获，从CPU到MMU的地址称为虚拟地址（Virtual Address，以下简称VA），而MMU将这个地址翻译成另一个地址发到CPU芯片的外部地址引脚上，也就是将虚拟地址映射成物理地址，如下图所示</p>
<p> <img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403155108029.png" alt="image-20220403155108029"></p>
<p>虚拟内存地址和物理内存地址的分离，给进程带来便利性和安全性。虚拟地址必须和物理地址建立一一对应的关系，才可以正确的进行地址转换。</p>
<p>记录对应关系最简单的办法，就是把对应关系记录在一张表中。为了让翻译速度足够地快，这个表必须加载在内存中。不过，这种记录方式惊人地浪费。</p>
<p>因此，Linux采用了分页（paging）的方式来记录对应关系。所谓的分页，就是以更大尺寸的单位页（page）来管理内存。在Linux中，通常每页大小为4KB。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403155154004.png" alt="image-20220403155154004"></p>
<p>依据以下步骤进行转换：</p>
<ol>
<li>从cr3中取出进程的页目录地址（操作系统负责在调度进程的时候，把这个地址装入对应寄存器）；</li>
<li>根据线性地址前十位，在数组中，找到对应的索引项，因为引入了二级管理模式，页目录中的项，不再是页的地址，而是一个页表的地址。（又引入了一个数组），页的地址被放到页表中去了。</li>
<li>根据线性地址的中间十位，在页表（也是数组）中找到页的起始地址；</li>
<li>将页的起始地址与线性地址中最后12位相加，得到最终我们想要的；</li>
</ol>
<h2 id="分段机制"><a href="#分段机制" class="headerlink" title="分段机制"></a>分段机制</h2><p>由IA-32体系结构支持的分段机制可以用来实现各种各样的系统设计。这些设计的范围很广，从只极少使用分段的平面模型到保护。这些设计从扁平模型到多分段模型，这些模型采用分段来创建一个强大的操作环境，在其中多个程序和任务可以可靠地执行。</p>
<h3 id="Basic-Flat-Model-基本平坦模型"><a href="#Basic-Flat-Model-基本平坦模型" class="headerlink" title="Basic Flat Model(基本平坦模型)"></a>Basic Flat Model(基本平坦模型)</h3><p>一个系统最简单的内存模型是基本的 “平坦模型”，在这个模型中，操作系统和应用程序可以访问一个连续的、没有分割的地址空间。在最大程度上，这种基本的平坦模型对系统设计者和应用程序都隐藏了架构的分割机制。<br>程序员为了实现IA-32体系结构的基本平坦内存模型，至少要创建两个段描述符，一个用于引用代码段，一个用于引用数据段。这两个段都被映射到整个线性地址空间：也就是说，两个段描述符都有同样的基址值为0，同样的段限制为4GBytes。通过设置段限制为4GBytes，分段机制就不会因为超出限制的内存引用而产生异常，即使在一个特定的地址上没有物理内存存在。ROM（EPROM）通常位于物理地址空间的顶部。因为处理器在FFF_FFF0H开始执行。RAM（DRAM）被放在物理地址空间的底部，因为复位初始化后DS数据段的初始基址是0。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403161325418.png" alt="image-20220403161325418"></p>
<p>​                                                                        flat model</p>
<h3 id="Protected-Flat-Model-受保护的平坦模型"><a href="#Protected-Flat-Model-受保护的平坦模型" class="headerlink" title="Protected Flat Model(受保护的平坦模型)"></a>Protected Flat Model(受保护的平坦模型)</h3><p>受保护的平坦模型与基本平坦模型类似，只是段的限制被设置为只包括物理内存实际存在的的地址范围（见下图）。一个一般保护的异常(#GP)会在任何访问不存在的内存的尝试中产生。这个模型提供了一个最低水平的<br>这种模式提供了最低水平的硬件保护，以防止某些类型的程序错误。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403161745702.png" alt="image-20220403161745702"></p>
<p>​                                                                  Protected Flat Model</p>
<p>更多的复杂性可以被添加到这个受保护的平坦模型中，以提供更多的保护。例如，对于分页机制要在用户和主管的代码和数据之间提供隔离，需要定义四个段。用户的代码和数据段的权限级别为3，而主管的代码和数据段的权限级别为0。通常，这些段都是相互重叠的，并从线性地址空间的地址0开始。这种平坦的分段模型和一个简单的分页结构可以保护操作系统不受应用程序的影响。通过为每个任务或进程增加一个单独的分页结构，它还可以保护应用程序之间的相互影响。类似的设计被几个流行的多任务操作系统所采用。</p>
<h3 id="Multi-Segment-Model-多段模型"><a href="#Multi-Segment-Model-多段模型" class="headerlink" title="Multi-Segment Model(多段模型)"></a>Multi-Segment Model(多段模型)</h3><p>多段模型（如下图）使用分段机制的全部功能，对代码、数据结构、程序和任务提供硬件强制保护。在这里，每个<br>程序（或任务）都有自己的段描述符表和自己的段。这些段可以是对其分配的程序来说是完全私有的，或者在程序之间共享。对所有程序段的访问以及对运行在各个程序上的执行环境都由硬件控制。<br>访问检查不仅可以用来防止引用一个段限制之外的地址，还可以防止在段内进行不允许的操作。例如，由于代码段被指定为只读段，所以可以用硬件来防止向代码段写东西。为段创建的访问权限信息也可以用来设置保护环或保护级别。保护级别可以用来保护操作系统程序免受应用程序的未经授权的访问。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403163121670.png" alt="image-20220403163121670"></p>
<p>​                                                            Multi-Segment Model</p>
<h3 id="Segmentation-in-IA-32e-Mode"><a href="#Segmentation-in-IA-32e-Mode" class="headerlink" title="Segmentation in IA-32e Mode"></a>Segmentation in IA-32e Mode</h3><p>在英特尔64架构的IA-32e模式下，分段的效果取决于处理器是在兼容模式还是64位模式下运行。在兼容模式下，分段的功能就像使用传统的16位或32位保护模式的语义。在64位模式下，分段功能通常被禁用（但不是完全禁用），创建一个平坦的64位线性地址空间。处理器将CS、DS、ES、SS的段基处理为零，创建一个线性地址，等于<br>有效地址。FS和GS段是个例外。这些段寄存器（存放段基）可以作为线性地址计算中的一个额外的基础寄存器。它们有助于寻址本地数据和某些操作系统的数据结构。注意，在64位模式下，处理器在运行时不执行段限制检查。</p>
<h3 id="Paging-and-Segmentation-分页和分段"><a href="#Paging-and-Segmentation-分页和分段" class="headerlink" title="Paging and Segmentation(分页和分段)"></a>Paging and Segmentation(分页和分段)</h3><p>分页可以与上图中描述的任何一种分段模式一起使用。处理器的分页机制将线性地址空间（段被映射到其中）分为若干页。然后这些线性地址空间的页被映射到物理地址空间的页中。分页机制提供了几个页级的保护设施，可以和段保护设施一起使用，也可以代替段保护设施。例如，它允许在逐页的基础上强制执行读写保护。分页 机制还提供了两级用户-监督者保护，也可以在每页的基础上指定。</p>
<h2 id="逻辑地址和线性地址的转换"><a href="#逻辑地址和线性地址的转换" class="headerlink" title="逻辑地址和线性地址的转换"></a>逻辑地址和线性地址的转换</h2><p>注:之前的内容为自己整理，以下为参考指导书翻译</p>
<p>在保护模式下的系统架构层面，处理器使用两个阶段的地址转换来获得物理地址：逻辑地址转换和线性地址空间分页。<br>物理地址：逻辑地址转换和线性地址空间分页。即使对段的使用降到最低，处理器地址空间中的每一个字节都可以用一个逻辑地址来访问。一个逻辑地址包括一个16位的段选择器和一个32位的偏移量。段选择器确定了字节所处的段，偏移量指定了字节在段中相对于该段的基址的位置。处理器将每个逻辑地址转化为一个线性地址。线性地址是处理器线性地址空间中的一个32位地址。像物理地址空间一样，线性地址空间是一个平面的（未分割的）。232字节的地址空间，地址范围从0到FFFFFFFH。线性地址空间包含所有段和为系统定义的系统表。为了将逻辑地址转换为线性地址，处理器做了以下工作：</p>
<ol>
<li>使用段选择器中的偏移量来定位GDT或LDT中段的段描述符，并将其读入处理器。(只有当一个新的段选择器被加载到段寄存器中时才需要这个步骤。）</li>
<li>检查段描述符，以检查段的访问权限和范围，以确保段是可访问的，并且偏移量在段的限制范围内。</li>
<li>将段描述符中的段基地址加到偏移量上，形成一个线性地址。</li>
</ol>
<p>如果不使用分页，处理器将线性地址直接映射到物理地址上。如果线性地址空间被分页，第二层的地址转换被用来将线性地址转换为物理地址。<br><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404154555152.png" alt="image-20220404154555152"></p>
<h3 id="Logical-Address-Translation-in-IA-32e-Mode-IA-32e-模式下的逻辑地址转换"><a href="#Logical-Address-Translation-in-IA-32e-Mode-IA-32e-模式下的逻辑地址转换" class="headerlink" title="Logical Address Translation in IA-32e Mode(IA-32e 模式下的逻辑地址转换)"></a>Logical Address Translation in IA-32e Mode(IA-32e 模式下的逻辑地址转换)</h3><p>在 IA-32e 模式下，Intel 64 处理器使用上述步骤将逻辑地址转换为线性地址。在64位模式下，段的偏移量和基地址是64位而不是32位。线性地址地址格式也是64位宽，并受制于典型形式的要求。每个代码段描述符都提供一个L位。这个位允许一个代码段执行64位代码或传统的32位代码的代码段。</p>
<h3 id="Segment-Selectors-段选择子"><a href="#Segment-Selectors-段选择子" class="headerlink" title="Segment Selectors(段选择子)"></a>Segment Selectors(段选择子)</h3><p>段选择器是一个段的16位标识符（见下图）。它并不直接指向段，而是指向定义该段的段描述符。一个段选择器包含以下内容 ：</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404154957115.png" alt="image-20220404154957115"></p>
<p>​                                                         Segment Selector</p>
<p><strong>索引</strong>（第3至15位）- 在GDT或LDT中选择8192个描述符之一。处理器将索引值乘以8（段描述符中的字节数），并将结果加到GDT或LDT的基址上（分别来自GDTR或LDTR寄存器）。<br><strong>TI（表指示器）标志</strong><br>(Bit 2) - 指定要使用的描述符表：清除该标志选择GDT；设置该标志选择当前的LDT。</p>
<p><strong>要求的权限级别(RPL)</strong><br>(位0和1) - 指定选择器的权限级别。特权级别范围从0到3，其中0为最高权限级别。</p>
<p>GDT的第一个条目不被处理器使用。指向GDT这个条目的段选择器（即索引为0且TI标志设置为0的段选择器）被用作 “空段选择器”。就是说，一个索引为0且TI标志设置为0的段选择器被用作 “空段选择器”。当一个段寄存器（除了CS或SS寄存器）被载入空段选择器时，处理器不会产生一个异常。然而，当一个持有空段选择器的段寄存器被用来访问内存时，它会产生一个异常。空选择器可以用来初始化未使用的段寄存器。用一个空的段选择器加载CS或SS寄存器会导致一个通用的保护机制。段选择器加载CS或SS寄存器会产生一个通用保护异常（#GP）。段落选择器作为指针变量的一部分对应用程序是可见的，但是选择器的值通常是由链接编辑器分配或修改的，而不是应用程序。</p>
<h3 id="Segment-Registers-段寄存器"><a href="#Segment-Registers-段寄存器" class="headerlink" title="Segment Registers(段寄存器)"></a>Segment Registers(段寄存器)</h3><p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404160315942.png" alt="image-20220404160315942"></p>
<p>为了减少地址转换的时间和编码的复杂性，处理器提供了最多容纳6个段选择器的寄存器。这些段寄存器中的每一个都支持一种特定的内存引用(代码、堆栈或数据)。对于几乎任何一种程序的执行，至少要有代码段（CS），数据段（DS）和堆栈段（SS）寄存器且必须被加载有效的段选择器。处理器还提供了三个额外的数据段寄存器（ES、FS和GS），这些寄存器可以用来为当前执行的程序（或任务）提供额外的数据段。</p>
<p>一个程序要访问一个段，该段的段选择器必须被加载到其中一个段寄存器中。因此，尽管一个系统可以定义数以千计的段，但只有6个可以立即使用。其他的段可以通过在程序执行期间将它们的段选择器加载到这些寄存器中来实现。</p>
<p>每个段寄存器都有一个 “可见 “部分和一个 “隐藏 “部分。(隐藏部分有时被称为”描述符缓存 “或 “阴影寄存器”）。当段选择器被加载到段寄存器的可见部分时，处理器也会在段寄存器的隐藏部分加载基础地址、段限制和段描述符的访问控制信息。这些信息来自段选择器所指向的段描述符。缓存在段寄存器中的信息（可见的和隐藏的）允许处理器翻译地址，而不需要花费额外的总线周期来读取基址和限制。<br>系统中，多个处理器可以访问相同的描述符表，当描述符表被修改时，软件有责任重新加载段寄存器。如果不这样做，缓存在段寄存器中的旧的段描述符就可能在其内存驻留版本被修改后被使用。<br>为加载段寄存器提供了两种类型的加载指令:</p>
<ol>
<li><p>直接加载指令，如MOV, POP, LDS, LES, LSS, LGS和LFS指令。这些指令明确地引用段寄存器。</p>
</li>
<li><p>隐含的加载指令，如CALL、JMP和RET指令的远端指针版本，SYSENTER和SYSEXIT指令，以及IRET、INTn、INTO和INT3指令。<br>这些指令改变了CS寄存器的内容（有时也会改变其他段寄存器的内容），这是其操作的附带部分。MOV指令也可以用来将段寄存器的可见部分存储在通用寄存器中。</p>
</li>
</ol>
<h3 id="Segment-Loading-Instructions-in-IA-32e-Mode-IA-32e模式下的段加载指令"><a href="#Segment-Loading-Instructions-in-IA-32e-Mode-IA-32e模式下的段加载指令" class="headerlink" title="Segment Loading Instructions in IA-32e Mode(IA-32e模式下的段加载指令)"></a>Segment Loading Instructions in IA-32e Mode(IA-32e模式下的段加载指令)</h3><p>由于ES、DS和SS段寄存器在64位模式下不被使用，它们在段描述符寄存器中的字段（base, limit, and attribute）被忽略了。某些形式的段装载指令也是无效的（例如LDS, POP ES）。引用ES、DS或SS段的地址计算被视为段基<br>为零。<br>处理器检查所有线性地址引用都是典型的形式，而不是执行极限检查。模式切换并不改变段寄存器或相关描述符寄存器的内容。在64位模式执行过程中，这些寄存器也不会改变，除非执行显式段加载。<br>为了给应用程序设置兼容模式，段加载指令（MOV to Sreg, POP Sreg）在64位模式下正常工作。从系统描述符表（GDT或LDT）中读取一个条目，并加载到段描述符的隐藏部分。描述符寄存器的基数、极限和属性字段都被加载。然而，数据和堆栈段选择器以及描述符寄存器的内容被忽略。<br>当FS和GS段重写在64位模式下使用时，它们各自的基础地址被用于线性地址计算中使用。(FS或GS).base + index + displacement。然后，FS.base和GS.base会被扩展到整个实现所支持的线性地址大小。由此产生的有效地址计算可以跨越正负地址；产生的线性地址必须是规范的。<br>在64位模式下，使用FS段和GS段覆盖的内存访问不会被检查是否有运行时限制也不受属性检查的影响。正常的段加载（MOV to Sreg和POP Sreg）到FS和GS中加载一个在段描述符寄存器的隐藏部分加载一个标准的32位基础值。标准32位以上的基址位以上的基址位被清除为0，以保证使用少于64位的实现方式的一致性。<br>FS.base和GS.base的隐藏描述符寄存器字段被物理映射到MSR，以便加载64位实现支持的所有地址位。64位实现所支持的所有地址位。CPL=0的软件（特权软件）可以使用WRMSR将所有支持的线性地址位加载到FS.base或GS.base。写入64位FS.base和GS.base寄存器中的地址必须是典型的形式。如果WRMSR指令试图向这些寄存器写入非经典地址的WRMSR指令会导致#GP故障。<br>当处于兼容模式时，FS和GS的重写操作与32位模式行为的定义无关。值加载到隐藏描述符寄存器基字段的前32位线性地址位。兼容性模式在计算有效地址时忽略上面的32位。<br>一个新的64位模式指令，SWAPGS，可以用来加载GS base。SWAPGS将IA32_KernelGSbase MSR中的内核数据结构指针与GS base寄存器交换。然后，内核可以使用GS前缀对正常的内存引用来访问内核的数据结构。试图向IA32_KernelGSbase MSR写一个非正则的值（使用WRMSR）会导致一个#GP故障。</p>
<h3 id="Segment-Descriptors-段描述子"><a href="#Segment-Descriptors-段描述子" class="headerlink" title="Segment Descriptors(段描述子)"></a>Segment Descriptors(段描述子)</h3><p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404161935629.png" alt="image-20220404161935629"></p>
<p>段描述符是GDT或LDT中的一个数据结构，为处理器提供段的大小和位置以及访问控制和状态信息。段落描述符通常是由编译器、链接器、加载器、操作系统或执行器，但不是应用程序创建的。</p>
<p>段落描述符中的标志和字段如下:</p>
<p><strong>分段限制字段</strong><br>指定段的大小。处理器把两个段限制字段放在一起，形成一个 一个20位的值。处理器以两种方式之一解释段限制，这取决于G（粒度）标志的设置：</p>
<ul>
<li>如果粒度标志是清除的，段的大小可以从1字节到1MByte，以字节为单位递增。</li>
<li>如果颗粒度标志被设置，段的大小可以从4KB字节到4GB字节，以4KB字节为增量。</li>
</ul>
<p>处理器以两种不同的方式使用段的限制，取决于段是一个向上扩展的段或一个向下扩展的段。对于扩大的段，<br>在逻辑地址中的偏移量可以从0到段的极限范围。大于段限制的偏移量产生一般保护异常（#GP，用于SS以外的所有段）或堆栈故障异常（#SS用于SS段）。对于向下扩展的段，段限具有相反的功能。<br>偏移量可以从段限加1到FFFFFFFH或FFFFFFH，取决于B标志的设置。小于或等于段限制的偏移量产生一般保护异常或堆栈故障异常。减少一个扩展段的段限值字段的值，在段的地址空间的底部分配新的内存，而不是在顶部。<br>IA-32架构的堆栈总是向下增长，使得这种机制对于可扩展堆栈。</p>
<p><strong>基准地址字段</strong><br>定义段的第0字节在4-GByte线性地址空间中的位置。处理器将三个基础地址字段放在一起，形成一个32位的数值。段的基址应与16字节的边界对齐，尽管16字节对齐不是必须的。这种对齐方式允许程序通过在16字节边界上对齐代码和数据来最大限度地提高性能。</p>
<p><strong>类型字段</strong></p>
<p>表示段或门的类型，并指定可以对该段进行的访问类型和增长方向。这个字段的解释取决于描述符类型标志指定的是应用（代码或数据）描述符还是系统描述符。类型字段的类型字段的编码对代码、数据和系统描述符是不同的。</p>
<p><strong>S（描述符类型）标志</strong><br>指定段描述符是用于系统段（S标志为清除）还是用于代码或数据段（S标志为设置）。<br><strong>DPL（描述符权限级别）字段</strong><br>指定段的权限级别。特权级别的范围是0到3，其中0是最高的级别。<br><strong>P（段存在）标志</strong><br>指示段是否存在于内存中（设置）或不存在（清除）。如果这个标志是清除的，当指向段描述符的段选择器出现时，处理器会产生一个段不存在的异常（#NP）。内存管理软件可以使用这个标志来控制哪些段在给定的时间内被实际加载到物理内存中。它为管理虚拟内存提供了一个除分页之外的控制。当该标志被清除时，操作系统或执行程序可以自由地使用标记为 “可用 “的位置来存储自己的数据，例如关于丢失的段的位置的信息。<br><strong>D/B（默认操作大小/默认堆栈指针大小和/或上界）标志</strong><br>执行不同的功能，取决于段描述符是否是可执行的代码段、扩展的数据段、或者是其他的段，一个扩展的数据段，或者一个堆栈段。(对于32位的代码和数据段，这个标志应该总是设置为1，对于16位的代码和数据段，这个标志应该设置为0）。</p>
<ul>
<li>可执行代码段。该标志被称为D标志，它指示了有效地址和操作数的默认长度。如果该标志被设置，32位的地址和32位或8位的操作数；如果它被清除，16位的地址和16位或8位操作数。指令前缀66H可以用来选择默认以外的操作数，而指令前缀67H可以用来选择一个非默认的地址大小。</li>
<li>堆栈段（由SS寄存器指向的数据段）。该标志被称为B（大）标志。它指定了用于隐式堆栈操作的堆栈指针的大小（如push, pops, and calls）。如果该标志被设置，则使用一个32位的堆栈指针，该指针被存储在32位的ESP寄存器中；如果该标志被清除，则使用16位的堆栈指针，该指针被存储在16位的SP寄存器中。如果堆栈段被设置为一个向下扩展的数据段（在下一段中描述下一段描述），B标志也指定了堆栈段的上界。</li>
<li>扩大-缩小数据段。该标志被称为B标志，它指定了段的上限。如果该标志被设置，上界是FFFFFFFH（4GB字节）；如果该标志被清除，上限是FFFFFFFF（64KB）。</li>
</ul>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404164628034.png" alt="image-20220404164628034"></p>
<h2 id="描述符的分类"><a href="#描述符的分类" class="headerlink" title="描述符的分类"></a>描述符的分类</h2><p>段描述符分类</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404171152577.png" alt="image-20220404171152577"></p>
<p>段描述符是GDT和LDT中的一个数据结构项，用于向处理器提供有关一个段的位置、大小以及访问控制的状态信息。每个段描述符的长度是8个字节，含有3个主要字段：</p>
<ul>
<li>段基地址</li>
<li>段限长</li>
<li>段属性</li>
</ul>
<p>段描述符通常由编译器，链接器，加载器或者操作系统来创建，但绝不是应用程序。</p>
<p>段描述符通用格式如下所示</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404170746133.png" alt="image-20220404170746133"></p>
<p>系统段描述符中各个位的含义如下所示</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404170802198.png" alt="image-20220404170802198"></p>
<h3 id="存储段描述符"><a href="#存储段描述符" class="headerlink" title="存储段描述符"></a>存储段描述符</h3><h4 id="数据段描述符"><a href="#数据段描述符" class="headerlink" title="数据段描述符"></a>数据段描述符</h4><p>当S=1且TYPE字段的最高位（第2个双字的位11）为0时，表明是一个数据段描述符。</p>
<p>下图是数据段描述符的格式。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404171430725.png" alt="image-20220404171430725"></p>
<h4 id="代码段描述符"><a href="#代码段描述符" class="headerlink" title="代码段描述符"></a>代码段描述符</h4><p>当S=1且TYPE字段的最高位（第2个双字的位11）为1时，表明是一个代码段描述符。</p>
<p>下图是代码段描述符的格式。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404171452192.png" alt="image-20220404171452192"></p>
<h3 id="系统描述符类型"><a href="#系统描述符类型" class="headerlink" title="系统描述符类型"></a>系统描述符类型</h3><p>当段描述符中S标志位(描述符类型)是复位状态(0)的话，那么该描述符是一个系统描述符。处理器能够识别以下一些类型的系统段描述符:</p>
<ul>
<li>局部描述符表(LDT)的段描述符</li>
<li>任务状态段（TSS）描述符</li>
<li>调用门描述符</li>
<li>中断门描述符</li>
<li>陷阱门描述符</li>
<li>任务门描述符</li>
</ul>
<p>这些描述符类型可分为两大类: 系统段描述符和门描述符。系统段描述符指向系统段(如LDT或TSS段)，门描述符也就是一个”门”,对应调用、中断或陷阱门，其中含有代码段的选择符和段中程序入口点的指针；对于任务门，其中含有TSS的段选择符。</p>
<p>系统段描述符和门描述符类型字段的编码如下所示:</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404170843601.png" alt="image-20220404170843601"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">x86系统架构预览-读书笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-03-28 15:44:58 / Modified: 20:05:31" itemprop="dateCreated datePublished" datetime="2022-03-28T15:44:58+08:00">2022-03-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="x86系统架构概述"><a href="#x86系统架构概述" class="headerlink" title="x86系统架构概述"></a>x86系统架构概述</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>[TOC]</p>
<h2 id="系统级体系架构概述"><a href="#系统级体系架构概述" class="headerlink" title="系统级体系架构概述"></a>系统级体系架构概述</h2><p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328160624845.png" alt="image-20220328160624845"></p>
<h3 id="Global-and-Local-Descriptor-Tables-全局和局部描述符表"><a href="#Global-and-Local-Descriptor-Tables-全局和局部描述符表" class="headerlink" title="Global and Local Descriptor Tables(全局和局部描述符表)"></a>Global and Local Descriptor Tables(全局和局部描述符表)</h3><p>​         当在保护模式下操作时，所有的内存访问都要经过<strong>全局描述符表（GDT）</strong>或可选的<strong>本地描述符表（LDT）</strong>，如图2-1所示。这些表包含的条目描述符称为段 。段描述符提供了段的基本地址以及访问权限、类型和使用信息。<br>​        每个段描述符都有一个相关的段选择器。一个段选择器为使用它的软件提供了 一个GDT或LDT的索引（其相关段描述符的偏移量），一个全局/本地标志（决定选择器是否指向GDT或LDT），以及访问权限信息。<br>​       要访问段中的一个字节，必须提供一个段选择器和一个偏移量。段选择器提供访问该段的段描述符（在GDT或LDT中）。从段描述符中，处理器获得该段在线性地址空间中的基本地址。然后，偏移量提供了字节相对于基址的位置。这种机制可以用来访问任何有效的代码、数据或堆栈段。只要该段可以从处理器所处的当前权限级别（CPL）访问。CPL被定义为当前执行的代码段的保护级别。<br>​       见图2-1。图中的实心箭头表示一个线性地址，虚线表示一个段选择器。而点状箭头表示物理地址。为了简单起见，许多段选择器被显示为 直接指向一个段。然而，从段选择器到其相关段的实际路径总是通过GDT或LDT。GDT的基址的线性地址包含在GDT寄存器（GDTR）中；LDT的线性地址包含在LDT寄存器（LDTR）中。</p>
<h4 id="Global-and-Local-Descriptor-Tables-in-IA-32e-Mode"><a href="#Global-and-Local-Descriptor-Tables-in-IA-32e-Mode" class="headerlink" title="Global and Local Descriptor Tables in IA-32e Mode"></a>Global and Local Descriptor Tables in IA-32e Mode</h4><p>​        GDTR 和 LDTR 寄存器在 IA-32e 子模式（64 位模式和兼容模式）中都被扩展到 64 位宽。全局和局部描述符表在64位模式下被扩展以支持64位基地址，（16字节的LDT 描述符持有一个64位的基本地址和各种属性）。在兼容模式下，描述符不被扩展 。</p>
<h3 id="System-Segments-Segment-Descriptors-and-Gates-系统段，段描述符和门"><a href="#System-Segments-Segment-Descriptors-and-Gates-系统段，段描述符和门" class="headerlink" title="System Segments, Segment Descriptors, and Gates(系统段，段描述符和门)"></a>System Segments, Segment Descriptors, and Gates(系统段，段描述符和门)</h3><p>​       除了构成程序或过程执行环境的代码、数据和堆栈段之外，架构还定义了两个系统段：<strong>任务状态段（TSS）</strong>和<strong>LDT</strong>。GDT不被视为。<br>因为它不是通过段选择器和段描述符访问的。TSSs和LDTs有为它们定义了段描述符。该体系结构还定义了一组特殊的描述符，称为门[调用门（call gates），中断门（interrupt gates），陷阱门（trap gates），和 任务门（task gates）]。这些描述符为系统程序和处理程序提供了受保护的通道，这些程序和处理程序可能在与应用程序不同的权限级别上运行。例如，一个调用门的CALL可以提供访问一个代码段中的程序，该代码段与当前代码段处于相同或更低的权限级别（更多权限）。<br>​        为了通过调用门访问一个过程，调用过程提供了调用门的选择器。然后，处理器对调用门进行访问权限检查，将CPL与调用门和调用门所指向的目标代码段的权限级别进行比较。如果对目标代码段的访问是允许的，处理器就会得到目标代码段的段选择器和该代码段的偏移。如果调用需要改变权限级别，处理器也会切换到目标权限级别的堆栈。新堆栈的段选择器是从当前运行任务的TSS中获得的。门也促进了16位和32位代码段之间的转换，反之亦然。</p>
<h4 id="Gates-in-IA-32e-Mode"><a href="#Gates-in-IA-32e-Mode" class="headerlink" title="Gates in IA-32e Mode"></a>Gates in IA-32e Mode</h4><p>在IA-32e模式下，以下描述符是16字节的描述符（扩大到允许64位基数）。LDT描述符、64位TSS、调用门、中断门和陷阱门。调用门促进了64位模式和兼容模式之间的转换。在IA32e模式下不支持任务门。在权限级别改变时，堆栈段选择器不从TSS中读取。相反，它们被设置为NULL。</p>
<h3 id="Task-State-Segments-and-Task-Gates-任务状态段任务门"><a href="#Task-State-Segments-and-Task-Gates-任务状态段任务门" class="headerlink" title="Task-State Segments and Task Gates(任务状态段任务门)"></a>Task-State Segments and Task Gates(任务状态段任务门)</h3><p>​       TSS（见图2-1）定义了一个任务的执行环境的状态。它包括通用寄存器、段寄存器、EFLAGS寄存器、EIP寄存器和段选择器的状态-指向三个堆栈段（每个权限级别有一个堆栈）。TSS还包括段选择器 ，用于与任务相关的LDT和分页结构层次的基址。<br>​       所有受保护模式下的程序执行都发生在一个任务（称为当前任务）的上下文中。<br>​      当前任务的TSS的段选择器被存储在任务寄存器中。最简单的切换方法是调用或跳转到一个新的任务。这里，新任务的TSS的段选择器是在CALL或JMP指令中给出的。在切换任务时，处理器会执行以下动作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 将当前任务的状态存储在当前TSS中。</span><br><span class="line">2. 用新任务的段选择器加载任务寄存器。</span><br><span class="line">3. 通过GDT中的段描述符访问新的TSS。</span><br><span class="line">4. 将新任务的状态从新的TSS加载到通用寄存器、段寄存器中、LDTR，控制寄存器CR3（分页结构层次的基址），EFLAGS寄存器，以及EIP寄存器。</span><br><span class="line">5. 开始执行新的任务。一个任务也可以通过一个任务门来访问。任务门类似于调用门，只是它提供了访问 (通过段选择器)访问一个TSS而不是一个代码段。</span><br></pre></td></tr></table></figure>
<h4 id="Task-State-Segments-in-IA-32e-Mode"><a href="#Task-State-Segments-in-IA-32e-Mode" class="headerlink" title="Task-State Segments in IA-32e Mode"></a>Task-State Segments in IA-32e Mode</h4><p>在IA-32e模式下不支持硬件任务开关。然而，TSSs继续存在。TSS的基本地址由其描述符指定。一个64位的TSS持有以下对64位操作很重要的信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 每个特权级别的堆栈指针地址</span><br><span class="line">- 中断堆栈表的指针地址</span><br><span class="line">- IO-permission位图的偏移地址（从TSS基数开始）。</span><br><span class="line">  在IA-32e模式下，任务寄存器被扩展为容纳64位基址。</span><br></pre></td></tr></table></figure>
<h3 id="Interrupt-and-Exception-Handling-中断和异常处理"><a href="#Interrupt-and-Exception-Handling-中断和异常处理" class="headerlink" title="Interrupt and Exception Handling(中断和异常处理)"></a>Interrupt and Exception Handling(中断和异常处理)</h3><p>​          外部中断、软件中断和异常是通过中断描述符表（IDT）处理的。IDT存储了一个门描述符的集合，提供对中断和异常处理程序的访问。与 GDT一样，IDT不是一个段。IDT基础的线性地址包含在IDT寄存器（IDTR）中。IDT中的门描述符可以是中断、陷阱、或任务门描述符。要访问一个中断或异常处理程序 ，处理器首先从内部硬件、外部中断控制器或软件中接收一个中断向量（中断号）。中断控制器，或通过INT、INTO、INT 3或BOUND指令从软件接收一个中断向量（中断号）。中断向量 提供了一个进入IDT的索引。如果选择的门描述符是一个中断门或陷阱门，相关的处理程序就会被访问。处理程序的访问方式与通过调用门调用程序的方式类似。如果描述符是一个<br>任务门，处理程序将通过一个任务开关被访问。</p>
<h4 id="Interrupt-and-Exception-Handling-IA-32e-Mode"><a href="#Interrupt-and-Exception-Handling-IA-32e-Mode" class="headerlink" title="Interrupt and Exception Handling IA-32e Mode"></a>Interrupt and Exception Handling IA-32e Mode</h4><p>在IA-32e模式下，中断描述符被扩展到16个字节，以支持64位基本地址。IDTR寄存器被扩展为容纳64位基地址。不支持任务门。</p>
<h3 id="Memory-Management-内存管理"><a href="#Memory-Management-内存管理" class="headerlink" title="Memory Management(内存管理)"></a>Memory Management(内存管理)</h3><p>​        系统架构支持内存的直接物理寻址或虚拟内存（通过分页）。<br>​        当使用物理寻址时，线性地址被当作物理地址处理。当使用分页时：所有的代码、数据、堆栈和系统段（包括GDT和IDT）可以被分页，只有最近访问的 页被保存在物理内存中。物理内存中的页面（有时称为页框）的位置包含在分页结构中。这些结构位于物理内存中。<br>​        分页结构层次结构的基本物理地址包含在控制寄存器CR3中。分页结构中的条目决定了 一个分页框的物理地址、访问权限和内存管理信息。为了使用这种分页机制，一个线性地址被分解成几个部分。这些部分提供了进入分页结构和页框的单独偏移。一个系统可以有一个单一的分页结构层次，也可以有几个。例如 ，每个任务可以有自己的层次结构。</p>
<h4 id="Memory-Management-in-IA-32e-Mode"><a href="#Memory-Management-in-IA-32e-Mode" class="headerlink" title="Memory Management in IA-32e Mode"></a>Memory Management in IA-32e Mode</h4><p>在IA-32e模式下，物理内存页由一组系统数据结构管理。在兼容模式 和64位模式下，使用四级系统数据结构。这些结构包括 ：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 第4级页面映射（PML4）--PML4表中的一个条目包含了一个页面的基点的物理地址目录指针表、访问权限和内存管理信息。PML4的基本物理地址被存储在CR3中。</span><br><span class="line">- 一组页目录指针表 - 页目录指针表中的一个条目包含了页目录指针表基的物理地址。</span><br><span class="line">- 一组页目录 - 页目录表中的一个条目包含了一个页目录表基的物理地址、访问权限和内存管理信息。</span><br><span class="line">- 成套的页表 - 一个页表中的条目包含了一个页框的物理地址，访问权限和内存管理信息。</span><br></pre></td></tr></table></figure>
<h3 id="System-Registers-系统寄存器"><a href="#System-Registers-系统寄存器" class="headerlink" title="System Registers(系统寄存器)"></a>System Registers(系统寄存器)</h3><p>为了帮助初始化处理器和控制系统操作，系统结构在EFLAGS寄存器中提供了系统标志和几个系统寄存器：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- EFLAGS寄存器中的系统标志和IOPL字段控制任务和模式的切换，中断处理，指令跟踪和访问权限。</span><br><span class="line">- 控制寄存器（CR0、CR2、CR3和CR4）包含各种控制系统级操作的标志和数据域。这些寄存器中的其他标志被用来表示对操作系统或执行器中特定处理器能力的支持。</span><br><span class="line">- 调试寄存器允许设置断点以用于调试程序和系统软件。</span><br><span class="line">- GDTR、LDTR和IDTR寄存器包含了它们各自表的线性地址和大小（限制）。</span><br><span class="line">- 任务寄存器包含了当前任务的线性地址和TSS的大小。</span><br><span class="line">- 特定型号的寄存器。这些寄存器控制一些项目，如调试扩展。</span><br><span class="line">  这些寄存器的数量和功能在英特尔64和IA-32处理器系列的不同成员中是不同的。</span><br></pre></td></tr></table></figure>
<h4 id="System-Registers-in-IA-32e-Mode"><a href="#System-Registers-in-IA-32e-Mode" class="headerlink" title="System Registers in IA-32e Mode"></a>System Registers in IA-32e Mode</h4><p>​        在IA-32e模式下，四个系统描述符表寄存器（GDTR、IDTR、LDTR和TR）在硬件上被扩展为<br>以容纳64位的基本地址。EFLAGS成为64位的RFLAGS寄存器。CR0-CR4被扩展到64位。CR8变得可用。CR8提供了对任务优先级寄存器（TPR）的读写访问，这样操作系统就可以控制外部设备的优先级。在64位模式下，调试寄存器DR0-DR7为64位。在兼容模式下，DR0-DR3的地址匹配也是以64位粒度进行的。在支持IA-32e模式的系统上，扩展功能启用寄存器（IA32_EFER）是可用的。这个特定型号的寄存器控制IA-32e模式的激活和其他IA-32e模式的操作。此外，还有几个特定型号的寄存器管理 IA-32e 模式指令。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- IA32_KernelGSbase - 由 SWAPGS 指令使用。</span><br><span class="line">- IA32_LSTAR - 由 SYSCALL 指令使用。</span><br><span class="line">- IA32_SYSCALL_FLAG_MASK - 由SYSCALL指令使用。</span><br><span class="line">- IA32_STAR_CS - 由SYSCALL和SYSRET指令使用。</span><br></pre></td></tr></table></figure>
<h3 id="Other-System-Resources"><a href="#Other-System-Resources" class="headerlink" title="Other System Resources"></a>Other System Resources</h3><p>除了前几节描述的系统寄存器和数据结构，系统结构还提供了以下的额外资源。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 操作系统指令</span><br><span class="line">- 性能监测计数器</span><br><span class="line">- 内部缓存和缓冲区</span><br><span class="line">  等</span><br></pre></td></tr></table></figure>
<h2 id="实模式和保护模式转换"><a href="#实模式和保护模式转换" class="headerlink" title="实模式和保护模式转换"></a>实模式和保护模式转换</h2><p>二者根本区别为：进程内存受保护与否</p>
<p> 保护模式 - 这是处理器的原生操作模式。它提供了一套丰富的结构特性、灵活性、高性能和对现有软件基础的向后兼容性。</p>
<p>真实地址模式 - 这种操作模式提供了英特尔8086处理器的编程环境，并有一些扩展（如切换到受保护或系统管理模式的能力）。</p>
<h3 id="实模式工作原理"><a href="#实模式工作原理" class="headerlink" title="实模式工作原理"></a>实模式工作原理</h3><p>实模式出现于早期8088CPU时期。当时由于CPU的性能有限，一共只有20位地址线（所以地址空间只有1MB），以及8个16位的通用寄存器，以及4个16位的段寄存器。所以为了能够通过这些16位的寄存器去构成20位的主存地址，必须采取一种特殊的方式。当某个指令想要访问某个内存地址时，它通常需要用下面的这种格式来表示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(段基址：段偏移量)</span><br></pre></td></tr></table></figure>
<p>其中第一个字段是段基址，它的值是由段寄存器提供的。</p>
<p>第二字段是段内偏移量，代表你要访问的这个内存地址距离这个段基址的偏移。它的值就是由通用寄存器来提供的，所以也是16位。</p>
<p>CPU采用把段寄存器所提供的段基址先向左移4位。这样就变成了一个20位的值，然后再与段偏移量相加，即可组合成一个二十位的地址。即：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">物理地址 = 段基址&lt;&lt;4 + 段内偏移</span><br></pre></td></tr></table></figure>
<h3 id="保护模式工作原理"><a href="#保护模式工作原理" class="headerlink" title="保护模式工作原理"></a>保护模式工作原理</h3><p>随着CPU的发展，CPU的地址线的个数也从原来的20根变为现在的32根，所以可以访问的内存空间也从1MB变为现在4GB，寄存器的位数也变为32位。所以实模式下的内存地址计算方式就已经不再适合了。所以就引入了现在的保护模式，实现更大空间的，更灵活也更安全的内存访问。</p>
<p>在保护模式下，CPU的32条地址线全部有效，可寻址高达4G字节的物理地址空间; 但是我们的内存寻址方式还是得兼容老办法，即(段基址：段偏移量)的表示方式。当然此时CPU中的通用寄存器都要换成32位寄存器(除了段寄存器)来保证寄存器能访问所有的4GB空间。</p>
<p>我们的偏移值和实模式下是一样的，就是变成了32位而已，而段值仍旧是存放在原来16位的段寄存器中，但是这些段寄存器存放的却不再是段基址了，毕竟之前说过实模式下寻址方式不安全，我们在保护模式下需要加一些限制，而这些限制可不是一个寄存器能够容纳的，于是我们把这些关于内存段的限制信息放在一个叫做<strong>全局描述符表(GDT)</strong>的结构里。全局描述符表中含有一个个表项，每一个表项称为<strong>段描述符。</strong>而段寄存器在保护模式下存放的便是相当于一个数组索引的东西，通过这个索引，可以找到对应的表项。段描述符存放了段基址、段界限、内存段类型属性(比如是数据段还是代码段,注意<strong>一个段描述符只能用来定义一个内存段</strong>)等许多属性,具体信息见下图：</p>
<p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328193206147.png" alt="image-20220328193206147"></p>
<p>其中，段界限表示段边界的扩张最值，即最大扩展多少或最小扩展多少，用20位来表示，它的单位可以是字节，也可以是4KB，这是由G位决定的(G为1时表示单位为4KB)。</p>
<p>实际段界限边界值=(描述符中的段界限+1)*（段界限的单位大小(即字节或4KB))-1，如果偏移地址超过了段界限，CPU会抛出异常。</p>
<p>全局描述符表位于内存中，需要用专门的寄存器指向它后， CPU 才知道它在哪里。这个专门的寄存器便是<strong>GDTR</strong>(一个48位的寄存器),专门用来存储 GDT 的内存地址及大小。</p>
<p>还需要介绍一个新的概念：段的选择子。段寄存器 CS、 DS、 ES、 FS、 GS、 SS，在实模式下时，段中存储的是段基地址，即内存段的起始地址。 而在保护模式下时，由于段基址已经存入了段描述符中，所以段寄存器中再存放段基址是没有意义的，在段寄存器中存入的是一个叫作选择子的东西。选择子“基本上”是个索引值。由于段寄存器是 16 位，所以选择子也是 16 位，在其低 2 位即第 0～1 位， 用来存储 RPL，即请求特权级，可以表示 0、 1、 2、 3 四种特权级。在选择子的第 2 位是 TI 位，即 Table Indicator，用来指示选择子是在 GDT 中，还是 LDT 中索引描述符。 TI 为 0 表示在 GDT 中索引描述符， TI 为 1 表示在 LDT 中索引描述符。选择子的高 13 位，即第 3～15 位是 描述符的索引值，用此值在 GDT 中索引描述符。前面说过 GDT 相当于一个描述符数组，所以此选择子中的索引值就是 GDT 中的下标。选择子结构如下：</p>
<p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328193601767.png" alt="image-20220328193601767"></p>
<p>此外， 扩充的存储器分段管理机制和可选的存储器分页管理机制，不仅为存储器共享和保护提供了硬件支持，而且为实现虚拟存储器提供了硬件支持; 支持多任务，能够快速地进行任务切换(switch)和保护任务环境(context); 4个特权级和完善的特权检查机制，既能实现资源共享又能保证代码和数据的安全和保密及任务的隔离; 支持虚拟8086方式，便于执行8086程序。</p>
<h3 id="实模式到保护模式的切换"><a href="#实模式到保护模式的切换" class="headerlink" title="实模式到保护模式的切换"></a>实模式到保护模式的切换</h3><p>从实模式切换到保护模式大致可以分为以下几个步骤：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、屏蔽中断</span><br><span class="line"></span><br><span class="line">2、初始化全局描述符表（GDT）</span><br><span class="line"></span><br><span class="line">3、将CR0寄存器最低位置1</span><br><span class="line"></span><br><span class="line">4、执行远跳转</span><br><span class="line"></span><br><span class="line">5、初始化段寄存器和栈指针</span><br></pre></td></tr></table></figure>
<h4 id="屏蔽中断"><a href="#屏蔽中断" class="headerlink" title="屏蔽中断"></a>屏蔽中断</h4><p>在16位实模式下的中断由BIOS处理，进入保护模式后，中断将交给中断描述符表IDT里规定的函数处理，在刚进入保护模式时IDTR寄存器的初始值为0，一旦发生中断（例如BIOS的时钟中断）就将导致CPU发生异常，所以需要首先屏蔽中断。屏蔽中断可以使用cli指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cli</span><br></pre></td></tr></table></figure>
<h4 id="初始化GDT"><a href="#初始化GDT" class="headerlink" title="初始化GDT"></a>初始化GDT</h4><p>在32位保护模式中，段与段之间是互相隔离的，当访问的地址超出段的界限时处理器就会阻止这种访问，因此每个段都需要有起始地址、范围、访问权限以及其他属性四个部分，这四个部分合在一起叫做段描述符（Segment Descriptor），总共需要8个字节来描述。但Intel为了保持向后兼容，将段寄存器仍然规定为16-bit，显然我们无法用16-bit的段寄存器来直接存储64-bit的段描述符。 </p>
<p>解决的办法是将所有64-bit的段描述符放到一个数组中，将16-bit段寄存器的值作为下标来访问这个数组（以字节为单位），获取64-bit的段描述符，这个数组就叫是全局描述符表</p>
<h4 id="将CR0最低位置1"><a href="#将CR0最低位置1" class="headerlink" title="将CR0最低位置1"></a>将CR0最低位置1</h4><p>CR0是系统内的32位控制寄存器之一，可以控制CPU的一些重要特性。其中最低位是保护允许位（Protected Mode Enable, PE），PE位置1后CPU进入保护模式（注意此时还是16位保护模式，不是32位保护模式），置0时则为实模式。现在我们要进入保护模式，即将CR0的最低位置1，汇编代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-把 cr0 的最低位置为 1，开启保护模式</span><br><span class="line">mov eax, cr0</span><br><span class="line">or eax, 0x1</span><br><span class="line">mov cr0, eax</span><br></pre></td></tr></table></figure>
<h4 id="执行远跳转"><a href="#执行远跳转" class="headerlink" title="执行远跳转"></a>执行远跳转</h4><p>将cr0最低位置1后，CPU就进入了保护模式，此时需要马上执行一条远跳转指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmp 08h:PModeMain</span><br></pre></td></tr></table></figure>
<p>这条指令有两个作用，第一个作用是将cs段寄存器的值修改为08h，切换到保护模式后，CPU寻址的方式就从实模式中的段地址 * 16 + 偏移地址改为了通过gdt寻址，所以这里的08h是段选择子而不是段地址，并且远跳转指令会自动将cs的值修改为对应的段选择子，这里是08h。</p>
<p>远跳转的另一个作用是清空CPU的流水线，流水线的作用在计组中有提到过，为了加速指令的执行，CPU在执行当前指令时会同时加载并解析接下来的一些指令，在进入保护模式之前，已经有许多指令进入了流水线，这些指令都是按16位模式处理的，而进入保护模式后的指令都是32位，所以这里通过一个远跳转来让CPU清空流水线。</p>
<p>切换到32位模式后，就应该执行32位的指令了，所以从PModeMain开始的指令都采用32位模式编译，通过[bits 32]这个标记实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[bits 32]</span><br><span class="line">PModeMain:</span><br></pre></td></tr></table></figure>
<h4 id="初始化段寄存器和栈指针"><a href="#初始化段寄存器和栈指针" class="headerlink" title="初始化段寄存器和栈指针"></a>初始化段寄存器和栈指针</h4><p>上一步中我们将代码段寄存器cs初始化成了0x08，现在我们还需要初始化其他的段寄存器如数据段寄存器ds，拓展段寄存器es，栈段ss以及fs，gs两个由操作系统使用的段。 </p>
<p>另外我们还需要初始化栈指针ebp和esp，代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[bits 32]</span><br><span class="line">PModeMain:</span><br><span class="line">    mov ax, 0x10        ; 将数据段寄存器ds和附加段寄存器es置为0x10</span><br><span class="line">    mov ds, ax         </span><br><span class="line">    mov es, ax</span><br><span class="line">    mov fs, ax          ; fs和gs寄存器由操作系统使用，这里统一设成0x10</span><br><span class="line">    mov gs, ax</span><br><span class="line">    mov ax, 0x18        ; 将栈段寄存器ss置为0x18</span><br><span class="line">    mov ss, ax</span><br><span class="line">    mov ebp, 0x7c00     ; 现在栈顶指向 0x7c00</span><br><span class="line">    mov esp, ebp</span><br></pre></td></tr></table></figure>
<h3 id="需要修改的内容"><a href="#需要修改的内容" class="headerlink" title="需要修改的内容"></a>需要修改的内容</h3><ul>
<li><p>GDT初始化：定义段描述符、定义GDTR的数据结构、定义GDT选择子</p>
</li>
<li><p>数据段+堆栈段</p>
</li>
<li><p>16位代码段（实模式下）的定义</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.设置代码运行环境，即给相关寄存器赋值；</span><br><span class="line">2.初始化16位代码段描述符 + 32位代码段描述符 + 堆栈段描述符 +数据段描述符；</span><br><span class="line">3.初始化全局描述符表寄存器GDTR的内容，因为其基地址还没有初始化， 然后通过lgdt [GdtPtr]，将内存中GDTR的内容加载到GDTR中，重点在于保存 GDT的基地址；</span><br><span class="line">4.关中断， 即设置CPU不响应任何其他的外部中断，因为CPU现在的时间片只属于当前加载的程序；</span><br><span class="line">5.打开地址线A20；</span><br><span class="line">6将CR0的 PE 位置1；PE位==1，表明CPU运行在保护模式下；</span><br><span class="line">7.跳转到保护模式： jmp dword SelectorCode32:0 ，这里的代码指提供了选择子，（2.3）末部分，已经说明了为什么通过选择子就可以索引到 32位代码段 LABEL_SEG_CODE32；（这就是从实模式跳入保护模式）</span><br></pre></td></tr></table></figure>
</li>
<li><p>32位代码段（由实模式跳入，即保护模式）的定义</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.将对应选择子赋值到 对应寄存器， 即设置任务代码的运行环境，不得不提的是本段代码还改变了ss和esp，则在32位代码段中所有的堆栈操作将会在新增的堆栈段中进行；</span><br><span class="line">2.做任务；</span><br><span class="line">3.任务做完后，跳转到16位代码段，因为从保护模式跳回实模式，只能从16位代码段中跳回；</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="80x86系统指令寄存器"><a href="#80x86系统指令寄存器" class="headerlink" title="80x86系统指令寄存器"></a>80x86系统指令寄存器</h2><h3 id="标志寄存器"><a href="#标志寄存器" class="headerlink" title="标志寄存器"></a>标志寄存器</h3><p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328194436597.png" alt="image-20220328194436597"></p>
<p>  EFLAGS系统标志和IOPL字段控制I/O，可屏蔽的硬件中断、调试、任务切换和虚拟8086模式。仅允许特权代码（通常为操作系统过执行代码）修改这些位。</p>
<p>​       在64位模式下，RFLAGS寄存器扩展为64位，保留高32位。PFLAGS中系统标志（64位模式）或EFLAGS（兼容模式）。在IA-32e模式下，处理器不允许设置VM位，因为不支持virtual-8086模式（尝试设置该位将被忽略）。同样，处理器将不会设置NT位。但是处理器确实允许软件将NT位置1（请注意，如果将NT位置1，则IRET会在IA-32e模式下引起一般性保护故障）。在IA-32e模式下，YSCALL/SYSRET指令具有一种可编程的方法来指定哪些位是已RFLAGS/EFLAGS中清除。这些说明保存/恢复EFLAGS/RFLAGS。</p>
<h3 id="内存管理寄存器"><a href="#内存管理寄存器" class="headerlink" title="内存管理寄存器"></a>内存管理寄存器</h3><p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328194633100.png" alt="image-20220328194633100"></p>
<h4 id="GDTR"><a href="#GDTR" class="headerlink" title="GDTR"></a>GDTR</h4><p>保存基地址（在保护模式下为32位，在IA-32e模式下为64位）和16位表GDT的限制。基地址指定GDT字节0的线性地址；表格限制指定了表中的字节数。LGDT和SGDT指令分别加载和存储GDTR寄存器。开机或重置在处理器中，基地址设置为默认值0，限制设置为0FFFFH。必须有新的基本地址将其作为保护模式操作的处理器初始化过程的一部分加载的GDTR。</p>
<h4 id="LDTR"><a href="#LDTR" class="headerlink" title="LDTR"></a>LDTR</h4><p>​       保留16位段选择器的结伴地址（在保护模式下为32位，在IA-32e模式下为64位）段限制和LDT的描述符属性。基地址指定字节的线性地址LDT段的0，段限制指定段中的字节数。LLDT和SLDT指令分别加载和存储LDTR寄存器的段选择器部分的包含LDT的段必须在GDT中具有段描述符。当LLDT指令加载一个LDTR中的段选择器：LDT描述符中的基地址、限制和描述符属性会自动加载到LDTR中。<br>​       发生任务切换时，LDTR会自动加载LDT的段选择器和描述符为新任务。在写入新的LDT信息之前，不会自动保存LDTR的内容进入寄存器。在处理器加电或重置时，段选择器和基地址被设置为默认值0和限制设置为0FFFFH。</p>
<h4 id="IDTR"><a href="#IDTR" class="headerlink" title="IDTR"></a>IDTR</h4><p>​        寄存器保存基地址（保护模式下为32位，IA-32e模式下为64位）和16位表限制IDT。基地址指定IDT字节0的线性地址，表限制指定数量表中的字节数。LIDT和SIDT指令分别加载和存储IDTR寄存器。开机或重置处理器后，基地址设置为默认值0，限制设置为0FFFFH。然后可以在处理器初始化过程中更改寄存器中的地址和限制。</p>
<h4 id="TR"><a href="#TR" class="headerlink" title="TR"></a>TR</h4><p>​        任务寄存器包含16位段选择器，基地址（在保护模式下为32位，在IA-32e中为64位），段限制和当前任务的TSS的描述符属性。选择器引用TSS、GDT的描述符。基地址指定TSS字节0的线性地址；段限制指定TSS中的字节数。LTR和STR指令分别加载和存储任务寄存器的段选择器部分。当LTR指令将段选择器加载到任务寄存器中时，基址、限制和描述符属性从TSS描述符将自动加载到任务寄存器中。处理器加电或重置时，基地址设置为默认值0，限制设置为0FFFFH。发生任务切换时，任务寄存器会自动加载段选择器和描述符新任务的TSS。在写入的新的TSS之前，不会自动保存任务寄存器的内容信息进去寄存器。</p>
<h3 id="控制寄存器"><a href="#控制寄存器" class="headerlink" title="控制寄存器"></a>控制寄存器</h3><h4 id="CR0"><a href="#CR0" class="headerlink" title="CR0"></a>CR0</h4><p>包含控制处理器的操作模式和状态的系统控制标志。</p>
<h4 id="CR3"><a href="#CR3" class="headerlink" title="CR3"></a>CR3</h4><p>包含分页结构层次结构基础的物理地址和两个标志（PCD和PWT）。仅指定基址的最高有效位（减去低12位）；低12位地址“0”假定为0.因此，第一个分页结构必须与页面（4KB）对齐边界。PCT和PWT标志控制处理器内部数据中该分页结构的缓存（它们不控制页面目录信息的TLB缓存）。使用物理地址扩展中，CR3寄存器包含页面目录指针表的基地址。在IA-32e模式下，CR3寄存器包含PML4表的基地址。</p>
<h2 id="系统指令"><a href="#系统指令" class="headerlink" title="系统指令"></a>系统指令</h2><p>LGDT加载GDTR寄存器——将GDT基址和限制从内存加载到GDTR寄存器。<br>SGDT存储GDTR寄存器——将GDT基址和GDTR寄存器中的限制存储到内存。<br>LIDT加载IDTR寄存器——将IDT基址和限制从存储器加载到IDTR寄存器中。<br>SIDT加载IDTR寄存器——将IDT寄存器的IDT基址和限制存储到内存中。<br>LLDT加载LDT寄存器——将LDT段选择器和段描述符从内存加载到LDTR，段选择器操作数也可以位于通用寄存器中。<br>SLDT存储LDT寄存器——将LDTR寄存器中的LDT段选择器存储到存储器或存储器中。<br>LTR记载任务寄存器——将TSS的段选择器和段描述符从内存加载到任务寄存器，段选择器操作数也可以位于通用寄存器中。<br>STR存储任务寄存器——将当前任务TSS的段选择器从任务存储器存储到存储器或通用寄存器。</p>
<h2 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://zhuanlan.zhihu.com/p/42309472</span><br><span class="line">https://mp.weixin.qq.com/s/VGhpbZaeyVwq3Ghs2E6eEw</span><br><span class="line">https://zhuanlan.zhihu.com/p/412845339</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/" class="post-title-link" itemprop="url">解决广告弹窗</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-03-12 20:00:20 / Modified: 20:25:48" itemprop="dateCreated datePublished" datetime="2022-03-12T20:00:20+08:00">2022-03-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="解决广告弹窗"><a href="#解决广告弹窗" class="headerlink" title="解决广告弹窗"></a>解决广告弹窗</h1><p>对于广告弹窗，我们采取安装火绒安全软件的方式来解决。具体流程如下</p>
<p>打开网站</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.huorong.cn/</span><br></pre></td></tr></table></figure>
<p><img src="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/image-20220312201421955.png" alt="image-20220312201421955"></p>
<p>点击上方一栏的个人产品</p>
<p><img src="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/image-20220312201439903.png" alt="image-20220312201439903"></p>
<p>点击免费下载</p>
<p>下载安装等步骤正常进行。</p>
<p>安装好之后如下</p>
<p><img src="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/image-20220312201528490.png" alt="image-20220312201528490"></p>
<p>点击安全工具</p>
<p>点击右上方的弹窗拦截</p>
<p><img src="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/image-20220312201548894.png" alt="image-20220312201548894"></p>
<p>注：首次点击需要应该需要下载，为正常现象。</p>
<p>到此工作完成。</p>
<p>注：完成之后建议把其他杀毒软件全部卸载。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/02/21/CTR%E5%B7%A5%E4%BD%9C%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/21/CTR%E5%B7%A5%E4%BD%9C%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">CTR工作介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-02-21 17:42:21" itemprop="dateCreated datePublished" datetime="2022-02-21T17:42:21+08:00">2022-02-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-02-22 09:12:54" itemprop="dateModified" datetime="2022-02-22T09:12:54+08:00">2022-02-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="中文"><a href="#中文" class="headerlink" title="中文"></a>中文</h2><p>点击率（CTR）的预测在网络广告中至关重要[McMahan等人，2013[1]；Juan等人，2016[2]；Wen等人，2019[3]]，其中的任务是估计用户点击推荐广告或物品的概率。在在线广告中，广告商向出版商付费，在出版商的网站上展示他们的广告。一种流行的支付模式是每次点击成本（CPC）模式[Zhou等人，2018[4]；Zhou等人，2019[5]]，广告商只有在点击发生时才会被收费。因此，出版商的收入在很大程度上依赖于准确预测CTR的能力[Wang等人，2017[6]] 。</p>
<p>如今，各种CTR模型层出不穷，从 Linear到 TreeBased ，再到Embedding和MLP，随着深度学习网络的推进，CTR模型也得到了充分的发展。每个模型都有其优点，例如自适应因子化网络（AFN）可以从数据中自适应地学习任意等级的交叉特征，双输入感知因式分解机（DIFM）能在矢量级有效地学习输入感知因子（用于重新加权原始特征表示）。但是CTR预测的情况总是多种多样，有时我们会面临大量的用户数据需要快速处理，有时又会缺乏用户历史信息而面临冷启动的问题。没有一种CTR模型会很好地适应所有的情况。</p>
<p>基于自动机器学习的启发，我们将创建一个CTR库，里面包含着目前世界上表现优异的各种CTR模型。主要根据预测时所面临的情况，根据传入的参数，来自适应地判断并且选择适当的CTR模型进行预测，以此来提高预测精度，缩短预测时间，最大化企业效率。</p>
<p>[1] [McMahan et al., 2013] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al. Ad click prediction: a view from the trenches. In <em>Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, pages 1222–1230. ACM, 2013.</p>
<p>[2] [Juan et al., 2016] Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. Field-aware factorization machines for ctr prediction. In <em>Proceedings of the 10th ACM Conference on Recommender Systems</em>, pages 43–50. ACM, 2016.</p>
<p>[3] [Wen et al., 2019] Hong Wen, Jing Zhang, Quan Lin, Keping Yang, and Pipei Huang. Multi-level deep cascade trees for conversion rate prediction in recommendation system. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 33, pages 338–345, 2019</p>
<p>[4] [Zhou et al., 2018] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. Deep interest network for click-through rate prediction. In <em>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, pages 1059–1068. ACM, 2018.</p>
<p>[5] [Zhou et al., 2019] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. Deep interest evolution network for click-through rate prediction. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 33, pages 5941–5948, 201</p>
<p>[6] [Wang et al., 2017] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. Deep &amp; cross network for ad click predictions. In <em>Proceedings of the ADKDD’17</em>, page 12. ACM, 2017.</p>
<h2 id="英文"><a href="#英文" class="headerlink" title="英文"></a>英文</h2><p>The prediction of click-through rate (CTR) is crucial in online advertising [McMahan et al., 2013[1]; Juan et al., 2016[2]; Wen et al., 2019[3]], where the mission is to estimate the probability that users click on a recommended ad or item. In online advertising, advertisers pay publishers to display their ads on publishers’ sites. One popular payment model is the cost-per-click (CPC) model [Zhou et al., 2018[4]; Zhou et al., 2019[5]], where advertisers are charged only when a click occurs. As a consequence, a publisher’s revenue relies heavily on the ability to predict CTR accurately [Wang et al., 2017[6]].</p>
<p>Nowadays, various CTR models have emerged, from Linear to TreeBased , to Embedding and MLP. With the advancement of deep learning networks, the CTR model has also been fully developed. Each model has its merits. For Instance, Adaptive Factorization Network (AFN) can adaptively learn cross features of any level from data, and Dual Input Perceptual Factorization Machine (DIFM) can effectively learn input perception factors at vector level (used to reweight original feature representations). Nevertheless, there are always various situations for CTR prediction. We are faced with a large amount of user data that needs to be processed quickly at times, and a cold boot due to the lack of user history information at others.  There is no CTR model that fits well in all situations.</p>
<p>Inspired by automated machine learning, we will create a CTR library containing a variety of CTR models that are currently performing well in the world. Based on the incoming parameters, we will self-adaptively determine and select the appropriate CTR model for forecasting according to the situation, in order to improve forecasting accuracy, shorten forecasting time, and maximize business efficiency.</p>
<p>[1] [McMahan et al., 2013] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al. Ad click prediction: a view from the trenches. In <em>Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, pages 1222–1230. ACM, 2013.</p>
<p>[2] [Juan et al., 2016] Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. Field-aware factorization machines for ctr prediction. In <em>Proceedings of the 10th ACM Conference on Recommender Systems</em>, pages 43–50. ACM, 2016.</p>
<p>[3] [Wen et al., 2019] Hong Wen, Jing Zhang, Quan Lin, Keping Yang, and Pipei Huang. Multi-level deep cascade trees for conversion rate prediction in recommendation system. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 33, pages 338–345, 2019</p>
<p>[4] [Zhou et al., 2018] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. Deep interest network for click-through rate prediction. In <em>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, pages 1059–1068. ACM, 2018.</p>
<p>[5] [Zhou et al., 2019] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. Deep interest evolution network for click-through rate prediction. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 33, pages 5941–5948, 201</p>
<p>[6] [Wang et al., 2017] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. Deep &amp; cross network for ad click predictions. In <em>Proceedings of the ADKDD’17</em>, page 12. ACM, 2017.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/24/CTR%E4%BC%98%E5%8A%A3%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/24/CTR%E4%BC%98%E5%8A%A3%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">CTR优劣总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-24 18:26:09" itemprop="dateCreated datePublished" datetime="2022-01-24T18:26:09+08:00">2022-01-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-26 17:27:32" itemprop="dateModified" datetime="2022-01-26T17:27:32+08:00">2022-01-26</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="CTR各模型优劣总结"><a href="#CTR各模型优劣总结" class="headerlink" title="CTR各模型优劣总结"></a>CTR各模型优劣总结</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文是依照上一篇文章的顺序来进行整理，现附上上一篇链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://perfect-player.github.io/2021/09/27/CTR/</span><br></pre></td></tr></table></figure>
<p>本文参考原论文（主）与网络资料（次）编写而成。</p>
<h3 id="Convolutional-Click-Prediction-Model-卷积点击预测模型CCPM"><a href="#Convolutional-Click-Prediction-Model-卷积点击预测模型CCPM" class="headerlink" title="Convolutional Click Prediction Model(卷积点击预测模型CCPM)"></a>Convolutional Click Prediction Model(卷积点击预测模型CCPM)</h3><p>由于循环神经网络在连续广告印象上的不可改变的传播方式，在有效建模动态点击预测方面有局限性，而深度CNN架构的池化和卷积层可以从连续的广告印象中充分提取局部-全局的关键特征。</p>
<p>CCPM就是基于CNN的一个架构，CCPM可以从具有不同元素的输入实例中提取局部-全局关键特征，这不仅可以针对单个广告印象，也可以针对连续的广告印象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">CCPM can extract local-global key features from an input instance with varied elements, which can be implemented for not only single ad impression but also sequential ad impression.</span><br></pre></td></tr></table></figure>
<h3 id="Factorization-supported-Neural-Network-因子分解支持的神经网络FNN"><a href="#Factorization-supported-Neural-Network-因子分解支持的神经网络FNN" class="headerlink" title="Factorization-supported Neural Network(因子分解支持的神经网络FNN)"></a>Factorization-supported Neural Network(因子分解支持的神经网络FNN)</h3><p>出发点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.之前运用的CTR模型大多是线性的，都是基于大量的稀疏特征的编码。性能相对较低，因为在学习非微观模式时，无法捕捉到假定的（有条件的）独立原始特征之间的相互作用。</span><br><span class="line">2.当时的非线性模型不能利用所有可能的不同特征的组合。</span><br><span class="line">3.大多数预测模型有浅层的结构，对复杂的海量数据的基础模型表达有限，数据建模和泛化能力仍然受到限制。</span><br></pre></td></tr></table></figure>
<p>基于上述出发点引入了深度学习模型。</p>
<p>带有监督学习嵌入层的FNN使用因子化机器被提出来，以有效地减少从稀疏特征到密集的连续特征。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">Specifically,FNN with a supervised-learning embedding layer using factorisation machines is proposed to efficiently reduce the dimension from sparse features to dense continuous features. </span><br></pre></td></tr></table></figure>
<h3 id="Product-based-Neural-Network-PNN"><a href="#Product-based-Neural-Network-PNN" class="headerlink" title="Product-based Neural Network(PNN)"></a>Product-based Neural Network(PNN)</h3><p>背景</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">深度神经网络（DNNs）在分类和回归任务中显示了巨大的能力，在用户反应预测中采用DNNs是很有前途的。之前为了改善多领域分类数据的交互，提出的一种基于因子预训练的方法，基于串联的嵌入向量，构建多层感知器（MLPs）来探索特征的相互作用。嵌入初始化的质量在很大程度上受到因式分解机的限制。</span><br></pre></td></tr></table></figure>
<p>为了利用神经网络的学习能力和挖掘以一种比MLPs更有效的方式挖掘数据的潜在模式，所以提出PNN。PNN有望在多领域的分类数据上学习高阶潜在模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">To utilize the learning ability of neural networks and mine the latent patterns of data in a more effective way than MLPs,in this paper we propose Product-based Neural Network。</span><br><span class="line">PNN is promising to learn high-order latent patterns on multi-field categorical data. </span><br></pre></td></tr></table></figure>
<h3 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide &amp; Deep"></a>Wide &amp; Deep</h3><p>谷歌曾经的主流推荐模型，业界影响巨大。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">记忆能力：可以被理解为模型直接学习并利用历史数据中物品和特征的“共现频率”的能力</span><br></pre></td></tr></table></figure>
<p>提出动机</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">利用手工构造的交叉组合特征来使线性模型具有记忆性会得到一个不错的效果，但特征工程需要耗费大量精力，对于未曾出现过的特征组合，权重系数为0，无法进行泛化。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">线性模型，记忆力较强，但泛化能力弱</span><br><span class="line">embedding模型，记忆能力弱，泛化能力强</span><br></pre></td></tr></table></figure>
<p>基于优势互补，提出Wide &amp; Deep，左边Wide部分是一个简单的线性模型，右边Deep部分是一个经典的DNN模型。</p>
<p>WDL的深层部分将稀疏的特征嵌入连接起来作为MLP的输入，宽层部分使用手工制作的特征作为输入。深度部分和宽度部分的对数相加，得到预测概率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">WDL’s deep part concatenates sparse feature embeddings as the input of MLP,the wide part use handcrafted feature as input. The logits of deep part and wide part are added to get the prediction probability.</span><br></pre></td></tr></table></figure>
<h3 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h3><p>整合了FM和深度神经网络（DNN）的架构。它像FM一样对低阶特征的交互进行建模，像DNN一样对高阶特征的交互进行建模。不同于</p>
<p>Wide &amp; Deep，DeepFM可以在没有任何特征工程的情况下进行端到端训练。但复杂性较大。</p>
<p>优点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.它不需要任何预训练</span><br><span class="line">2.它同时学习高阶和低阶特征的相互作用；</span><br><span class="line">3.它引入了特征嵌入的共享策略以避免特征工程</span><br></pre></td></tr></table></figure>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1) it does not need any pre-training; </span><br><span class="line">2) it learns both high- and loworder feature interactions; </span><br><span class="line">3) it introduces a sharing strategy of feature embedding to avoid feature engineering</span><br></pre></td></tr></table></figure>
<p>DeepFM可以看作是WDL和FNN的改进。与WDL相比，DeepFM在广义部分使用FM而不是LR，在深义部分使用嵌入向量的连接作为MLP的输入。与FNN相比，FM的嵌入向量和MLP的输入是相同的。而且它们不需要FM预训练向量来初始化，它们是端对端学习。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">DeepFM can be seen as an improvement of WDL and FNN.Compared with WDL,DeepFM use FM instead of LR in the wide part and use concatenation of embedding vectors as the input of MLP in the deep part. Compared with FNN,the embedding vector of FM and input to MLP are same. And they do not need a FM pretrained vector to initialiaze,they are learned end2end.</span><br></pre></td></tr></table></figure>
<h3 id="Piece-wise-Linear-Model"><a href="#Piece-wise-Linear-Model" class="headerlink" title="Piece-wise Linear Model"></a>Piece-wise Linear Model</h3><p>背景</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CTR预测问题是一个高度非线性的问题。LR很难抓住非线性因素，基于树的方法不适合非常稀疏和高维的数据，FM不能适应数据中所有的一般非线性模式</span><br></pre></td></tr></table></figure>
<p>提出了一个用于大规模数据的片状线性模型及其训练算法LS-PLM,遵循分而治之的策略。首先将特征空间划分为几个局部区域，然后在每个区域内拟合一个线性模型。结果是输出加权线性预测的组合。它可以从稀疏数据中捕捉到稀疏数据中的非线性模式，并将我们从繁重的特征工程工作中解救出来，这对于实际的工业应用是至关重要的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">优势</span><br><span class="line">LS-PLM的优势在于在三个方面对网络规模的数据挖掘具有优势。</span><br><span class="line">非线性。有了足够的划分区域，LS-PLM可以适应任何复杂的非线性函数。</span><br><span class="line">可扩展性。与LR模型类似，LS-PLM可以扩展到大量样本和高维特征。</span><br><span class="line">稀疏性。</span><br><span class="line">工业模型，可以处理具有1000万个参数的10亿个样本的问题，这就是典型的工业数据量。</span><br></pre></td></tr></table></figure>
<p>由于其能够捕获非线性模式的能力和对海量数据的可扩展性，LS-PLMs已经成为在线显示广告系统中主要的CTR预测榜样，自2012年以来为数亿用户提供服务，成为阿里巴巴在线展示广告系统中主要的点击率预测模型。</p>
<h3 id="Deep-amp-Cross-Network"><a href="#Deep-amp-Cross-Network" class="headerlink" title="Deep &amp; Cross Network"></a>Deep &amp; Cross Network</h3><p>applies feature crossing in an automatic fashion.</p>
<p>以自动的方式进行特征交叉，可以处理大量的稀疏和密集的特征集，并与传统的深层网络共同学习程度有限的显性交叉特征。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">can handle a large set of sparse and dense features, and learns explicit cross features</span><br><span class="line">of bounded degree jointly with traditional deep representations.</span><br></pre></td></tr></table></figure>
<h3 id="Attentional-Factorization-Machine-AFM"><a href="#Attentional-Factorization-Machine-AFM" class="headerlink" title="Attentional Factorization Machine(AFM)"></a>Attentional Factorization Machine(AFM)</h3><p>AFM是FM的一个变种，传统的FM是将嵌入向量的内积均匀地加起来。AFM可以被看作是特征相互作用的加权和。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">AFM is a variant of FM,tradional FM sums the inner product of embedding vector uniformly. AFM can be seen as weighted sum of feature interactions.The weight is learned by a small MLP.</span><br></pre></td></tr></table></figure>
<p>AFM弥补了FM对于不同的特征交互不能赋予不同权重的问题。</p>
<h3 id="Neural-Factorization-Machine"><a href="#Neural-Factorization-Machine" class="headerlink" title="Neural Factorization Machine"></a>Neural Factorization Machine</h3><p>NFM使用一个双交互池层来学习嵌入向量之间的特征交互，并将结果压缩成一个单一的向量，其大小与单一嵌入向量相同。MLP的输出对数和线性部分的输出对数相加，得到预测概率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">NFM use a bi-interaction pooling layer to learn feature interaction between embedding vectors and compress the result into a singe vector which has the same size as a single embedding vector. And then fed it into a MLP.The output logit of MLP and the output logit of linear part are added to get the prediction probability.</span><br></pre></td></tr></table></figure>
<p>FM的性能可能受到其线性的限制，以及仅对成对（即二阶）特征的相互作用进行建模。特别是，对于具有复杂和非线性基础结构的真实世界数据，FM可能无法表达。</p>
<p>NFMs:一个用于稀疏数据预测的新模型,将线性分解机的有效性与非线性神经网络的强大表示能力结合起来，用于稀疏预测分析。通过对高阶和非线性特征的相互作用的建模，增强了FMs的功能。NFM结构的关键是新提出的双交互操作。</p>
<h3 id="xDeepFM"><a href="#xDeepFM" class="headerlink" title="xDeepFM"></a>xDeepFM</h3><p>xDeepFM可以自动学习显性和隐性的高阶特征交互，这对于减少人工特征工程的工作具有重要意义。它是将一个CIN和一个DNN纳入一个端到端的框架中所产生的。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Thus xDeepFM can automatically learn high-order feature interactions in both explicit and implicit fashions, which is of great significance to reducing manual feature engineering work.</span><br></pre></td></tr></table></figure>
<p>xDeepFM使用压缩交互网络（CIN）来显式学习低阶和高阶特征交互，并使用MLP来隐式学习特征交互。在CIN的每一层，首先计算$x^k$和$x<em>0$之间的外积，得到一个张量$Z</em>{k+1}$，然后使用1DConv来学习这个张量上的特征图$H_{k+1}$。最后，对所有的特征图$H_k$应用总和池，得到一个向量。该向量用于计算CIN的贡献对数。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xDeepFM use a Compressed Interaction Network (CIN) to learn both low and high order feature interaction explicitly,and use a MLP to learn feature interaction implicitly. In each layer of CIN,first compute outer products between $x^k$ and $x_0$ to get a tensor $Z_&#123;k+1&#125;$,then use a 1DConv to learn feature maps $H_&#123;k+1&#125;$ on this tensor. Finally,apply sum pooling on all the feature maps $H_k$ to get one vector.The vector is used to compute the logit that CIN contributes.</span><br></pre></td></tr></table></figure>
<h3 id="Deep-Interest-Network"><a href="#Deep-Interest-Network" class="headerlink" title="Deep Interest Network"></a>Deep Interest Network</h3><p>出发点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在传统的深度CTR模型中，使用固定长度的表示法是捕捉用户兴趣多样性的一个瓶颈。用户的各种兴趣被压缩到一个固定长度的向量中，这限制了嵌入和MLP方法的表达能力。</span><br></pre></td></tr></table></figure>
<p>深度兴趣网络（DIN），它通过考虑到候选广告的历史行为的相关性，自适应地计算用户兴趣的表示向量。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Deep Interest Network (DIN), which adaptively calculates the representation vector of user interests by taking into consideration the relevance of historical behaviors given a candidate ad. </span><br></pre></td></tr></table></figure>
<p>DIN引入了一种注意力方法来学习序列（多值）特征。传统的方法通常在序列特征上使用和/均值池。DIN使用一个局部激活单元来获得候选项目和历史项目之间的激活分数。用户的兴趣由用户行为的加权和表示，用户的兴趣向量和其他嵌入向量被连接起来，并输入MLP得到预测。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DIN introduce a attention method to learn from sequence(multi-valued) feature. Tradional method usually use sum/mean pooling on sequence feature. DIN use a local activation unit to get the activation score between candidate item and history items. User’s interest are represented by weighted sum of user behaviors. user’s interest vector and other embedding vectors are concatenated and fed into a MLP to get the prediction.</span><br></pre></td></tr></table></figure>
<h3 id="Deep-Interest-Evolution-Network"><a href="#Deep-Interest-Evolution-Network" class="headerlink" title="Deep Interest Evolution Network"></a>Deep Interest Evolution Network</h3><p>出发点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.包括DIN在内的大多数兴趣模型都将行为直接视为兴趣，而潜在的兴趣则很难通过显性行为完全反映出来。</span><br><span class="line">2.用户的兴趣是不断变化的，捕捉兴趣的动态对于兴趣的表达是非常重要的。</span><br></pre></td></tr></table></figure>
<p>深度兴趣进化网络（DIEN）使用兴趣提取器层，从历史行为序列中捕捉时间性兴趣。在这一层，提出了一个辅助损失来监督每一步的兴趣提取。由于用户的兴趣是多样化的，特别是在电子商务系统中，兴趣演化层被提出来捕捉与目标项目有关的兴趣演化过程。在兴趣演化层，注意力机制被新颖地嵌入到顺序结构中，并且在兴趣演化过程中加强了相对兴趣的影响。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Deep Interest Evolution Network (DIEN) uses interest extractor layer to capture temporal interests from history behavior sequence. At this layer, an auxiliary loss is proposed to supervise interest extracting at each step. As user interests are diverse, especially in the e-commerce system, interest evolving layer is proposed to capture interest evolving process that is relative to the target item. At interest evolving layer, attention mechanism is embedded into the sequential structure novelly, and the effects of relative interests are strengthened during interest evolution.</span><br></pre></td></tr></table></figure>
<p>关于DIEN详情可参照本人的另一篇博客</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://perfect-player.github.io/2022/01/09/DIEN/</span><br></pre></td></tr></table></figure>
<h3 id="AutoInt"><a href="#AutoInt" class="headerlink" title="AutoInt"></a>AutoInt</h3><p>该模型能够以明确的方式自动学习高阶特征的相互作用。方法的关键的关键是新引入的交互层，它允许每个特征与其他特征交互，并通过学习来确定相关性。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The key to our method is the newly-introduced interacting layer, which allows each feature to interact with the others and to determine the relevance through learning.</span><br></pre></td></tr></table></figure>
<p>AutoInt使用交互层来模拟不同特征之间的相互作用。在每个交互层中，每个特征都被允许与其他所有的特征进行交互，并且能够自动识别相关的特征，通过多头关注机制形成有意义的高阶特征。通过堆叠多个交互层，AutoInt能够对不同等级的特征交互进行建模。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AutoInt use a interacting layer to model the interactions between different features. Within each interacting layer, each feature is allowed to interact with all the other features and is able to automatically identify relevant features to form meaningful higher-order features via the multi-head attention mechanism. By stacking multiple interacting layers,AutoInt is able to model different orders of feature interactions.</span><br></pre></td></tr></table></figure>
<h3 id="ONN"><a href="#ONN" class="headerlink" title="ONN"></a>ONN</h3><p>出发点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">很少有工作专注于改进由嵌入层学习的特征表示</span><br></pre></td></tr></table></figure>
<p>与传统的特征嵌入方法相比，操作感知嵌入方法为所有操作学习一种表征。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Compared with the traditional feature embedding method which learns one representation for all operations, operation-aware embedding can learn various representations for different operations.</span><br></pre></td></tr></table></figure>
<p>ONN对二阶特征交互进行建模，就像FFM一样，并尽可能地保留二阶交互信息。此外，深度神经网络被用来学习高阶特征交互。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ONN models second order feature interactions like like FFM and preserves second-order interaction information as much as possible.Further more,deep neural network is used to learn higher-ordered feature interactions.</span><br></pre></td></tr></table></figure>
<h3 id="FiBiNET-Feature-Importance-and-Bilinear-feature-Interaction-NETwork"><a href="#FiBiNET-Feature-Importance-and-Bilinear-feature-Interaction-NETwork" class="headerlink" title="FiBiNET(Feature Importance and Bilinear feature Interaction NETwork)"></a>FiBiNET(Feature Importance and Bilinear feature Interaction NETwork)</h3><p>提出了特征重要性和双线性特征交互网络，以动态学习特征重要性和细粒度的特征交互。一方面，FiBiNET可以通过Squeeze-Excitation网络（SENET）机制动态地学习特征的重要性；另一方面，它能够通过双线性函数有效地学习特征的相互作用。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Feature Importance and Bilinear feature Interaction NETwork is proposed to dynamically learn the feature importance and fine-grained feature interactions. On the one hand, the FiBiNET can dynamically learn the importance of fea- tures via the Squeeze-Excitation network (SENET) mechanism; on the other hand, it is able to effectively learn the feature interactions via bilinear function.</span><br></pre></td></tr></table></figure>
<p>目的</p>
<p>于动态学习特征重要性和细粒度的特征相互作用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proposed to dynamically learn the feature importance and finegrained feature interactions. </span><br></pre></td></tr></table></figure>
<p>优势</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.对于CTR任务。SENET模块可以动态地学习特征的重要性。它提高了重要特征的权重，抑制了不重要特征的权重。</span><br><span class="line">2.引入了三种类型的双线性交互层来学习特征的交互作用，而不是通过计算特征的交互作用。</span><br><span class="line">3.在浅层模型中，将SENET机制与双线性特征交互结合起来，优于其他浅层、</span><br><span class="line">4.将经典的深度神经网络（DNN）组件与浅层模型相结合，成为一个深度模型。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> 1) For CTR task,the SENET module can learn the importance of features dynamically. It boosts the weight of the important feature and suppresses the weight of unimportant features. </span><br><span class="line"> 2) We introduce three types of Bilinear-Interaction layers to learn feature interaction rather</span><br><span class="line">than calculating the feature interactions with Hadamard product or inner product.</span><br><span class="line">3) Combining the SENET mechanism with bilinear feature interaction in our shallow model outperforms other shallow models such as FM and FFM.</span><br><span class="line">4) In order to improve performance further, we combine a classical deep neural network(DNN) component with the shallow model to be a deep model. The deep FiBiNET consistently outperforms the other state-of-the-art deep models such as DeepFM and XdeepFM.</span><br></pre></td></tr></table></figure>
<h3 id="IFM"><a href="#IFM" class="headerlink" title="IFM"></a>IFM</h3><p>输入感知因子机（IFM）通过神经网络为不同实例中的同一特征学习一个独特的输入感知因子。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Input-aware Factorization Machine (IFM) learns a unique input-aware factor for the same feature in different instances via a neural network.</span><br></pre></td></tr></table></figure>
<p>适用于稀疏的数据集。它的目的是通过有目的地学习更灵活、更准确的特征，来增强传统的FM。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">It aims to enhance traditional FMs by purposefully learning more flexible and accurate representation of features for different instances with the help of a factor estimating network. </span><br></pre></td></tr></table></figure>
<p>IFM的两个主要优势</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.与现有的技术相比，它能产生更好的预测结果</span><br><span class="line">2.它能更深入地了解每个特征在预测任务中的作用。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">i). it produces better prediction results compared to existing techniques</span><br><span class="line">ii). it provides deeper insights into the role that each feature plays in the prediction task.</span><br></pre></td></tr></table></figure>
<h3 id="DCN-V2"><a href="#DCN-V2" class="headerlink" title="DCN V2"></a>DCN V2</h3><p>以一种富有表现力而又简单的方式为显式交叉建模，观察到交叉网络中权重矩阵的低秩性质。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Observing the low-rank nature of the weight matrix in the cross network</span><br></pre></td></tr></table></figure>
<h3 id="DIFM"><a href="#DIFM" class="headerlink" title="DIFM"></a>DIFM</h3><p>双输入感知因式分解机（DIFM）可以同时在比特级和矢量级对原始特征表示进行自适应的重新加权。此外，DIFM战略性地将包括多头自适应、残差网络和DNN在内的各种组件整合到一个统一的端到端模型中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Dual Inputaware Factorization Machines (DIFM) can adaptively reweight the original feature representations at the bit-wise and vector-wise levels simultaneously.Furthermore, DIFMs strategically integrate various components including Multi-Head Self-Attention, Residual Networks and DNNs into a unified end-to-end model.</span><br></pre></td></tr></table></figure>
<p>目的是根据不同的输入实例，借助DIFMs，自适应地学习一个给定特征的灵活表示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">It aims to adaptively learn flexible representations of a given feature according to different input instances with the help of the Dual-Factor Estimating Network (Dual-FEN).</span><br></pre></td></tr></table></figure>
<p>主要优点是它不仅能在比特级，而且能在矢量级同时有效地学习输入感知因子（用于重新加权原始特征表示）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The major advantage of DIFM is that it can effectively learn the inputaware factors (used to reweight the original feature representations) not only at the bit-wise level but also at the vectorwise level imultaneously.</span><br></pre></td></tr></table></figure>
<h3 id="AFN"><a href="#AFN" class="headerlink" title="AFN"></a>AFN</h3><p>自适应因子化网络（AFN）可以从数据中自适应地学习任意等级的交叉特征。AFN的核心是一个对数转换层，将特征组合中每个特征的功率转换成要学习的系数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Adaptive Factorization Network (AFN) can learn arbitrary-order cross features adaptively from data. The core of AFN is a logarith- mic transformation layer to convert the power of each feature in a feature combination into the coefficient to be learned.</span><br></pre></td></tr></table></figure>
<p>AFN能够从数据中自适应地学习任意顺序的特征互动。而不是在一个固定的最大顺序内对所有的交叉特征进行明确的建模。<br>AFN能够自动生成辨别性的交叉特征和相应特征的权重。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learns arbitrary-order feature interactions adaptively from data. Instead of explicitly modeling all the cross features within a fixed maximum order,AFN is able to generate discriminative cross features and</span><br><span class="line">the weights of the corresponding features automatically.</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/09/DIEN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/09/DIEN/" class="post-title-link" itemprop="url">DIEN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-09 20:04:42" itemprop="dateCreated datePublished" datetime="2022-01-09T20:04:42+08:00">2022-01-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-11 09:53:17" itemprop="dateModified" datetime="2022-01-11T09:53:17+08:00">2022-01-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Deep-Interest-Evolution-Network-for-Click-Through-Rate-Prediction"><a href="#Deep-Interest-Evolution-Network-for-Click-Through-Rate-Prediction" class="headerlink" title="Deep Interest Evolution Network for Click-Through Rate Prediction"></a>Deep Interest Evolution Network for Click-Through Rate Prediction</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>阿里CTR预估模型—-DIEN（深度兴趣演化网络）</p>
<p>这是一篇一篇阿里2019发表在AAAI上的CTR预估的论文，本文亮点主要是作者提出了兴趣提取层与兴趣演化层两个网络层。</p>
<p>附一个原文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/abs/1809.03672v1</span><br></pre></td></tr></table></figure>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><strong>每点击付费(CPC)</strong> 是广告系统中最常见的计费形式之一，广告商对广告的每次点击进行收费。在CPC广告系统中，点击率(CTR)预测的效果不仅影响整个平台的最终收益，还会影响用户体验和满意度。</p>
<p>在大多数<strong>非搜索</strong>的电子商务场景中，用户不主动表达自己当前的意愿。因此设计能够捕捉用户动态兴趣的模型是提高CTR预测性能的关键。</p>
<h3 id="研究状态"><a href="#研究状态" class="headerlink" title="研究状态"></a>研究状态</h3><p>注，本文的研究状态为到2019年以前。</p>
<p>a.由于深度学习在特征表示上的强学习能力，目前大部分CTR模型从传统的线性或非线性模型（例如FM）转换到深度模型。</p>
<p>b.大多数深度模型遵循Embedding+多层感知器(MLP)的结构， 但这些模型只关注从不同的领域捕获特征之间的交互，【没有考虑到用户兴趣的表示】。</p>
<p>c.DIN引入了一个attention机制来激活具有意义的历史行为。但</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DIN很难捕捉潜在的用户兴趣；</span><br><span class="line">用户兴趣是不断发展，DIN在捕获用户序列的行为之间的依赖有所欠缺。</span><br></pre></td></tr></table></figure>
<p>d.大多数基于RNN的模型都【连续且均等地处理相邻行为之间的所有依赖关系】。但并非所有用户的行为都严格取决于每个相邻的行为。 每个用户都有不同的兴趣，并且每个兴趣都有其自己的发展轨迹，例如书籍和衣服的发展过程几乎是各自独立的。 对于目标物品，这些模型只能获得一个固定的兴趣演化轨迹，可能会受到兴趣漂移的干扰。【简而言之，就是缺少Attention机制】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">兴趣漂移：兴趣漂移对行为的影响是用户可能在一段时间内对各种书籍产生兴趣，在另一段时间内又需要衣服。</span><br></pre></td></tr></table></figure>
<h3 id="创新"><a href="#创新" class="headerlink" title="创新"></a>创新</h3><p>a.兴趣提取器层（interest extractor layer）：首先DIEN选择GRU来建模两行为之间的依赖性。其次由于隐藏状态缺乏对兴趣表示的监督，作者提出了<strong>辅助损失</strong>，即<strong>使用下一个行为来监督当前隐藏状态的学习</strong>。作者把这些有额外监督的隐藏状态称为【兴趣状态】，有助于捕获更多的语义意义用于兴趣表示，推动GRU的隐藏状态，从而有效地表示兴趣。</p>
<p>b.兴趣演化层（interest evolving layer）：兴趣的多样性会导致兴趣偏移的现象。在相邻的访问中，用户的意图可能非常不同，用户的一个行为可能依赖于很久以前的行为。因此，作者提出<strong>建立与目标物相关的兴趣演化轨迹模型</strong>，设计了带有注意力机制更新门的GRU—-AUGRU。<strong>运用兴趣状态和目标物体去计算相关性</strong>。AUGRU增强了在兴趣演化中相关兴趣的影响，同时削弱了兴趣漂移所产生的非相关兴趣效应。通过在更新门中引入注意机制，AUGRU可以实现针对不同目标物体的特定兴趣演化过程。</p>
<h3 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h3><p>a.提出一个新的网络结构来对兴趣演化过程进行建模。兴趣表示更具有表达性，CTR预估更精确。</p>
<p>b.设计了一个兴趣提取层。指出GRU对兴趣表示的针对性弱，故提出辅助损失。</p>
<p>c.设计了一个兴趣演化层，AUGRU增强了相关兴趣对目标物体的影响。</p>
<h3 id="具体细节"><a href="#具体细节" class="headerlink" title="具体细节"></a>具体细节</h3><h4 id="DIN与DIEN的总体思路"><a href="#DIN与DIEN的总体思路" class="headerlink" title="DIN与DIEN的总体思路"></a>DIN与DIEN的总体思路</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在MLP的基础上，引入先验知识，加速模型训练，提高模型准确性。</span><br></pre></td></tr></table></figure>
<p><img src="/2022/01/09/DIEN/image-20220110103347882.png" alt="image-20220110103347882" style="zoom: 25%;">到<img src="/2022/01/09/DIEN/image-20220110103434044.png" alt="image-20220110103434044" style="zoom:25%;"></p>
<p>兴趣</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">兴趣是用来表达行为，行为则是挖掘兴趣。</span><br><span class="line">对兴趣建模的任务就是从用户的历史行为中，挖掘出用户的兴趣，将兴趣</span><br><span class="line">这个抽象的概念量化表达。</span><br><span class="line">因此训练数据中，需要引入用户的历史点击行为。</span><br></pre></td></tr></table></figure>
<p>DIN与DIEN的区别就是兴趣的建模方式不同。</p>
<h4 id="DIN兴趣建模思路与缺点"><a href="#DIN兴趣建模思路与缺点" class="headerlink" title="DIN兴趣建模思路与缺点"></a>DIN兴趣建模思路与缺点</h4><p><img src="/2022/01/09/DIEN/image-20220110104128810.png" alt="image-20220110104128810" style="zoom:50%;"></p>
<p>在DIN中，直接将每个历史行为等价于用户兴趣(方框处)。然后通过注意力机制，模拟处候选广告与每个历史点击之间的相关性，从而判断用户对候选广告感兴趣的程度。</p>
<p>缺点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">对兴趣的表达，不能完全贴合实际情况。</span><br><span class="line">a.直接吧行为等价成兴趣</span><br><span class="line">b.很难通过已表现出来的行为，来反映出用户的潜在兴趣</span><br><span class="line">c.之前的方法，忽略了去挖掘潜藏在用户行为背后的兴趣</span><br><span class="line">eg:假设你当下点击了鞋子，则DIN认为你是对于鞋子感兴趣的，但是你背后的兴趣可能是多样的，例如还可能对衣服感兴趣。</span><br><span class="line">DIN忽略了序列信息，容易基于用户所有购买历史行为综合推荐，而不是针对下一次购买推荐。</span><br></pre></td></tr></table></figure>
<p>兴趣的实际情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a.人的兴趣是多样的，在同一个时刻，拥有多种不同的兴趣应该用兴趣状态来描述。但是DIN只能捕捉到用户的一个兴趣。</span><br><span class="line">b.兴趣是动态变换，都有属于自己的演化过程。但是DIN没有动态演化过程，例如你买完鞋子以后你可能对鞋子不感兴趣了，但是DIN还是会认为你对鞋子感兴趣。</span><br><span class="line">c.兴趣的发展是有前后关联的</span><br><span class="line">d.兴趣会存在兴趣漂移</span><br></pre></td></tr></table></figure>
<h4 id="DIEN对兴趣的建模思路"><a href="#DIEN对兴趣的建模思路" class="headerlink" title="DIEN对兴趣的建模思路"></a>DIEN对兴趣的建模思路</h4><p>循环神经网络满足上述兴趣的特点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.使用循环神经网络，从用户的序列行为信息中，提取出用户的兴趣状态</span><br><span class="line">b.每个时刻下的兴趣状态用一个向量来表征，这个向量相当于一个黑盒，当中包含了丰富的语义信息，例如用户当前有哪些兴趣、对各个兴趣的强烈程度。</span><br><span class="line">c.利用循环神经网络的串联结构，以及记忆特性，找到用户兴趣演化的规律。</span><br></pre></td></tr></table></figure>
<p>步骤</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a.从用户历史行为中提取出每个时刻的兴趣状态</span><br><span class="line">b.利用注意力机制，找到与候选广告相关的那部分兴趣的演化过程，判断用户下一时刻对该兴趣的感兴趣程度</span><br></pre></td></tr></table></figure>
<h4 id="DIEN详解"><a href="#DIEN详解" class="headerlink" title="DIEN详解"></a>DIEN详解</h4><p><img src="/2022/01/09/DIEN/image-20220110115254821.png" alt="image-20220110115254821"></p>
<p>核心为历史行为处理部分，往右依次是目标广告，上下文特征，用户行为特征。</p>
<p>核心部分分为三层，从下到上为行为序列层，兴趣抽取层，兴趣进化层</p>
<h5 id="兴趣抽取层"><a href="#兴趣抽取层" class="headerlink" title="兴趣抽取层"></a>兴趣抽取层</h5><p>作用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">挖缺并提取出每个时刻下，用户行为背后潜藏的兴趣状态。</span><br></pre></td></tr></table></figure>
<p>采用的序列模型为GRU，具有记忆特性，可以缓解梯度消失，训练参数小于LSTM。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">具体可参考：</span><br><span class="line">https://zhuanlan.zhihu.com/p/32481747</span><br></pre></td></tr></table></figure>
<p>结构：多输入，多输出</p>
<p>为更好的提取，设计了auxiliary loss</p>
<p><img src="/2022/01/09/DIEN/image-20220110120300856.png" alt="image-20220110120300856" style="zoom: 50%;"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">这里设计了一个二分类模型来计算兴趣抽取的准确性，</span><br><span class="line">我们将用户下一时刻真实的行为e(t+1)作为正例，</span><br><span class="line">负采样得到的行为作为负例e(t+1)&#x27;，</span><br><span class="line">分别于抽取出的兴趣h(t)结合输入到设计的辅助网络中，得到预测结果，并通过logloss计算一个辅助的损失</span><br></pre></td></tr></table></figure>
<p>原因</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果只采用最后的label去监督，则隐藏层所有状态都是为最后一个状态服务，则提取出的隐藏层状态显然失真。</span><br></pre></td></tr></table></figure>
<p>训练方式：引入负采样训练</p>
<h5 id="兴趣进化层"><a href="#兴趣进化层" class="headerlink" title="兴趣进化层"></a>兴趣进化层</h5><p>兴趣演化的特点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">存在兴趣漂移，每个兴趣都有自己的演化过程</span><br></pre></td></tr></table></figure>
<p>作用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">模拟出与目标广告相关的进化机制</span><br></pre></td></tr></table></figure>
<p>DIEN创新点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">把这个注意力操作嵌入到GRU的更新门里面去，形成了一个AUGRU的结构，用这个层来更有针对性的模拟与目标广告相关的兴趣进化路径</span><br></pre></td></tr></table></figure>
<p>得到过程</p>
<h6 id="AIGRU"><a href="#AIGRU" class="headerlink" title="AIGRU"></a>AIGRU</h6><p><img src="/2022/01/09/DIEN/image-20220110122005893.png" alt="image-20220110122005893"></p>
<p><img src="/2022/01/09/DIEN/image-20220110122133352.png" alt="image-20220110122133352"></p>
<p>直接拿$a_t$乘上了兴趣抽取层的隐藏兴趣状态，但会使不相干的兴趣会影响到兴趣演化层的学习</p>
<h6 id="AGRU"><a href="#AGRU" class="headerlink" title="AGRU"></a>AGRU</h6><p><img src="/2022/01/09/DIEN/image-20220110122118801.png" alt="image-20220110122118801"></p>
<p>拿$a_t$替换掉了更新门。</p>
<p>若某个时刻t的兴趣$h_t$与当前候选广告一点关系没有，即$a_t$为0，这个时候的隐藏状态会直接使用上一时刻的。</p>
<p>通过这种机制保障只关注和当前候选广告相关的兴趣演化过程。</p>
<p>问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在替换时用标量替换向量，忽视了不同维度上值的重要性</span><br></pre></td></tr></table></figure>
<h6 id="AUGRU"><a href="#AUGRU" class="headerlink" title="AUGRU"></a>AUGRU</h6><p><img src="/2022/01/09/DIEN/image-20220110122639019.png" alt="image-20220110122639019"></p>
<p>克服了AGRU忽略维度的问题。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文提出了一种新的深层网络结构，即深层兴趣演化网络(DIEN)，来模拟兴趣的演化过程。在在线广告系统中，DIEN极大地提高了CTR预测的性能。具体地说，作者设计了</p>
<ul>
<li>兴趣提取层来捕获兴趣序列，利用辅助损失来提供对兴趣状态的更多监督。</li>
<li>兴趣演化层，使用带有注意力更新门(AUGRU)的GRU来模拟与目标物品相关的兴趣演化过程。在AUGRU的帮助下，DIEN克服了兴趣漂移的干扰。兴趣演化建模有助于有效捕获兴趣，进一步提高CTR预测的性能。</li>
</ul>
<h3 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h3><p>B站，老弓的学习日记</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">操作系统</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-07 19:05:41" itemprop="dateCreated datePublished" datetime="2022-01-07T19:05:41+08:00">2022-01-07</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">编译原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-04 10:47:20" itemprop="dateCreated datePublished" datetime="2022-01-04T10:47:20+08:00">2022-01-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-19 11:31:04" itemprop="dateModified" datetime="2022-01-19T11:31:04+08:00">2022-01-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><h3 id="什么是编译"><a href="#什么是编译" class="headerlink" title="什么是编译"></a>什么是编译</h3><p>编译：将高级语言翻译成汇编语言或机器语言的过程。</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220104110715843.png" alt="image-20220104110715843" style="zoom:50%;"></p>
<p>预处理器：把存储在不同文件中的源程序聚合在一起；把被称为宏的缩写语句转换为原始语句。</p>
<p>可重定位：在内存中存放的起始位置L不是固定的</p>
<p>加载器：修改可重定位地址；将修改后的指令和数据放到内存中适当的位置。</p>
<p>链接器：将多个可重定位的机器代码文件连接到一起；解决外部内存地址问题</p>
<h3 id="编译系统的结构"><a href="#编译系统的结构" class="headerlink" title="编译系统的结构"></a>编译系统的结构</h3><p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220104113047587.png" alt="image-20220104113047587" style="zoom:50%;"></p>
<h3 id="词法分析概述"><a href="#词法分析概述" class="headerlink" title="词法分析概述"></a>词法分析概述</h3><p>词法分析的主要任务：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">从左向右逐行扫描源程序的字符，识别出各个单词，确定单词的类型。将识别出的单词转换成统一的机内表示——词法单元(token)形式。</span><br><span class="line">token:&lt;种别码，属性值&gt;</span><br></pre></td></tr></table></figure>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220105104115216.png" alt="image-20220105104115216" style="zoom:50%;"></p>
<h3 id="语法分析概述"><a href="#语法分析概述" class="headerlink" title="语法分析概述"></a>语法分析概述</h3><p>语法分析器从词法分析器输出的token序列中识别出各类短语，并构造语法分析树。</p>
<h3 id="语义分析概述"><a href="#语义分析概述" class="headerlink" title="语义分析概述"></a>语义分析概述</h3><p>主要任务：</p>
<p>任务一：收集标识符的属性信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">：</span><br><span class="line">种属</span><br><span class="line">类型</span><br><span class="line">存储类型，长度</span><br><span class="line">值</span><br><span class="line">作用域</span><br><span class="line">参数和返回值信息</span><br></pre></td></tr></table></figure>
<p>符号表：用来存放标识符的属性信息的数据结构</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220106095418057.png" alt="image-20220106095418057" style="zoom:50%;"></p>
<p>任务二：语义检查</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">变量或过程未经声明就使用；</span><br><span class="line">变量或过程名重复声明；</span><br><span class="line">运算分量类型不匹配；</span><br><span class="line">操作符与操作数之间的类型不匹配</span><br></pre></td></tr></table></figure>
<h3 id="中间代码生成及编译器后端"><a href="#中间代码生成及编译器后端" class="headerlink" title="中间代码生成及编译器后端"></a>中间代码生成及编译器后端</h3><p>常用的中间表示形式：</p>
<p>三地址码；语法结构树/语法树</p>
<h4 id="三地址码"><a href="#三地址码" class="headerlink" title="三地址码"></a>三地址码</h4><p>三地址码由类似于汇编语言的指令序列组成，每个指令最多有三个操作数。</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220106095933969.png" alt="image-20220106095933969" style="zoom:50%;"></p>
<p>三地址指令的表示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">四元式(op.y.z.x)</span><br><span class="line">三元式</span><br><span class="line">间接三元式</span><br></pre></td></tr></table></figure>
<p>目标代码生成以源程序的中间表示形式作为输入，并把它映射到目标语言；目标代码生成的一个重要任务是为程序中使用的变量合理分配寄存器。</p>
<p>代码优化：为改进代码，所进行的等价程序变换，使其运行得更快一些，占用空间更小一些。</p>
<h2 id="语言及其文法"><a href="#语言及其文法" class="headerlink" title="语言及其文法"></a>语言及其文法</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>字母表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个有穷符号集合。</span><br></pre></td></tr></table></figure>
<p>字母表运算</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">乘积</span><br><span class="line">n次幂</span><br><span class="line">正闭包（正数次幂的并集）</span><br><span class="line">克林闭包(正闭包的基础上加个空串)</span><br></pre></td></tr></table></figure>
<p>串：字母表中符号的一个有穷序列</p>
<p>串的运算</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">连接，空串是连接运算的单位元</span><br><span class="line">串的幂运算</span><br></pre></td></tr></table></figure>
<h3 id="文法的定义"><a href="#文法的定义" class="headerlink" title="文法的定义"></a>文法的定义</h3><p>文法</p>
<p>$G=(V_T,V_N,P,S)$</p>
<p>$V_T$:终结符集合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">终结符是文法所定义的语言的基本符号，有事也称为token</span><br></pre></td></tr></table></figure>
<p>$V_N$：非终结符集合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">非终结符是用来表示语法成分的符号，有时也称为&quot;语法变量&quot;</span><br></pre></td></tr></table></figure>
<p>$V_T$与$V_N$不相交，二者相并统称为文法符号集。</p>
<p>P：产生式集合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">描述了将终结符和非终结符组合成串的方法</span><br></pre></td></tr></table></figure>
<p>S:开始符号</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">开始符号表示的是该文法中最大的语法成分</span><br></pre></td></tr></table></figure>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220107105320903.png" alt="image-20220107105320903" style="zoom:50%;"></p>
<p>符号约定</p>
<p>终结符</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220107110153976.png" alt="image-20220107110153976" style="zoom:50%;"></p>
<p>非终结符</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220107110227112.png" alt="image-20220107110227112" style="zoom:50%;"></p>
<p>注</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220107110401057.png" alt="image-20220107110401057" style="zoom:50%;"></p>
<h3 id="语言的定义"><a href="#语言的定义" class="headerlink" title="语言的定义"></a>语言的定义</h3><p>符号串$a<em>0$经过n步推导出$a_n$,可简记为$a_0\Longrightarrow </em>{}^{n}a_n $</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220108100026833.png" alt="image-20220108100026833" style="zoom:50%;"></p>
<h3 id="文法的分类"><a href="#文法的分类" class="headerlink" title="文法的分类"></a>文法的分类</h3><p>Chomsky文法分类体系</p>
<h4 id="0型文法"><a href="#0型文法" class="headerlink" title="0型文法"></a>0型文法</h4><p>$\alpha \longrightarrow \beta $</p>
<p>无限制文法，其中$\alpha$中至少包含一个非终结符。</p>
<p>由0型文法G生成的语言称为 <strong>0型语言</strong></p>
<h4 id="1型文法"><a href="#1型文法" class="headerlink" title="1型文法"></a>1型文法</h4><p>$\alpha \longrightarrow \beta $</p>
<p>上下文有关文法，CSG</p>
<script type="math/tex; mode=display">
|\alpha| < |\beta|</script><p>产生式的一般形式:</p>
<script type="math/tex; mode=display">
\alpha_1A\alpha_2\longrightarrow\alpha_1\beta\alpha_2(\beta\ne\varepsilon)</script><h4 id="2型文法"><a href="#2型文法" class="headerlink" title="2型文法"></a>2型文法</h4><p>$\alpha \longrightarrow \beta $</p>
<p>上下文无关文法，CFG</p>
<p>其中$\alpha\in V_N$</p>
<p>产生式的一般形式：</p>
<script type="math/tex; mode=display">
A\longrightarrow \beta</script><h4 id="3型文法"><a href="#3型文法" class="headerlink" title="3型文法"></a>3型文法</h4><p>$\alpha \longrightarrow \beta $</p>
<p>正则文法，RG</p>
<p>右线性文法：$A\longrightarrow wB或A\longrightarrow w$</p>
<p>左线性文法：$A\longrightarrow Bw或A\longrightarrow w$</p>
<h3 id="CFG的分析树"><a href="#CFG的分析树" class="headerlink" title="CFG的分析树"></a>CFG的分析树</h3><p>给定一个句型，其分析树中的每一棵子树的边缘称为该句型的一个短语。</p>
<p>直接短语：高度为2的子树的边缘。</p>
<p>二义性文法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果一个文法可以为某个句子生成多颗分析树，则称这个文法是二义性的。</span><br></pre></td></tr></table></figure>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220109105001704.png" alt="image-20220109105001704" style="zoom:50%;"></p>
<h2 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h2><h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220109105354813.png" alt="image-20220109105354813" style="zoom:50%;"></p>
<h3 id="正则定义"><a href="#正则定义" class="headerlink" title="正则定义"></a>正则定义</h3><p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220111100400281.png" alt="image-20220111100400281" style="zoom:50%;"></p>
<h3 id="有穷自动机"><a href="#有穷自动机" class="headerlink" title="有穷自动机"></a>有穷自动机</h3><p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220111101353306.png" alt="image-20220111101353306" style="zoom:50%;"></p>
<h3 id="有穷自动机的分类"><a href="#有穷自动机的分类" class="headerlink" title="有穷自动机的分类"></a>有穷自动机的分类</h3><p>DFA确定的有穷自动机</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220112104246612.png" alt="image-20220112104246612" style="zoom:50%;"></p>
<p>NFA非确定的有穷自动机</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220112104402251.png" alt="image-20220112104402251" style="zoom:50%;"></p>
<p>正则文法与正则表达式与有穷自动机等价</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220112104637911.png" alt="image-20220112104637911" style="zoom:50%;"></p>
<p>带有空边的NFA与不带空边的NFA有等价性</p>
<h3 id="从正则表达式到有穷自动机"><a href="#从正则表达式到有穷自动机" class="headerlink" title="从正则表达式到有穷自动机"></a>从正则表达式到有穷自动机</h3><p>先构造NFA,再从NFA到DFA。</p>
<h3 id="从NFA到DFA的转换"><a href="#从NFA到DFA的转换" class="headerlink" title="从NFA到DFA的转换"></a>从NFA到DFA的转换</h3><p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220114100302890.png" alt="image-20220114100302890" style="zoom:50%;"></p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220114100719876.png" alt="image-20220114100719876" style="zoom: 50%;"></p>
<h3 id="识别单词的DFA"><a href="#识别单词的DFA" class="headerlink" title="识别单词的DFA"></a>识别单词的DFA</h3><p> 词法分析阶段可检测错误的类型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">单词拼写错误</span><br><span class="line">非法字符</span><br></pre></td></tr></table></figure>
<p>错误恢复策略</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">最简单的错误恢复策略：恐慌模式</span><br><span class="line">从剩余的输入中不断删除字符，直到词法分析器能够在剩余的开头发现一个正确的字符为止。</span><br></pre></td></tr></table></figure>
<h2 id="语法分析"><a href="#语法分析" class="headerlink" title="语法分析"></a>语法分析</h2><h3 id="自顶向下分析概述"><a href="#自顶向下分析概述" class="headerlink" title="自顶向下分析概述"></a>自顶向下分析概述</h3><p>从分析树的顶部向底部方向构造分析树。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最左推导：总是选择每个句型的最左非终结符进行替换。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最右推导：总是选择每个句型的最右非终结符进行替换。</span><br></pre></td></tr></table></figure>
<p>在自底向上的分析中，总是采用最左规约的方式，因此把最左规约称为规范规约，而最右推导相应的称为规范推导。</p>
<p>自顶向下选择最左推导。</p>
<p>需要回溯的分析器叫不确定分析器。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">预测分析：递归下降分析技术的一个特例，通过在输入中向前看固定个数符号来选择正确的A-产生式。</span><br><span class="line">预测分析不需要回溯，是一种确定的自顶向下分析方法。</span><br></pre></td></tr></table></figure>
<h3 id="文法转换"><a href="#文法转换" class="headerlink" title="文法转换"></a>文法转换</h3><p>问题一</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当同一个非终结符的多个候选式存在共同前缀，将导致回溯现象 </span><br></pre></td></tr></table></figure>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220115101308032.png" alt="image-20220115101308032" style="zoom:50%;"></p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220115101415801.png" alt="image-20220115101415801" style="zoom:50%;"></p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220115101523666.png" alt="image-20220115101523666" style="zoom:50%;"></p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220115101639910.png" alt="image-20220115101639910" style="zoom:50%;"></p>
<h3 id="LL-1-文法"><a href="#LL-1-文法" class="headerlink" title="LL(1)文法"></a>LL(1)文法</h3><p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220119105058524.png" alt="image-20220119105058524" style="zoom:50%;"></p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220119105540074.png" alt="image-20220119105540074" style="zoom:50%;"></p>
<p>非终结符的后继符号集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可能在某个句型中紧跟在A后边的终结符a的集合</span><br></pre></td></tr></table></figure>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220119105852021.png" alt="image-20220119105852021" style="zoom:50%;"></p>
<p>q_文法中不含右部以非终结符打头的产生式</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220119110032971.png" alt="image-20220119110032971" style="zoom:50%;"></p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220119110441801.png" alt="image-20220119110441801" style="zoom:50%;"></p>
<p>LL(1)文法</p>
<p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220119110545417.png" alt="image-20220119110545417" style="zoom:50%;"></p>
<h3 id="FIRST集和FOLLOW集"><a href="#FIRST集和FOLLOW集" class="headerlink" title="FIRST集和FOLLOW集"></a>FIRST集和FOLLOW集</h3><p><img src="/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/image-20220119110913536.png" alt="image-20220119110913536" style="zoom:50%;"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/12/24/NLP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/24/NLP/" class="post-title-link" itemprop="url">NLP</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-24 17:08:09" itemprop="dateCreated datePublished" datetime="2021-12-24T17:08:09+08:00">2021-12-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-29 00:31:44" itemprop="dateModified" datetime="2021-12-29T00:31:44+08:00">2021-12-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>NLP任务：分词、词性标注、未登录词识别</p>
<p>语言的性质：共时性；历时性</p>
<p>语法单位</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">句子是语言中最大的语法单位</span><br><span class="line">词组是词的组合，它是句子里面作用相当于词而本身又是由词组成的大于词的单位。</span><br><span class="line">词是最重要的一级语法单位，它是造句的时候能够独立运用的最小单位。</span><br><span class="line">语素是语言中音义结合的最小单位。就汉语来说，大抵一个汉字就是一个语素，但是也有两个字表示一个语素的，如：“咖啡”</span><br></pre></td></tr></table></figure>
<h2 id="语料库"><a href="#语料库" class="headerlink" title="语料库"></a>语料库</h2><p>• 语料库（corpus）一词在语言学上意指大量的文本，通常经过整理， 具有既定格式与标记</p>
<p>语料库的种类</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">共时语料库与历时语料库</span><br><span class="line">通用语料库与专用语料库</span><br></pre></td></tr></table></figure>
<h3 id="语料加工"><a href="#语料加工" class="headerlink" title="语料加工"></a>语料加工</h3><p>文本处理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">垃圾格式问题</span><br><span class="line">大小写</span><br><span class="line">标记化</span><br><span class="line">空格</span><br><span class="line">连字符</span><br><span class="line">词法</span><br><span class="line">句子定义—启发式算法</span><br><span class="line">句子边界的研究</span><br></pre></td></tr></table></figure>
<p>格式标注</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">通用标记语言SGML</span><br><span class="line">SGML是超文本格式的最高层次标准，是可以定义标记语言的元语言</span><br><span class="line">语法标注</span><br></pre></td></tr></table></figure>
<p>Zipf法则 • 一个词地频率f和它的词频排序位置r： f*r=k (k为常数)</p>
<p><img src="/2021/12/24/NLP/image-20211227150000774.png" alt="image-20211227150000774"></p>
<p>如果设置参数B=1, ρ=0，Mandelbrot公式就简化为Zipf法则</p>
<p>搭配抽取</p>
<p><img src="/2021/12/24/NLP/image-20211227150045052.png" alt="image-20211227150045052" style="zoom:50%;"></p>
<h2 id="语料库加工-双语句子自动对齐-amp-双语词典获取"><a href="#语料库加工-双语句子自动对齐-amp-双语词典获取" class="headerlink" title="语料库加工_双语句子自动对齐&amp; 双语词典获取"></a>语料库加工_双语句子自动对齐&amp; 双语词典获取</h2><h3 id="句子对齐问题描述"><a href="#句子对齐问题描述" class="headerlink" title="句子对齐问题描述"></a>句子对齐问题描述</h3><p>基于长度的句子对齐  基本思想：源语言和目标语言的句子长度存在一定 的比例关系</p>
<p>要求：最小（句珠内无句珠）； 唯一（一个句子仅属于一个句珠）； 无交叉（后句对齐一定在前句对齐位置之后）</p>
<h3 id="基于共现的双语词典的获取"><a href="#基于共现的双语词典的获取" class="headerlink" title="基于共现的双语词典的获取"></a>基于共现的双语词典的获取</h3><p>基本思想：如果汉语词出现在某个双语句对 中，其译文也必定在这个句对中。</p>
<p>汉英词典的迭代获取策略</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">迭代策略</span><br><span class="line">1) 初始化；</span><br><span class="line">2) 使用对数相似性模型计算汉英翻译词对候选；</span><br><span class="line">3) 选取前n个汉英对译词对；</span><br><span class="line">4) 双语句对中剔除选定的翻译词对；</span><br><span class="line">5) 若不满足终止条件，重复步骤2；</span><br><span class="line"> 几点说明：复合词暂未考虑；可加入交互方式;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>基于共现的词汇对译模型</p>
<p>评价方式：专家独立于上下文进行判别</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">评价1：每5000个翻译词对候选中正确的译文数</span><br><span class="line">评价2：综合考虑翻译词典的性能</span><br></pre></td></tr></table></figure>
<h2 id="汉语自动分词"><a href="#汉语自动分词" class="headerlink" title="汉语自动分词"></a>汉语自动分词</h2><h3 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h3><p>词干提取vs词形还原：分别用于IR 和 NLP</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">词干提取（stemming）是抽取词的词干或词根形式（不一定能够表达完整语义</span><br><span class="line">词形还原（lemmatization），是把一个任何形式的语言词汇还原为一般形式（能表达完整语义）</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">词干提取主要是采用“缩减”的方法</span><br><span class="line">词形还原主要采用“转变”的方法</span><br><span class="line">在复杂性上：词干提取方法相对简单，词形还原更复杂</span><br><span class="line">在实现方法上：主流方法类似，但具体实现上各有侧重</span><br></pre></td></tr></table></figure>
<p>词性标注</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">词性标注（part-of-speech tagging）,又称为词类标注或者简称</span><br><span class="line">标注，是指为分词结果中的每个单词标注一个正确的词性的程序，</span><br><span class="line">也即确定每个词是名词、动词、形容词或者其他词性的过程</span><br><span class="line">• 词性标注是很多NLP任务的预处理步骤，如句法分析，经过词性</span><br><span class="line">标注后的文本会带来很大的便利性，但也不是不可或缺的步骤</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="分词算法"><a href="#分词算法" class="headerlink" title="分词算法"></a>分词算法</h3><p>正向最大匹配分词(Forward Maximum  Matching method, FMM)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">基本思想：将当前能够匹配的最长词输出</span><br><span class="line">• 1. 设自动分词词典中最长词条所含汉字个数为I</span><br><span class="line">• 2. 取被处理材料当前字符串序数中的I个字作为匹配字段，查找分词词典。</span><br><span class="line">若词典中有这样的一个I字词，则匹配成功，匹配字段作为一个词被切分出</span><br><span class="line">来，转6</span><br><span class="line">• 3. 如果词典中找不到这样的一个I字词，则匹配失败</span><br><span class="line">• 4. 匹配字段去掉最后一个汉字，I--</span><br><span class="line">• 5. 重复2-4，直至切分成功为止</span><br><span class="line">• 6. I重新赋初值，转2，直到切分出所有词为止</span><br></pre></td></tr></table></figure>
<p>逆向最大匹配分词(Backward  Maximum Matching method, BMM法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">分词过程与FMM方法相同，不过是从句子(或文</span><br><span class="line">章)末尾开始处理，每次匹配不成功时去掉的是</span><br><span class="line">最前面的一个汉字</span><br></pre></td></tr></table></figure>
<p>实验表明：逆向最大匹配法比最大匹配法更有效</p>
<p>最大匹配法的问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">• 存在分词错误：增加知识、局部修改</span><br><span class="line">• 局部修改：增加歧义词表，排歧规则</span><br><span class="line">无法发现分词歧义-&gt;从单向匹配改为双向最大匹配</span><br></pre></td></tr></table></figure>
<p>双向匹配法（Bi-direction Matching  method, BM法）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">双向最大匹配法是将正向最大匹配法（FMM）得到的分词</span><br><span class="line">结果和逆向最大匹配法（BMM）得到的结果进行比较，从</span><br><span class="line">而决定正确的分词方法</span><br></pre></td></tr></table></figure>
<p>最少分词法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">• 分词结果中含词数最少</span><br><span class="line">• 优化代替了贪心</span><br><span class="line">• 等价于最短路径</span><br><span class="line">•算法：</span><br><span class="line">• 动态规划算法</span><br><span class="line">• 优点：好于单向的最大匹配方法</span><br><span class="line">• 最大匹配：独立自主/和平/等/互利/的/原则</span><br><span class="line">• 最短路径：独立自主/和/平等互利/的/原则</span><br><span class="line">• 缺点：忽略了所有覆盖歧义，也无法解决大部分交叉歧义</span><br><span class="line">• 结合成分子时</span><br><span class="line">• 结合|成分|子 &#123;&#125; 结|合成|分子 &#123;&#125; 结合|成|分</span><br></pre></td></tr></table></figure>
<h3 id="分词问题：歧义"><a href="#分词问题：歧义" class="headerlink" title="分词问题：歧义"></a>分词问题：歧义</h3><p>交集型切分歧义</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">汉字串AJB被称作交集型切分歧义，如果满足AJ、JB同时</span><br><span class="line">为词(A、J、B分别为汉字串)。此时汉字串J被称作交集串。</span><br></pre></td></tr></table></figure>
<p>组合型切分歧义</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">• 汉字串AB被称作组合型切分歧义，如果满足条件：A、</span><br><span class="line">B、AB同时为词</span><br></pre></td></tr></table></figure>
<p>交集型歧义字段中含有交集字段的个数，称为链长</p>
<p>“真歧义”和“伪歧义”</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">• 真歧义指存在两种或两种以上的可实现的切分形式</span><br><span class="line">• 伪歧义一般只有一种正确的切分形式</span><br></pre></td></tr></table></figure>
<p>分词问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">歧义</span><br><span class="line">未登录词</span><br><span class="line">新词</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>分词质量评价</p>
<p><img src="/2021/12/24/NLP/image-20211227193857156.png" alt="image-20211227193857156" style="zoom:50%;"></p>
<h2 id="中文分词-统计建模"><a href="#中文分词-统计建模" class="headerlink" title="中文分词_统计建模"></a>中文分词_统计建模</h2><h3 id="基于N元文法的分词（MM）"><a href="#基于N元文法的分词（MM）" class="headerlink" title="基于N元文法的分词（MM）"></a>基于N元文法的分词（MM）</h3><p>MM(马尔可夫模型/过程) ：有限历史假设，仅依 赖前n-1个词</p>
<p>一种最简化的情况：一元文法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">P（S）=p(w1) ·p(w2) ·p(w3)….p(wn)</span><br><span class="line"> 等价于最大频率分词</span><br><span class="line"> 即把切分路径上每一个词的概率相乘得到该切</span><br><span class="line">分路径的概率</span><br><span class="line"> 把词概率的负对数理解成路径“代价”，输出</span><br><span class="line">结果就是整体代价最“小”分词序列</span><br></pre></td></tr></table></figure>
<p>采用二元语法(bi-gram)：性能进一步提高</p>
<p><img src="/2021/12/24/NLP/image-20211227195204331.png" alt="image-20211227195204331" style="zoom:50%;"></p>
<p> 更大的n：对下一个词出现的约束性信息更多，更大的辨别力。  更小的n：出现的次数更多，更可靠的统计结果，更高的可靠性。</p>
<p>等价类映射：降低语言模型参数空间</p>
<p>数据平滑（smoothing）：保持模型的辨别能力</p>
<h3 id="基于HMM的分词-词性标注一体化"><a href="#基于HMM的分词-词性标注一体化" class="headerlink" title="基于HMM的分词/词性标注一体化"></a>基于HMM的分词/词性标注一体化</h3><p>输入：待处理句子S </p>
<p> 输出：S的 词序列 W = w1 ,w2…wn </p>
<p>词性序列 T = t1 ,t2…tn </p>
<p> 提示  W可以代表S  分词结果即观测序列  词性序列是状态序列</p>
<p>公式推导</p>
<p><img src="/2021/12/24/NLP/image-20211227200001707.png" alt="image-20211227200001707" style="zoom:50%;"></p>
<p><img src="/2021/12/24/NLP/image-20211227200011651.png" alt="image-20211227200011651" style="zoom:50%;"></p>
<p><img src="/2021/12/24/NLP/image-20211227200200077.png" alt="image-20211227200200077"></p>
<h3 id="由字构词的汉语分词方法"><a href="#由字构词的汉语分词方法" class="headerlink" title="由字构词的汉语分词方法"></a>由字构词的汉语分词方法</h3><p>基本思路  分词过程：一个字的分类问题；  每个字在词语中属于一个确定位置</p>
<p>字的的标注过程中，对所有的字根据预定义的特 征进行词位特征学习，获得一个概率模型</p>
<p>由字构词的分词技术的优势</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> 简化了分词系统的设计  文本中的词表词和未登录词都是用统一的字 标注过程来实现的，分词过程成为字重组的 简单过程。  既可以不必专门强调词表词信息，也不用专 门设计特定的未登录词识别模块</span><br></pre></td></tr></table></figure>
<h3 id="汉语分词方法的后处理方法"><a href="#汉语分词方法的后处理方法" class="headerlink" title="汉语分词方法的后处理方法"></a>汉语分词方法的后处理方法</h3><p>为什么不采用更精巧的模型？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">四元或更高阶...  不可行，需要大量的参数  不得不做一些平滑或差值  难度随模型复杂度而加剧</span><br></pre></td></tr></table></figure>
<p>两个重要组成部分：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 允许的错误校正转换的详细说明</span><br><span class="line"> 学习算法</span><br></pre></td></tr></table></figure>
<p>输入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">一个已经标注好的语料库，</span><br><span class="line">*一个词典</span><br></pre></td></tr></table></figure>
<p>基于转换错误驱动的规则方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 学习和标注在该方法种都是简单和直观的</span><br><span class="line"> 成功用于词性标注、句法分析、介词附着以及</span><br><span class="line">语义消歧</span><br><span class="line"> 经验上，没有出现过拟合现象</span><br><span class="line"> 可以被用来解决大部分后处理问题</span><br><span class="line"> 效率的提升优化，考验工程能力</span><br></pre></td></tr></table></figure>
<p>标注可以采用 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> 隐马尔科夫模型（HMM）  最大熵（ME）  最大熵马尔科夫模型（MEMM）  条件随机场（CRF）等</span><br></pre></td></tr></table></figure>
<h2 id="隐马尔科夫模型"><a href="#隐马尔科夫模型" class="headerlink" title="隐马尔科夫模型"></a>隐马尔科夫模型</h2><h3 id="马尔科夫-Markov-模型"><a href="#马尔科夫-Markov-模型" class="headerlink" title="马尔科夫(Markov)模型"></a>马尔科夫(Markov)模型</h3><p>马尔科夫模型是一种统计模型，广泛的应用在语音识别， 词性自动标注，音字转换，概率文法等各个自然语言处理 的应用领域。</p>
<p>随机过程又称为随机函数，是随时间随机变化的过程。马 尔科夫模型描述了一类重要随机过程。</p>
<p>系统在时间t处于状态𝑠𝑗的概率取决于其在时间1,2,…t-1的 状态，该概率为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">𝑃(𝑞𝑡 = 𝑠𝑗|𝑞𝑡−1 = 𝑠𝑖, 𝑞𝑡−2 = 𝑠𝑘, … )</span><br></pre></td></tr></table></figure>
<p>离散的一阶马尔科夫链：系统在时间t的状态只与时间t-1 的状态有关。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">𝑃(𝑞𝑡 = 𝑠𝑗|𝑞𝑡−1 = 𝑠𝑖, 𝑞𝑡−2 = 𝑠𝑘, … ) = 𝑃(𝑞𝑡 = 𝑠𝑗|𝑞𝑡−1 = 𝑠𝑖)</span><br></pre></td></tr></table></figure>
<p>状态转移概率𝑎𝑖𝑗必须满足以下条件：</p>
<p><img src="/2021/12/24/NLP/image-20211227203707059.png" alt="image-20211227203707059" style="zoom:50%;"></p>
<p>N个状态的一阶马尔科夫过程有𝑁2，可以表示成为一个状 态转移矩阵</p>
<p>eg:状态𝑠1：名词 状态𝑠2：动词 状态𝑠3：形容词</p>
<p>如果在该文字中某句子的第一个词为名词，那么该句子 中三类词出现顺序为O=“名动形名”的概率。</p>
<p><img src="/2021/12/24/NLP/image-20211227203903492.png" alt="image-20211227203903492" style="zoom:50%;"></p>
<p>马尔科夫(Markov)模型：有限状态机</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">马尔科夫模型可视为随机的有限状态机。</span><br><span class="line">圆圈表示状态，状态之间的转移用带箭头的弧表示，弧上</span><br><span class="line">的数字为状态转移的概率。</span><br><span class="line">初始状态用标记为start的输入箭头表示。</span><br><span class="line">假设任何状态都可作为终止状态。</span><br><span class="line">对每个状态来说，发出弧上的概率和为1。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>eg:</p>
<p><img src="/2021/12/24/NLP/image-20211227204121800.png" alt="image-20211227204121800" style="zoom:50%;"></p>
<p>一般地，一个HMM记为一个五元组μ＝（S，K， A，B，π），其中，S为状态的集合，K为输出符 号的集合，π，A和B分别是初始状态的概率分布、 状态转移概率和符号发射概率。为了简单，有时也将其记为三元组μ＝（A，B，π）</p>
<p>隐马尔可夫模型：三个基本问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.估值问题：给定一个观察序列 O = 𝑂1𝑂2 … 𝑂𝑇 和模型μ＝(A，</span><br><span class="line">B，π)，如何快速地计算出给定模型μ情况下，观察序列O的</span><br><span class="line">概率，即𝑃 𝑂 𝜇 ?</span><br><span class="line">2.序列问题：给定一个观察序列 O = 𝑂1𝑂2 … 𝑂𝑇 和模型μ＝(A，</span><br><span class="line">B，π),如何快速有效的选择在一定意义下“最优”的状态序</span><br><span class="line">列 𝑄 = 𝑞1𝑞2 … 𝑞𝑇 ，使得该状态序列“最好的解释”观察序列？</span><br><span class="line">3.参数估计问题：给定一个观察序列O = 𝑂1𝑂2 … 𝑂𝑇，如何根</span><br><span class="line">据最大似然估计来求模型的参数值？即如何调节模型μ＝(A，</span><br><span class="line">B，π)的参数，使得𝑃 𝑂 𝜇 最大？</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="隐马尔可夫模型：求解观察序列的概率"><a href="#隐马尔可夫模型：求解观察序列的概率" class="headerlink" title="隐马尔可夫模型：求解观察序列的概率"></a>隐马尔可夫模型：求解观察序列的概率</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给定观察序列O = 𝑂1𝑂2 … 𝑂𝑇和模型𝜇 =(𝐴, 𝐵, π)，快速的计算出给定模型𝜇情况下观察序列O的概率，即𝑃 （𝑂|𝜇） 。</span><br></pre></td></tr></table></figure>
<p><img src="/2021/12/24/NLP/image-20211227210645264.png" alt="image-20211227210645264" style="zoom:50%;"></p>
<p>隐马尔可夫模型：前向算法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">基本思想：定义前向变量𝛼𝑡(𝑖)，前向变量𝛼𝑡(𝑖)是在时间t，HMM输出了序列𝑂1𝑂2 … 𝑂𝑡 ，并且位于状态𝑠𝑖的概率。</span><br></pre></td></tr></table></figure>
<p><img src="/2021/12/24/NLP/image-20211227211103464.png" alt="image-20211227211103464" style="zoom:50%;"></p>
<p>前向算法总的复杂度为O(𝑁2𝑇)</p>
<p>隐马尔可夫模型：后向算法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">后向变量𝛽𝑡(𝑖)是在给定模型𝜇 = (𝐴, 𝐵, π)，并且在时间t状态为𝑠𝑖的条件下，HMM输出观察序列𝑂𝑡+1 … 𝑂𝑇的概率。</span><br></pre></td></tr></table></figure>
<p>与计算前向变量一样，可以用动态规划的算法计算后向变量。</p>
<p><img src="/2021/12/24/NLP/image-20211227211441031.png" alt="image-20211227211441031" style="zoom:50%;"></p>
<p>时间复杂度：O(𝑁2𝑇)</p>
<h4 id="序列问题"><a href="#序列问题" class="headerlink" title="序列问题"></a>序列问题</h4><p>隐马尔可夫模型：维特比算法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">维特比算法用于求解HMM中的第二个问题，给定一个观</span><br><span class="line">察序列O = 𝑂1𝑂2 … 𝑂𝑇和模型𝜇 = (𝐴, 𝐵, π)，如何快速有效</span><br><span class="line">的选择在一定意义下最优的状态序列𝑄 = 𝑞1𝑞2 … 𝑞𝑇，使得</span><br><span class="line">该状态序列“最好的解释”观察序列。</span><br></pre></td></tr></table></figure>
<p><img src="/2021/12/24/NLP/image-20211227211917788.png" alt="image-20211227211917788" style="zoom:50%;"></p>
<p><img src="/2021/12/24/NLP/image-20211227211938609.png" alt="image-20211227211938609" style="zoom:50%;"></p>
<p>存在问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">单独最优不一定整体最优</span><br></pre></td></tr></table></figure>
<h4 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h4><p>最 大似然估计</p>
<p>EM</p>
<h2 id="句法分析"><a href="#句法分析" class="headerlink" title="句法分析"></a>句法分析</h2><h3 id="句法分析概述"><a href="#句法分析概述" class="headerlink" title="句法分析概述"></a>句法分析概述</h3><p>基本任务：确定句子的句法结构或句子中词汇之间的依存关系。</p>
<p>定义：判断单词序列（一般为句子）判读其构成是否合乎 给定的语法(recognition)，如果是，则给出其（树）结构 (parsing)</p>
<p>描述一种语言可以有三种途径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">穷举法：把语言中的所有句子都枚举出来。显然，这种方法只适合句子数目有限的语</span><br><span class="line">语法/文法描述：语言中的每个句子用严格定义的规则来构造，利用规则生成语言中合法的句子</span><br><span class="line">自动机法：通过对输入句子进行合法性检验，区别哪些是语言中的句子，哪些不是语言中的句子</span><br></pre></td></tr></table></figure>
<p>形式语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">四元组 𝐺 = &#123;𝑁, Σ, 𝑃, 𝑆&#125;</span><br><span class="line">𝑁是非终结符(non-terminal symbol)的有限集合(有时也称变量集或句法种类集)</span><br><span class="line">Σ是终结符号(terminal symbol)的有限集合，𝑁 ∩ Σ = ∅</span><br><span class="line">𝑃是一组重写规则的有限集合：𝑃 = 𝛼 → 𝛽 ，其中𝛼, 𝛽是由V中元素构成的串，但是𝛼中至少应含一个非终结符</span><br><span class="line">𝑆 ∈ 𝑁称为句子符或初始符</span><br></pre></td></tr></table></figure>
<p>形式语法种类</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">正则文法</span><br><span class="line">上下文无关文法</span><br><span class="line">上下文相关文法</span><br><span class="line">无约束文法</span><br></pre></td></tr></table></figure>
<p>控制策略</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">自顶向下、自底向上</span><br><span class="line">移进-归约是自底向上语法分析的一种形式</span><br><span class="line"> 使用一个栈来保存文法符号，并用一个输入缓冲区来存放将要进行语</span><br><span class="line">法分析的其余符号</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>搜索策略</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">深搜广搜</span><br></pre></td></tr></table></figure>
<p>扫描策略</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">自左至右，自右至左</span><br></pre></td></tr></table></figure>
<p>移进-归约是自底向上语法分析的一种形式</p>
<p>CFG缺陷</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> 对于一个中等长度的输入句子来说，要利用大覆盖度的语法规</span><br><span class="line">则分析出所有可能的句子结构是非常困难的，分析过程的复杂</span><br><span class="line">度往往使程序无法实现</span><br><span class="line"> 即使能分析出句子所有可能的结构，也难以在巨大的句法分析</span><br><span class="line">结果集中实现有效的消歧，并选择出最有可能的分析结果</span><br><span class="line"> 手工编写的规则一般带有一定的主观性，对于实际应用系统来</span><br><span class="line">说，往往难以覆盖大领域的所有复杂语言</span><br><span class="line"> 写规则本身是一件大工作量的复杂劳动，而且编写的规则对特</span><br><span class="line">定的领域有密切的相关性，不利于句法分析系统向其他领域移</span><br><span class="line">植</span><br></pre></td></tr></table></figure>
<h3 id="概率上下文无关文法-PCFG"><a href="#概率上下文无关文法-PCFG" class="headerlink" title="概率上下文无关文法(PCFG)"></a>概率上下文无关文法(PCFG)</h3><p>概率上下文无关文法就是一个为规则增添了概率的简单CFG， 指明了不同重写规则的可能性大小</p>
<p>在基于PCFG的句法分析模型中，假设满足以下三个条件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">上下文无关性</span><br><span class="line">祖先无关性</span><br><span class="line">位置不变性</span><br></pre></td></tr></table></figure>
<p>剪枝策略：Beam search（集束搜索）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">一种启发式图搜索算法，为了减少搜索占用的时间和空间，在每一步深度扩展的时候，</span><br><span class="line">减掉一些质量比较差的节点，保留质量较高的一些节点</span><br><span class="line">优点是减少空间消耗，提高时间效率</span><br><span class="line">缺点是有可能存在潜在的最佳方案被丢弃，beam search算法是不完全的</span><br></pre></td></tr></table></figure>
<p>PCFG的优点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">可利用概率减少分析过程的搜索空间</span><br><span class="line">可以利用概率对概率较小的子树剪枝，加快分析效</span><br><span class="line">率</span><br><span class="line">可以定量地比较两个语法的性能</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>PCFG的缺陷</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">结构相关性</span><br><span class="line">词汇相关性</span><br></pre></td></tr></table></figure>
<h2 id="词义消歧"><a href="#词义消歧" class="headerlink" title="词义消歧"></a>词义消歧</h2><p>word sense disambiguation     WSD</p>
<p>义位：语义系统中能独立存在的基本语义单位</p>
<p>WSD需要解决三个问题：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(1)如何判断一个词是不是多义词？ 如何表示一个多义词的不同意思？</span><br><span class="line">(2)对每个多义词，预先要有关于它的 各个不同义项的清晰的区分标准</span><br><span class="line">(3)对出现在具体语境中的每个多义词，为它确定一个合适的义项</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">基于机器词典的WSD</span><br><span class="line">基于义类词典的WSD</span><br><span class="line">基于语料库的WSD</span><br><span class="line">基于统计方法的WSD</span><br><span class="line">基于规则的WSD</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">总结：</span><br><span class="line">用词典资源进行词义排歧，是利用词典中对多义</span><br><span class="line">词的各个义项的描写，求多义词的释义跟其上下</span><br><span class="line">文环境词的释义之间的交集，判断词义的亲和程</span><br><span class="line">度，来确定词义；</span><br><span class="line">由于词典释义的概括性，这种方法应用于实际语</span><br><span class="line">料中多义词的排歧，效果不一定理想</span><br></pre></td></tr></table></figure>
<p>基于义类词典的WSD方法</p>
<p><img src="/2021/12/24/NLP/image-20211227233833336.png" alt="image-20211227233833336" style="zoom:50%;"></p>
<p>互信息：I（X；Y）反映的是在知道了Y的值 以后X的不确定性的减少量。</p>
<p>基于Bayes判别的WSD方法</p>
<p><img src="/2021/12/24/NLP/image-20211227235729108.png" alt="image-20211227235729108" style="zoom:50%;"></p>
<p>词义消歧——基于多分类器集成</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">总结</span><br><span class="line">还有很多问题需要探讨</span><br><span class="line">❖如何选用更有效的分类器</span><br><span class="line">❖单分类器的结果怎样更高效地集成</span><br><span class="line">❖如何在单分类器中选取更有效的特征</span><br><span class="line"> 集成学习的研究对自然语言处理中的其他任务</span><br></pre></td></tr></table></figure>
<h2 id="篇章"><a href="#篇章" class="headerlink" title="篇章"></a>篇章</h2><p>概念</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Anaphor:指代语</span><br><span class="line">Entity(referent):实体（指称对象）</span><br><span class="line">Reference:指称。用于指称实体的语言表示</span><br><span class="line">Antecedent:先行语。语篇中引入的一个相对明确的指称意义表述（如张三）；</span><br><span class="line">Coreference:共指（同指）。当两种表述均指称相同对象（实体）时，这两种表述具有共指关系</span><br></pre></td></tr></table></figure>
<p>六类指称表示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> Indefinite NPs（不定名词）: 一辆汽车</span><br><span class="line"> Definite NPs （有定名词）: 那个人</span><br><span class="line"> Pronouns （人称代词）: 它，他</span><br><span class="line"> Demonstratives （指示代词）: 这，那</span><br><span class="line"> One-anaphora （one指代）: one (in English)</span><br><span class="line"> Zero anaphora （0型指代）: 省略</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>指代一般包括两种情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">– 回指(Anaphora)：强调指代语与另一个表述之间的关</span><br><span class="line">系。指代语的指称对象通常不明确，需要确定其与先行</span><br><span class="line">语之间的关系来解释指代语的语义</span><br><span class="line">• 张先生走过来，给大家看他的新作品</span><br><span class="line">– 共指(coreference)：强调一个表述与另一个表述是否</span><br><span class="line">指向相同的实体，可以独立于上下文存在</span><br><span class="line">• 第44任美国总统 与奥巴马</span><br></pre></td></tr></table></figure>
<h3 id="衔接和连贯"><a href="#衔接和连贯" class="headerlink" title="衔接和连贯"></a>衔接和连贯</h3><p>以词汇表示的关联，通常称为“衔接(cohesion)，强调其构成成分</p>
<p>通过句子意义表示的关联称为连贯Coherence，强调整体上表达某种意义</p>
<h3 id="篇章表示和相似度计算"><a href="#篇章表示和相似度计算" class="headerlink" title="篇章表示和相似度计算"></a>篇章表示和相似度计算</h3><p>将文档表示为如下所示的向量： 𝑑𝑗 = (𝑤1,𝑗 , 𝑤2,𝑗 , 𝑤3,𝑗 , … , 𝑤𝑡,𝑗)  向量的每一维都对应于词表中的一个词。  如果某个词出现在了文档中，那它在向量中的值就非 零。  这个值有很多计算方法，我们使用词语在文档中出现 的次数表示。</p>
<h2 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h2><h3 id="传统机器翻译方法"><a href="#传统机器翻译方法" class="headerlink" title="传统机器翻译方法"></a>传统机器翻译方法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">直接翻译法</span><br></pre></td></tr></table></figure>
<p>基于规则的翻译方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">对源语言和目标语言均进行适当描述</span><br><span class="line">吧翻译机制与语法分开</span><br><span class="line">用规则描述语法的翻译方式</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">▪优点：</span><br><span class="line">▪ 可以较好地保持原文的结构，产生的译文结构与源文的结构关系密切</span><br><span class="line">▪ 尤其对于语言现象的或句法结构的明确的源语言语句具有较强的处理能力</span><br><span class="line">▪弱点：</span><br><span class="line">▪ 规则一般由人工编写，工作量大，主观性强，一致性难以保障</span><br><span class="line">▪ 不利于系统扩充，对非规范语言现 象缺乏相应的处理能力</span><br></pre></td></tr></table></figure>
<p>基于实例的翻译方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">方法：输入语句-&gt;与事例相似度比较-&gt;翻译结果</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">▪ 方法优点</span><br><span class="line">▪ 不要求源语言句子必须符合语法规定;</span><br><span class="line">▪ 翻译机制一般不需要对源语言句子做深入分析;</span><br><span class="line">▪ 方法弱点</span><br><span class="line">▪ 两个不同的句子之间的相似性(包括结构相似性和语义相似性)往往难以把握</span><br><span class="line">▪ 在口语中，句子结构一般比较松散，成分冗余和成分省略都较严重;</span><br><span class="line">▪ 系统往往难以处理事例库中没有记录的陌生的语言现象；</span><br><span class="line">▪ 当事例库达到一定规模时，其事例检索的效率较低;</span><br></pre></td></tr></table></figure>
<h3 id="基于统计的机器翻译模型"><a href="#基于统计的机器翻译模型" class="headerlink" title="基于统计的机器翻译模型"></a>基于统计的机器翻译模型</h3><p>噪声信道模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一种语言T 由于经过一个噪声信道而发生变形从而在信道的另一端呈现为另一种语言 S</span><br></pre></td></tr></table></figure>
<p>翻译问题可定义为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">▪ 如何根据观察到的 S，恢复最为可能的T 问题。</span><br></pre></td></tr></table></figure>
<p><img src="/2021/12/24/NLP/image-20211228101907190.png" alt="image-20211228101907190" style="zoom:50%;"></p>
<p>▪三个关键问题 ▪ (1)估计语言模型概率 p(T)； ▪ (2)估计翻译概率 p(S|T)； ▪ (3)快速有效地搜索T 使得 p(T)×p(S | T) 最大</p>
<h4 id="基于词的统计机器翻译模型"><a href="#基于词的统计机器翻译模型" class="headerlink" title="基于词的统计机器翻译模型"></a>基于词的统计机器翻译模型</h4><p>IBM模型1：词汇翻译（词对齐）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">▪ 基于词的统计翻译模型</span><br><span class="line">▪ 引入了词对齐的问题</span><br><span class="line">▪ 通过EM算法学习词对齐</span><br><span class="line">▪ 缺陷</span><br><span class="line">▪ 无法刻画翻译过程中重排序、添词、舍词等情况；</span><br><span class="line">▪ 例如：</span><br><span class="line">▪ Seldom do I go to work by bus.</span><br><span class="line">▪ 我很少乘公共汽车上班</span><br></pre></td></tr></table></figure>
<p>IBM模型2：增加绝对对齐模型</p>
<p>IBM模型3：引入繁衍率模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">前述模型存在的问题</span><br><span class="line">▪ 在随机选择对位关系的情况下，与目标语言句子中的单词t对应的源语言句子中的单</span><br><span class="line">词数目是一个随机变量；</span><br></pre></td></tr></table></figure>
<p>繁衍率</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">定义：与目标语言句子中的单词t对应的源语言句子中的单词数目的变量</span><br><span class="line">▪ 记做Фt，称该变量为单词t的繁衍能力或产出率(fertility)。一个具体的取值记做：Фt</span><br><span class="line">▪ 繁衍率刻画的是目标语言单词与源语言单词之间一对多的关系</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="基于短语的统计机器翻译模型"><a href="#基于短语的统计机器翻译模型" class="headerlink" title="基于短语的统计机器翻译模型"></a>基于短语的统计机器翻译模型</h4><p>基本思想</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">▪ 把训练语料库中所有对齐的短语及其翻译概率存储起来，作为一部带</span><br><span class="line">概率的短语词典</span><br><span class="line">▪ 这里所说的短语是任意连续的词串，不一定是一个独立的语言单位</span><br><span class="line">▪ 翻译的时候将输入的句子与短语词典进行匹配，选择最好的短语划分，</span><br><span class="line">将得到的短语译文重新排序，得到最优的译文.</span><br></pre></td></tr></table></figure>
<h3 id="系统融合"><a href="#系统融合" class="headerlink" title="系统融合"></a>系统融合</h3><p>几个相似的系统执行同一个任务时，可能有多个输出结果，系统融合将这些结果进行融 合，抽取其有用信息，归纳得到任务的最终输出结果。</p>
<p>目标：最终的输出比之前的输入结果都要好</p>
<p>句子级系统融合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">两种技术</span><br><span class="line">最小贝叶斯风险解码；通用线性模型</span><br></pre></td></tr></table></figure>
<p>句子级系统融合方法不会产生新的翻译句子，而是在已有的翻 译句子中挑选出最好的一个</p>
<p>短语级系统融合 ▪ 利用多个翻译系统的输出结果，重新抽取短语翻译规则集合，并利用 新的短语翻译规则进行重新解码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">基本思想：首先合并参与融合的所有系统的短语表，从中抽取</span><br><span class="line">一个新的源语言到目标语言的短语表，然后使用新的短语表和</span><br><span class="line">语言模型去重新解码源语言句子。</span><br></pre></td></tr></table></figure>
<p>词语级系统融合 ▪ 首先将多个翻译系统的译文输出进行词语对齐，构建一个混淆网络， 对混淆网络中的每个位置的候选词进行置信度估计， 最后进行混淆网 络解码</p>
<p>小结</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">句子级系统融合</span><br><span class="line">▪ 未生成新的翻译假设，有效的保护原来翻译假设中短语的连续性和句子词序，但</span><br><span class="line">是也没有吸收借鉴其他翻译假设中词或者短语层次的知识。</span><br><span class="line">▪ 短语级系统融合</span><br><span class="line">▪ 借鉴其他翻译系统的短语表知识，利用传统的基于短语的翻译引擎来重新解码源</span><br><span class="line">语言的句子。有效的保持短语的连续性和译文的局部词序。但是不能很好的利用</span><br><span class="line">非连续短语和句法知识来克服译文的远距离调序问题</span><br><span class="line">▪ 词语级系统融合</span><br><span class="line">▪ 从词的粒度重组了输出译文，充分利用了各个翻译假设的词汇级别的知识，取长</span><br><span class="line">补短。但是在混淆网络解码时，并不能保证新生成的翻译句子的词序一致性和短</span><br><span class="line">语连续性</span><br></pre></td></tr></table></figure>
<h2 id="应用：语言自动生成"><a href="#应用：语言自动生成" class="headerlink" title="应用：语言自动生成"></a>应用：语言自动生成</h2><h3 id="自然语言生成概述"><a href="#自然语言生成概述" class="headerlink" title="自然语言生成概述"></a>自然语言生成概述</h3><p>NLG生成模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1. 马尔可夫链：通过当前单词可以预测句子中的下一个单</span><br><span class="line">词。</span><br><span class="line">缺点：无法探测当前单词与句子中其他单词的关系以及句</span><br><span class="line">子的结构，使得预测结果不够准确。</span><br><span class="line">2. 循环神经网络(RNN)：通过前馈网络传递序列的每个项目</span><br><span class="line">信息，并将模型的输出作为序列中下一项的输入，每个项</span><br><span class="line">目存储前面步骤中的信息。</span><br><span class="line">优点：能够捕捉输入数据的序列特征</span><br><span class="line">缺点：第一，RNN短期记忆无法生成连贯的长句子；第二，</span><br><span class="line">因为 RNN 不能并行计算，无法适应主流趋势。</span><br><span class="line">3. 长短期记忆网络(LSTM)，解决梯度消失问题，但难以并行化</span><br><span class="line">4. Seq2Seq，能够解决大部分序列不等长的问题</span><br><span class="line">5. Attention模型</span><br><span class="line">6. Transformer模型，能够在不考虑单词位置的情况</span><br><span class="line">下，直接捕捉句子中所有单词之间的关系</span><br><span class="line">7. ELMO模型</span><br><span class="line">8. BERT模型</span><br></pre></td></tr></table></figure>
<h3 id="数据到文本的生成"><a href="#数据到文本的生成" class="headerlink" title="数据到文本的生成"></a>数据到文本的生成</h3><p>以包含键值对的数据作为输入，旨在 自动生成流畅的、贴近事实的文本以描 述输入数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> 信号分析模块(Siganl Analysis)</span><br><span class="line"> 数据阐释模块(Data Interpretation)</span><br><span class="line"> 文档规划模块(Document Planning)</span><br><span class="line"> 微规划与实现模块(Microplanning and Realisation)</span><br></pre></td></tr></table></figure>
<p>应用领域：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 天气预报领域的文本生成系统</span><br><span class="line"> 针对空气质量的文本生成系统</span><br><span class="line"> 针对财经数据的文本生成系统</span><br><span class="line"> 面向医疗诊断数据的文本生成系统</span><br><span class="line"> 基于体育数据生成文本摘要</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="文本到文本的生成"><a href="#文本到文本的生成" class="headerlink" title="文本到文本的生成"></a>文本到文本的生成</h3><p>对给定文本进行变换和处理从而获得新文本的技术</p>
<p>应用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> 对联自动生成</span><br><span class="line"> 诗歌自动生成</span><br><span class="line"> 作文自动生成</span><br><span class="line"> 对话生成*---这个任务现阶段一般不作为NLG的研究分支来探讨</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="词和文档表示与相似度计算"><a href="#词和文档表示与相似度计算" class="headerlink" title="词和文档表示与相似度计算"></a>词和文档表示与相似度计算</h2><h3 id="词的表示"><a href="#词的表示" class="headerlink" title="词的表示"></a>词的表示</h3><p>独热表示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">每个词对应一个向量，向量的维度等于词典的大小，向量中只有一个元素值为1，其余的元素均为0 ，值为1的元素对应的下标为该词在词典中的位置</span><br></pre></td></tr></table></figure>
<p>词频 -逆文档频率(TF -IDF)</p>
<p>词嵌入方法的问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">静态词向量</span><br><span class="line">词向量无法随语境变化</span><br><span class="line">不能处理一词多义</span><br><span class="line">多义词无法区分多个含义</span><br><span class="line">不能有效区分反义词</span><br><span class="line">反义词的上下文很相似</span><br></pre></td></tr></table></figure>
<p>词向量</p>
<p>skip-gram</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1. 将目标词和邻近的 </span><br><span class="line">语境词作为正面例子。</span><br><span class="line">2.随机抽取词库中的其他词 </span><br><span class="line">词库中的其他词，以获得负面样本。</span><br><span class="line">3. 使用逻辑回归来训练一个分类器，以区分这两种情况。</span><br><span class="line">区分这两种情况。</span><br><span class="line">4. 使用权重作为嵌入。</span><br></pre></td></tr></table></figure>
<h3 id="文档表示"><a href="#文档表示" class="headerlink" title="文档表示"></a>文档表示</h3><p><img src="/2021/12/24/NLP/image-20211228162546651.png" alt="image-20211228162546651" style="zoom:50%;"></p>
<h3 id="文本相似度计算"><a href="#文本相似度计算" class="headerlink" title="文本相似度计算"></a>文本相似度计算</h3><p>编辑距离，动态规划</p>
<h2 id="信息抽取"><a href="#信息抽取" class="headerlink" title="信息抽取"></a>信息抽取</h2><h3 id="信息抽取的定义、任务及发展"><a href="#信息抽取的定义、任务及发展" class="headerlink" title="信息抽取的定义、任务及发展"></a>信息抽取的定义、任务及发展</h3><p>信息抽取中的主要任务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">命名实体识别：</span><br><span class="line">识别和分类文本中出现的“实体提及”</span><br><span class="line">实体链接：</span><br><span class="line">将“实体提及”链接到知识库中对应的实体</span><br><span class="line">关系抽取：</span><br><span class="line">找到句子中有关系的两个实体，并识别出他们之间的关系类型</span><br><span class="line">事件抽取：</span><br><span class="line">事件抽取就要是找到一个事件对应的元素。</span><br></pre></td></tr></table></figure>
<h3 id="命名实体识别"><a href="#命名实体识别" class="headerlink" title="命名实体识别"></a>命名实体识别</h3><p>挑战</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">种类繁多，命名方式灵活多样</span><br><span class="line">同一实体对应很多变体</span><br><span class="line">相同的词或者短语可以表示不同类别的实</span><br><span class="line">体</span><br><span class="line">存在嵌套</span><br><span class="line">细粒度</span><br><span class="line">语言不断进化，新的挑战不断出现</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>主要方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">基于规则的方法 基于词典的方法 机器学习方法 ◼最大熵 ◼条件随机场 ◼深度学</span><br></pre></td></tr></table></figure>
<p>命名实体识别的评价</p>
<p><img src="/2021/12/24/NLP/image-20211228163639194.png" alt="image-20211228163639194" style="zoom:50%;"></p>
<p><img src="/2021/12/24/NLP/image-20211228163649954.png" alt="image-20211228163649954" style="zoom:50%;"></p>
<h3 id="实体链接"><a href="#实体链接" class="headerlink" title="实体链接"></a>实体链接</h3><p>将“实体提及”链接到知识库中对应的实体</p>
<h3 id="关系抽取"><a href="#关系抽取" class="headerlink" title="关系抽取"></a>关系抽取</h3><p>自动识别由一对实体和联系这对实体的关系构成的 相关三元组</p>
<p>预定义关系抽取</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">任务</span><br><span class="line">给定实体关系类别，给定语料，抽取目标关系对</span><br><span class="line">评测语料（MUC, ACE, KBP, SemEval）</span><br><span class="line">专家标注语料，语料质量高</span><br><span class="line">抽取的目标类别已经定义好</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>基于神经网络的关系抽取方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">主要问题：如何设计合理的网络结构，从而捕捉更多的信息，进而更准确的完成关系的抽取</span><br><span class="line">网络结构：不同的网络结构捕捉文本中不同的信息</span><br></pre></td></tr></table></figure>
<p>开放域关系抽取</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">实体类别和关系类别不固定、数量大</span><br><span class="line">难点问题</span><br><span class="line"> 如何获取训练语料</span><br><span class="line"> 如何获取实体关系类别</span><br><span class="line"> 如何针对不同类型目标文本抽取关系</span><br><span class="line">需要研究新的抽取方法</span><br><span class="line"> 基于句法的方法</span><br><span class="line"> 基于知识监督的方法</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="深度学习简介"><a href="#深度学习简介" class="headerlink" title="深度学习简介"></a>深度学习简介</h2><p>常用的深度学习模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">激活函数</span><br><span class="line">深度神经网络（Deep Neural Network, DNN）</span><br><span class="line">卷积神经网络（Convolutional Neural Network,CNN)</span><br><span class="line">循环神经网络 (Recurrent Neural Network, RNN) </span><br><span class="line">注意力机制（Attention Mechanisms）</span><br></pre></td></tr></table></figure>
<p>pooling</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">目的：</span><br><span class="line">扩大视野：就如同先从近处看一张图片，然后离远一些再看同一张图片，有些细节就会被忽略。</span><br><span class="line">降维：在保留图片局部特征的前提下，使得图片更小，更易于计算。</span><br><span class="line">平移不变性，轻微扰动不会影响输出。</span><br><span class="line">维持同尺寸，便于后端处理。</span><br></pre></td></tr></table></figure>
<p>深度学习模型的应用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DBN的应用</span><br><span class="line">基于DBN的问答对挖掘</span><br><span class="line">CNN的应用</span><br><span class="line">关系分类</span><br><span class="line">句子分类</span><br><span class="line">LSTM-RNN的应用</span><br><span class="line">命名实体识别</span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">40</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
