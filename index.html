<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/" class="post-title-link" itemprop="url">任务管理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-14 18:39:21" itemprop="dateCreated datePublished" datetime="2022-04-14T18:39:21+08:00">2022-04-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-15 16:46:32" itemprop="dateModified" datetime="2022-04-15T16:46:32+08:00">2022-04-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="任务管理"><a href="#任务管理" class="headerlink" title="任务管理"></a>任务管理</h1><h2 id="任务管理概述"><a href="#任务管理概述" class="headerlink" title="任务管理概述"></a>任务管理概述</h2><p>一个任务是一个处理器可以调度、执行和暂停的工作单位。它可以用来执行一个程序，一个任务或进程，一个操作系统服务工具，一个中断或异常处理程序，或一个内核或执行实用程序。</p>
<p>IA-32结构提供了一种机制，用于保存任务的状态，调度任务的执行，以及从一个任务切换到另一个任务。当在保护模式下运行时，所有的处理器执行都是在任务内进行的，即使是简单的系统也必须至少定义一个任务。更复杂的系统可以使用处理器的任务管理设施来支持多任务的应用。</p>
<p>一个过程调用包括将数据（以<strong>参数</strong>和<strong>返回值</strong>的形式）与控制从代码的一部分传递到另一部分。除此之外，在进入时为过程的局部变量分配空间，在退出的时候释放这些空间。数据传递、局部变量的分配和释放通过操纵程序栈来实现。</p>
<p>操作系统实现宏观上并行任务的效果，其本质是微观上在多个任务之间切换。因此，当操作系统由任务A切换到任务B时，需要暂停任务A的执行，并将处理器执行任务A时各个寄存器的值保存到内存的某个位置上，这个过程叫做保存现场；之后将处理器上一次执行任务B时各个寄存器的值由内存中的某个位置回复到处理的寄存器当中，这个过程叫做恢复现场。当操作系统在调度时由任务A切换到任务B时，对任务A保存现场，对任务B恢复现场，这个整体的过程称之为：上下文切换。</p>
<p>在每一个任务在执行之前，操作系统都需要为其分配一个专属的内存区域供其使用，这个内存区域通常被称为此任务的栈（stack）。Cortex-M有两个堆栈寄存器，主栈指针（MSP）与进程栈指针（PSP）。主程序操作系统和各个中断函数使用的是MSP指针，而各个被调度的任务（进程）使用的是PSP指针。本质上它是处理器的一个寄存器，PSP寄存器的值就是内存中任务的栈地址。</p>
<h3 id="任务的结构"><a href="#任务的结构" class="headerlink" title="任务的结构"></a>任务的结构</h3><p>一个任务由两部分组成：一个任务执行空间和一个任务状态段（TSS）。任务执行空间由一个代码段、一个堆栈段和一个或多个数据段组成（见图7-1）。如果操作系统或执行程序使用处理器的特权级别保护机制，任务执行空间也会为每个特权提供一个单独的堆栈。<br>TSS指定了组成任务执行空间的段，并为任务状态信息提供了一个存储位置信息。在多任务系统中，TSS还提供了一种连接任务的机制。<br>一个任务由其TSS的段选择器来识别。当一个任务被加载到处理器中执行时，它的段选择器、基地址、限制和段描述符属性被加载到任务的寄存器。如果任务实现了分页，任务所使用的页面目录的基地址被加载到控制寄存器CR3。</p>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220414193049801.png" alt="image-20220414193049801"></p>
<h3 id="任务状态"><a href="#任务状态" class="headerlink" title="任务状态"></a>任务状态</h3><p>以下项目定义了当前执行的任务的状态：</p>
<ul>
<li>任务的当前执行空间，由段寄存器（CS、DS、SS、ES、GS、FS和GS）中的段选择器定义。</li>
<li>通用寄存器的状态。</li>
<li>EFLAGS寄存器的状态。</li>
<li>EIP寄存器的状态。</li>
<li>控制寄存器CR3的状态。</li>
<li>任务寄存器的状态。</li>
<li>LDTR寄存器的状态。</li>
<li>I/O地图的基址和I/O地图（包含在TSS中）。</li>
<li>特权0、1和2堆栈的堆栈指针（包含在TSS中）。</li>
<li>与先前执行的任务的链接（包含在TSS中）。<br>在调度任务之前，所有这些项目都包含在任务的TSS中，除了任务寄存器的状态。另外，LDTR寄存器的全部内容不包含在TSS中，只有LDT的段选择器。</li>
</ul>
<h3 id="任务的执行"><a href="#任务的执行" class="headerlink" title="任务的执行"></a>任务的执行</h3><p>软件或处理器可以通过以下方式之一调度一个任务的执行。</p>
<ul>
<li>用CALL指令明确调用一个任务。</li>
<li>用JMP指令显式跳转到一个任务。</li>
<li>隐式调用（由处理器）到一个中断处理任务。</li>
<li>对一个异常处理任务的隐式调用。</li>
<li>当EFLAGS寄存器中的NT标志被设置时，返回（用IRET指令启动）。</li>
</ul>
<p>所有这些调度任务的方法都是用一个段选择器来识别要调度的任务，这个段选择器指向任务门或任务的TSS。当用CALL或JMP指令调度任务时，指令中的选择器可以直接选择TSS或持有TSS的选择器的任务门。当调度一个任务来处理一个中断或异常时，中断或异常的IDT条目必须包含一个任务门，它持有中断或异常处理程序TSS的选择器。<br>当一个任务被调度执行时，在当前运行的任务和被调度的任务之间会发生一个任务切换。在任务切换期间，当前执行的任务的执行环境（称为任务的状态或上下文）被保存在其TSS中，任务的执行被暂停。被派遣任务的上下文被加载到处理器中，该任务的执行从新加载的EIP寄存器所指向的指令开始。如果任务在系统上次初始化后没有运行过，EIP将指向任务代码的第一条指令；否则，它将指向任务最后执行的指令之后的下一条指令。<br>如果当前执行的任务（调用任务）调用了被派发的任务（被调用任务），则段选择器被存储在被调用任务的TSS中，以提供与调用任务的链接。<br>对于所有IA-32处理器，任务不是递归的。一个任务不能调用或跳转到自身。中断和异常可以通过任务切换到一个处理任务来处理。在这里，处理器执行一个任务来处理中断或异常，从中断处理任务或异常处理任务返回后，自动切换回被中断的任务。这种机制也可以处理在中断任务中发生的中断。<br>作为任务切换的一部分，处理器也可以切换到另一个LDT，允许每个任务对基于LDT的段有不同的逻辑到物理地址的映射。在任务切换时，页面目录基础寄存器（CR3）也被重新加载，允许每个任务有它自己的一套页表。这些保护设施有助于隔离任务并防止它们相互干扰。<br>如果不使用保护机制，处理器不提供任务之间的保护。这一点即使在操作系统也是如此，该系统使用多个特权级别进行保护。一个运行在特权级别3的任务，使用与其他任务相同的LDT和页表。</p>
<h2 id="任务的数据结构"><a href="#任务的数据结构" class="headerlink" title="任务的数据结构"></a>任务的数据结构</h2><p>处理器定义了五个数据结构来处理与任务有关的活动。</p>
<ul>
<li>任务状态段（TSS）。</li>
<li>任务门描述符。</li>
<li>TSS描述符。</li>
<li>任务寄存器。</li>
<li>EFLAGS寄存器中的NT标志。</li>
</ul>
<p>当在保护模式下运行时，必须为至少一个任务创建一个TSS和TSS描述符，并且TSS的段选择器必须被加载到任务寄存器中（使用LTR指令）。</p>
<h3 id="任务状态段-Task-State-Segment-TSS"><a href="#任务状态段-Task-State-Segment-TSS" class="headerlink" title="任务状态段 Task-State Segment (TSS)"></a>任务状态段 Task-State Segment (TSS)</h3><p>恢复一个任务所需的处理器状态信息被保存在一个叫做任务状态段（TSS）的系统段中。图7-2显示了为32位CPU设计的任务的TSS的格式。TSS的字段被分为两个主要类别：动态字段和静态字段。<br><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220414195850785.png" alt="image-20220414195850785"></p>
<p>在任务切换期间，当一个任务被暂停时，处理器会更新动态字段。以下是动态字段。</p>
<ul>
<li>通用寄存器字段 - EAX, ECX, EDX, EBX, ESP, EBP, ESI, 和 EDI 寄存器在任务切换前的状态。</li>
<li>分段选择器字段—在任务切换前存储在ES、CS、SS、DS、FS和GS寄存器中的分段选择器。</li>
<li>EFLAGS寄存器字段 - 任务切换前EFAGS寄存器的状态。</li>
<li>EIP（指令指针）字段 - 任务切换前EIP寄存器的状态。</li>
<li>前一个任务链接字段—包含前一个任务的TSS的段选择器（在由调用、中断或异常启动的任务切换中更新）。这个字段（有时被称为后端链接字段）允许通过使用IRET指令将任务切换到前一个任务。处理器读取静态字段，但通常不改变它们。这些字段是在一个任务被创建时设置的。<br>以下是静态字段。</li>
<li>LDT段选择器字段 - 包含任务的LDT的段选择器。</li>
<li>CR3控制寄存器字段 - 包含任务要使用的页面目录的基本物理地址。控制寄存器CR3也被称为页面目录基础寄存器（PDBR）。</li>
<li>权限级别-0、-1和-2的堆栈指针字段—这些堆栈指针包括一个逻辑地址，由堆栈段的段选择器（SS0、SS1和SS2）和堆栈的偏移量（ESP0, ESP1和ESP2）组成。注意，这些字段的值对于一个特定的任务来说是静态的；而SS和ESP的值会在任务中发生堆栈切换时改变。</li>
<li>T（调试陷阱）标志（字节100，位0）—当设置时，T标志会使处理器在任务切换到这个任务时引发一个调试异常。</li>
<li>I/O地图基址字段 - 包含从TSS的基点到I/O权限位的图和中断重定向位图的16位偏移。当存在时，这些地图以更高的地址存储在TSS中。</li>
<li>避免在处理器在任务切换时读取的TSS部分（前104字节）放置页面边界。如果边界出现在这个区域，处理器可能无法正确执行地址转换。在任务切换过程中，处理器在每个TSS的前104个字节中进行读写（使用连续的物理地址，从任务的物理地址开始）。所以，在TSS访问开始后，如果104字节中的一部分 不是物理上连续的，处理器将访问不正确的信息，而不会产生页面错误异常。</li>
<li>与前一个任务的TSS、当前任务的TSS相对应的页面，以及每个任务的描述符表项都应该被标记为读/写。</li>
</ul>
<p>如果包含这些结构的页面在任务切换开始前就已经存在于内存中，那么任务切换的速度会更快。</p>
<h3 id="TSS-描述符"><a href="#TSS-描述符" class="headerlink" title="TSS 描述符"></a>TSS 描述符</h3><p>TSS，像所有其他段一样，是由段描述符定义的。图7-3显示了TSS的格式 。TSS描述符只能放在GDT中，它们不能放在LDT或IDT中。<br>试图使用设置了TI标志（表示当前的LDT）的段选择器访问一个TSS，会导致在CALLs和JMPs期间会产生一个一般保护异常（#GP）；在IRETs期间会产生一个无效的TSS异常（#TS）。如果试图将一个TSS的段选择器加载到一个段寄存器中，也会产生一般保护异常。<br>类型字段中的繁忙标志（B）表示任务是否繁忙。一个繁忙的任务目前正在运行或暂停。类型字段的值为1001B表示一个不活动的任务；值为1011B表示一个繁忙的任务。<br>处理器使用繁忙标志来检测调用一个执行被中断的任务的尝试。为了确保只有一个繁忙标志与一个任务相关联，每个TSS应该只有一个TSS描述符指向它。</p>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220414201925534.png" alt="image-20220414201925534"></p>
<p>基数、极限和DPL字段以及粒度和当前标志的功能与它们在数据段描述符中的使用类似。当32位TSS描述符中的G标志为0时，极限字段必须是32位TSS描述符中的极限。TSS描述符中G标志为0时，极限字段的值必须等于或大于67H，比TSS的最小尺寸少一个字节。<br>试图切换到一个TSS描述符的极限值小于67H的任务，会产生一个无效的TSS异常（#TS）。如果包括一个I/O权限位图或操作系统存储了额外的数据，则需要一个更大的限制。处理器不检查任务开关上是否有大于67H的限制；但是，当访问I/O权限位图或中断重定向位图时，它将进行检查。<br>任何可以访问TSS描述符的程序或过程（即其CPL在数字上等于或小于的DPL）可以通过调用或跳转来调度任务。<br>在大多数系统中，TSS描述符的DPL被设置为小于3的值，因此只有特权软件才能进行任务切换。然而，在多任务应用程序中，一些TSS描述符的DPLs可能被设置为3，以便允许在应用程序（或用户）权限级别进行任务切换。</p>
<h3 id="任务寄存器"><a href="#任务寄存器" class="headerlink" title="任务寄存器"></a>任务寄存器</h3><p>任务寄存器持有16位段选择器和整个段描述符（32位基本地址（在IA-32e模式下为64位 ），16位段限制和描述符属性），用于当前任务的TSS。<br>这个信息是从当前任务的GDT中的TSS描述符中复制过来的。图7-5显示了处理器访问TSS的路径 （使用任务寄存器中的信息）。任务寄存器有一个可见的部分（可以被软件读取和改变）和一个不可见的部分（由处理器维护，不能访问）。可见部分的段选择器指向GDT中的一个TSS描述符。处理器使用任务寄存器的不可见部分来缓存段描述符 。在寄存器中缓存这些值使得任务的执行更加有效。LTR（加载任务<br>寄存器）和STR（存储任务寄存器）指令加载和读取任务寄存器的可见部分。<br>LTR指令将段选择器（源操作数）加载到任务寄存器中，指向GDT中的TSS描述符。然后它用TSS描述符的信息加载任务寄存器的不可见部分。LTR是一个 特权指令，只有当CPL为0时才能执行。之后，当任务切换发生时，任务寄存器的内容会被隐含地改变。<br>STR(存储任务寄存器)指令将任务寄存器的可见部分存储在一个通用寄存器或内存中。这条指令可以被运行在任何权限级别的代码执行，以识别当前的运行的任务。然而，它通常只被操作系统软件使用。在处理器上电或复位时，段选择器和基地址被设置为默认值0；极限值<br>被设置为FFFH。</p>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220414203302131.png" alt="image-20220414203302131"></p>
<h3 id="任务门描述符"><a href="#任务门描述符" class="headerlink" title="任务门描述符"></a>任务门描述符</h3><p>任务门描述符提供了对一个任务的间接的、受保护的引用（见图7-6）。它可以被放置在GDT、LDT或IDT中。任务门描述符中的TSS段选择器字段指向GDT中的一个TSS描述符。该段选择器中的RPL不被使用。任务门描述符的DPL在任务切换期间控制对TSS描述符的访问。当一个程序或过程通过任务门调用或跳转到一个任务时，指向任务门的门选择器的CPL和RPL域必须小于或等于任务门描述符的DPL。请注意，当任务门被使用时 ，目标TSS描述符的DPL不被使用。</p>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220414204423254.png" alt="image-20220414204423254"></p>
<p>一个任务可以通过一个任务门描述符或一个TSS描述符来访问。这两种结构都满足以下需求。</p>
<ul>
<li>一个任务只需要一个繁忙标志 - 因为一个任务的繁忙标志是存储在TSS描述符中，每个任务应该只有一个TSS描述符。然而，可能有几个任务门会引用同一个TSS描述符。</li>
<li>需要提供对任务的选择性访问—任务门满足这一需求，因为它们可以驻留在一个LDT中，并且可以有一个与TSS描述符的DPL不同的DPL。一个程序或过程如果没有足够的权限访问GDT中任务的TSS描述符（通常DPL为0）的程序或过程可以通过一个具有更高DPL的任务门来访问该任务。任务门给了操作系统更大的限制对特定任务的访问的自由度。</li>
<li>需要一个独立的任务来处理中断或异常 - 任务门也可以驻留在IDT中。在IDT中，它允许中断和异常由处理任务来处理。当一个中断或异常向量指向一个任务门时，处理器会切换到指定的任务。图7-7说明了LDT中的任务门、GDT中的任务门和IDT中的任务门如何都能指向同一个任务。</li>
</ul>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220414210542784.png" alt="image-20220414210542784"></p>
<h2 id="任务切换"><a href="#任务切换" class="headerlink" title="任务切换"></a>任务切换</h2><p>处理器在四种情况中的一种将执行转移到另一个任务。</p>
<ul>
<li>当前程序、任务或过程执行JMP或CALL指令到GDT中的TSS描述符。</li>
<li>当前程序、任务或过程执行JMP或CALL指令到GDT或当前LDT中的任务门描述符。</li>
<li>中断或异常向量指向IDT中的一个任务门描述符。</li>
<li>当EFLAGS寄存器中的NT标志被设置时，当前任务执行一个IRET。JMP、CALL和IRET指令，以及中断和异常，都是重定向程序的机制。对TSS描述符或任务门的引用（当调用或跳转到一个任务时）或NT标志的状态（当执行IRET时）都是重定向的机制。NT标志的状态（执行IRET指令时）决定是否发生任务切换。当切换到一个新的任务时，处理器会执行以下操作：</li>
</ul>
<ol>
<li>获得新任务的TSS段选择器，作为JMP或CALL指令的操作数，从任务门或前一个任务链接字段（对于用IRET指令启动的任务切换）获得新任务的TSS段选择器。</li>
<li>检查当前（旧）任务是否被允许切换到新任务。数据访问权限规则适用于JMP和CALL指令。当前（旧）任务的CPL和新任务的段选择器的RPL必须小于或等于被引用的TSS描述符或任务门的DPL。例外的情况，中断（由INT n指令产生的中断除外）和IRET指令被允许切换任务，而不考虑TSS描述符的DPL。对于INT n指令产生的中断，要检查DPL。</li>
<li>检查新任务的TSS描述符是否被标记为存在，并且有一个有效的限制（大于或等于67H）。</li>
<li>检查新任务是否可用（调用、跳转、异常或中断）或繁忙（IRET返回）。</li>
<li>检查当前（旧）TSS、新TSS和任务切换中使用的所有段描述符是否被分页到系统内存中。</li>
<li>如果任务切换是由JMP或IRET指令启动的，处理器将清除当前（旧）任务的TSS中的忙（B）标志；如果用CALL指令、异常或中断启动：忙（B）标志保持不变。</li>
<li>如果任务切换是由IRET指令启动的，处理器将清除EFLAGS寄存器中临时保存的NT标志；如果是由CALL或JMP指令、异常或中断启动的，则NT标志在EFLAGS寄存器中保持不变。</li>
<li>在当前任务的TSS中保存当前（旧）任务的状态。处理器在任务寄存器中找到当前TSS的基地址 ，然后将下列寄存器的状态复制到当前的TSS中：所有的通用寄存器，段寄存器中的段选择器，临时保存的EFLAGS寄存器的映像，以及指令指针寄存器（EIP）。</li>
<li>如果任务切换是由CALL指令、异常或中断启动的，处理器将设置EFLAGS寄存器中的NT标志。如果是用IRET指令或JMP指令启动的，NT标志将反映新任务中加载的EFLAGS的NT状态（见表7-2）。</li>
<li>如果任务切换是由CALL指令、JMP指令、异常或中断启动的，处理器就会在新任务的TSS描述符中设置繁忙(B)标志；如果是由IRET指令启动的，繁忙(B)标志就保持不变。</li>
<li>用段选择器和新任务的TSS的描述符加载任务寄存器。</li>
<li>TSS状态被加载到处理器中。这包括LDTR寄存器，PDBR(控制寄存器CR3)，EFLAGS寄存器，EFLAGS寄存器，<br>EIP寄存器，通用寄存器，以及段选择器。在这个状态的加载过程中出现的故障可能会破坏架构状态。(如果没有启用分页，PDBR值会从新任务的TSS中读出，但它不会被加载到CR3中）。</li>
<li>与段选择器相关的描述符被加载和限定。与此相关的任何错误都发生在新任务的上下文中，并可能破坏架构状态。</li>
</ol>
<p><strong>注意事项</strong><br>如果所有的检查和保存都成功进行了，处理器就会提交给任务开关。如果在步骤1到11中发生了不可恢复的错误，处理器不会完成任务切换，并确保处理器返回到执行启动任务切换的指令之前的状态。<br>如果一个不可恢复的错误发生在步骤12，架构状态可能会被破坏，但会试图将在先前的执行环境中处理该错误。如果一个不可恢复的错误发生在提交点之后（在步骤13），处理器完成了任务切换（不执行额外的访问和段可用性检查），并在开始执行新的任务之前产生适当的异常。<br>如果异常发生在提交点之后，异常处理程序必须完成任务切换本身然后才允许处理器开始执行新的任务。</p>
<ol>
<li>开始执行新任务。(对于异常处理程序来说，新任务的第一条指令似乎没有被执行）。</li>
</ol>
<p>当一个成功的任务切换发生时，当前执行的任务的状态总是被保存。如果该任务被恢复 ，执行将从保存的EIP值所指向的指令开始，并且寄存器被恢复到 任务暂停时的值。<br>当切换任务时，新任务的权限级别不会继承被暂停的任务的权限级别。新的任务以CS寄存器的CPL字段中指定的权限级别开始执行，CS寄存器是由TSS加载的。因为任务被它们独立的地址空间和TSS所隔离，并且因为特权规则控制对TSS的访问，所以任务在执行时，需要有足够的权限。<br>表7-1显示了处理器在切换任务时检查的异常条件。它还显示了如果检测到错误，每个检查都会产生异常，以及错误代码所引用的段。<br><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220414215039998.png" alt="image-20220414215039998"></p>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220414215048323.png" alt="image-20220414215048323"></p>
<p><strong>注意</strong></p>
<ol>
<li><h1 id="NP是段不存在异常，-GP是一般保护异常，-TS是无效TSS异常，-SS是堆栈故障异常。"><a href="#NP是段不存在异常，-GP是一般保护异常，-TS是无效TSS异常，-SS是堆栈故障异常。" class="headerlink" title="NP是段不存在异常，#GP是一般保护异常，#TS是无效TSS异常，#SS是堆栈故障异常。"></a>NP是段不存在异常，#GP是一般保护异常，#TS是无效TSS异常，#SS是堆栈故障异常。</h1></li>
<li>错误代码包含了这一列中引用的段描述符的索引。</li>
<li>如果一个段选择器在一个兼容类型的表中（GDT或LDT），在表的段限制内占据一个地址，那么它是有效的。<br>并且指向兼容的描述符类型（例如，CS寄存器中的段选择器只有当它指向代码段描述符时才有效）。</li>
</ol>
<p>每次发生任务切换时，控制寄存器CR0中的TS（任务切换）标志被设置。在产生浮点异常时，系统软件使用TS标志来协调浮点单元与处理器其他部分的行动。</p>
<h2 id="任务链"><a href="#任务链" class="headerlink" title="任务链"></a>任务链</h2><p>TSS的前一个任务链接字段（有时称为 “反向链接”）和EFLAGS寄存器中的NT标志被用来返回到前一个任务的执行。EFLAGS.NT=1表示当前执行的任务被嵌套在另一个任务的执行中。<br>当CALL指令、中断或异常导致任务切换时：处理器将当前TSS的选择器复制到新任务的TSS的前一个任务链接字段；然后设置EFLAGS.NT=1。如果软件使用IRET指令来暂停新任务，处理器检查EFLAGS.NT=1；然后使用<br>它使用前一个任务链接字段中的值来返回到前一个任务。见图7-8。<br>当JMP指令引起任务切换时，新任务不被嵌套。前一个任务链接字段不被使用，并且EFLAGS.NT=0。当不需要嵌套时，使用JMP指令来调度一个新任务。</p>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220415161736123.png" alt="image-20220415161736123"></p>
<p>表7-2显示了任务切换过程中的繁忙标志（在TSS段描述符中）、NT标志、前一个任务链接字段和TS标志(在控制寄存器CR0中)在任务切换期间。<br>NT标志可以被任何权限级别的软件所修改。一个程序有可能在设置NT标志的同时执行IRET指令。这可能会随机地调用当前任务的TSS的前一个链接字段中指定的任务。为了防止这种虚假的任务切换成功，操作系统应该把它所创建的每个TSS中的前一个任务链接字段初始化为0。</p>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220415162023949.png" alt="image-20220415162023949"></p>
<h3 id="使用繁忙标志来防止递归任务的切换"><a href="#使用繁忙标志来防止递归任务的切换" class="headerlink" title="使用繁忙标志来防止递归任务的切换"></a>使用繁忙标志来防止递归任务的切换</h3><p>一个TSS只允许为一个任务保存一个上下文；因此，一旦一个任务被调用（派发），对任务的递归（或重入）调用该任务将导致该任务的当前状态丢失。TSS段中的繁忙标志 是为了防止重入式任务切换和随后的任务状态信息的丢失。处理器对繁忙标志的管理如下 ：</p>
<ol>
<li>当调度一个任务时，处理器设置新任务的繁忙标志。</li>
<li>如果在任务切换过程中，当前任务被放置在一个嵌套链中（任务切换是由一个CALL指令、一个中断或异常产生的），那么新任务的繁忙标志将被设置。</li>
<li>当切换到新的任务时（由CALL指令、中断或异常启动），处理器产生一个一般保护异常。如果新任务的繁忙标志已经被设置，处理器会产生一个一般保护的异常（#GP）。如果任务切换是由IRET指令发起的，那么异常就不会产生，因为处理器希望繁忙标志被设置。</li>
<li>当一个任务被跳转到一个新的任务（由任务代码中的JMP指令发起）或由任务代码中的IRET指令终止时，将产生一个异常。任务代码中的IRET指令终止时，处理器会清除繁忙标志，使任务回到 “不忙 “状态。</li>
</ol>
<p>处理器通过防止一个任务切换到它自己或一个嵌套的任务链中的任何任务来防止递归任务切换。由于多个调用、中断或异常，嵌套的暂停任务链可能增长到任何长度。如果一个任务在这个链中，忙碌标志会阻止它被调用。繁忙标志可以在多处理器配置中使用，因为处理器遵循一个LOCK协议（在总线上或缓存中），当它设置或清除繁忙标志时。这个锁使两个处理器不会同时调用同一个任务。</p>
<h3 id="修改任务链"><a href="#修改任务链" class="headerlink" title="修改任务链"></a>修改任务链</h3><p>在单处理器系统中，如果有必要从链接的任务链中删除一个任务，请使用以下程序来删除<br>使用以下程序来删除任务。</p>
<ol>
<li>禁用中断。</li>
<li>改变抢占式任务（暂停要删除的任务的任务）的TSS中的前一个任务链接字段。假设抢占式任务是要删除的任务链中的下一个任务（较新的任务）。改变前一个任务的链接字段，使其指向链中下一个最老的任务的TSS，或者指向链中更老的任务。</li>
<li>清除被删除的任务的TSS段描述符中的繁忙（B）标志。如果有一个以上的任务被从链上删除，必须清除每个被删除的任务的繁忙标志。</li>
<li>启用中断。</li>
</ol>
<p>在多进程系统中，必须在此过程中增加同步和序列化操作，以确保在改变前一个任务链接字段时，TSS和它的段描述符都被锁定并且繁忙标志被清除。</p>
<h2 id="任务地址空间"><a href="#任务地址空间" class="headerlink" title="任务地址空间"></a>任务地址空间</h2><p>一个任务的地址空间由该任务可以访问的段组成。这些段包括代码、数据、堆栈和在TSS中引用的系统段以及任务代码所访问的任何其他段。这些段被映射到处理器的线性地址空间，而线性地址空间又被映射到处理器的物理地址空间（直接或通过分页）。<br>TSS中的LDT段字段可以用来给每个任务提供它自己的LDT。给予一个任务它自己的LDT允许任务地址空间与其他任务隔离，将与该任务相关的所有段描述符放在该任务的LDT中。也可以让几个任务使用同一个LDT。这是一种节省内存的方式，允许特定的任务互相通信或控制，而不丢掉整个系统的保护屏障。因为所有的任务都可以访问GDT，所以也有可能创建共享段，通过该表的段描述符来访问。<br>如果分页功能被启用，TSS中的CR3寄存器（PDBR）字段允许每个任务有自己的一套页表，用于将线性地址映射到物理地址。或者，几个任务可以共享同一组页表。</p>
<h3 id="将任务映射到线性和物理地址空间"><a href="#将任务映射到线性和物理地址空间" class="headerlink" title="将任务映射到线性和物理地址空间"></a>将任务映射到线性和物理地址空间</h3><p>任务可以通过两种方式之一被映射到线性地址空间和物理地址空间。</p>
<ul>
<li>一个线性到物理地址空间的映射在所有任务之间共享。- 当分页未被启用时，这是唯一的选择。没有分页，所有线性地址都映射到相同的物理地址。当启用时，这种形式的线性到物理地址空间映射是通过为所有任务使用一个页目录来获得。如果支持需求分页，线性地址空间可能超过可用的物理空间。</li>
<li>每个任务都有自己的线性地址空间，被映射到物理地址空间。- 这种形式的映射是通过为每个任务使用不同的页面目录来完成的。因为PDBR（控制寄存器CR3）被加载到任务开关上，每个任务可能有一个不同的页面目录。</li>
</ul>
<p>不同任务的线性地址空间可能映射到完全不同的物理地址。如果不同页面目录的条目 指向不同的页表，而页表指向内存的不同页面，那么这些任务就不会共享物理地址。<br>无论采用哪种方法来映射任务的线性地址空间，所有任务的TSS必须位于物理空间的一个共享区域，这个区域是所有任务都可以访问的。这种映射是必需的，当处理器在任务切换过程中读取和更新TSSs时不会改变。线性地址空间也应该被映射到物理空间的一个共享区域；否则，GDT的目的就会落空。<br>图7-9显示了两个任务的线性地址空间是如何通过共享页表可在物理空间中重叠通过共享页表。</p>
<p><img src="/2022/04/14/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/image-20220415163751118.png" alt="image-20220415163751118"></p>
<h3 id="任务逻辑地址空间"><a href="#任务逻辑地址空间" class="headerlink" title="任务逻辑地址空间"></a>任务逻辑地址空间</h3><p>为了允许任务之间共享数据，使用以下技术为数据段创建共享的逻辑-物理地址空间映射。</p>
<ul>
<li><strong>通过GDT中的段描述符</strong> - 所有任务必须能够访问GDT中的段描述符。如果GDT中的一些段描述符指向线性地址空间中的段，这些段被映射到所有任务共有的物理地址空间的一个区域，那么所有任务都可以共享这些段的数据和代码。</li>
<li><strong>通过一个共享的LDT</strong> - 如果两个或更多的任务的TSSs中的LDT字段指向同一个LDT，那么它们可以使用同一个LDT。如果共享LDT中的一些段描述符指向被映射到物理地址空间的一个共同区域的段 ，这些段的数据和代码可以在共享LDT的任务之间共享。这种共享方法比通过GDT共享更具选择性，因为共享可以被限制在特定的任务中。系统中的其他任务可能有不同的LDT，不允许他们访问共享段。</li>
<li><strong>通过不同的LDT中的段描述符，这些描述符被映射到线性空间的公共地址上</strong> -如果这个线性地址空间的公共区域被映射到每个任务的物理地址空间的相同区域，这些段描述符允许任务共享段。这种段描述符 通常被称为别名。这种共享方法比上面列出的方法更具有选择性。因为，LDT中的其他段描述符可能指向独立的线性地址，而这些段描述符并没有被共享。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/12/%E6%97%B6%E9%97%B4%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/12/%E6%97%B6%E9%97%B4%E8%AE%B0%E5%BD%95/" class="post-title-link" itemprop="url">时间记录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-12 09:33:47" itemprop="dateCreated datePublished" datetime="2022-04-12T09:33:47+08:00">2022-04-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-15 16:19:02" itemprop="dateModified" datetime="2022-04-15T16:19:02+08:00">2022-04-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="4-12"><a href="#4-12" class="headerlink" title="4.12"></a>4.12</h2><p>9.30-9.39 背单词</p>
<p>9.39-9.54 看编译原理慕课</p>
<p>10.02-11.07 线代第一讲</p>
<p>11.30-11.45 线代第一讲</p>
<p>13.26-14.56 午觉 </p>
<p>15.00-15.28  15.38- 16.06 线代第一讲完成</p>
<p>16.22-17.00 背单词</p>
<p>17.16-17.35 看《Linux内核完全剖析》</p>
<p>17.45-20.00 健身</p>
<p>20.09-20.44背单词</p>
<p>21.20-21.51 看《Linux内核完全剖析》</p>
<p>21.56-22.08 看实验</p>
<p>22.11-22.20 线代第二章</p>
<h2 id="4-13"><a href="#4-13" class="headerlink" title="4.13"></a>4.13</h2><p>8.49-8.56 英语单词</p>
<p>9.05-9.45 线代第二章</p>
<p>10.-11.45上课</p>
<p>12.39 吃完饭</p>
<p>12.40-14.26 睡午觉</p>
<p>14.31 -14.53 15.00-16.58 17.10-17.17线代第二章</p>
<p>17.18-17.33 英语单词</p>
<p>17.45-20.08 锻炼</p>
<p>20.20-22.00 讨论</p>
<p>22.10-22.36 英语单词</p>
<h2 id="4-14"><a href="#4-14" class="headerlink" title="4.14"></a>4.14</h2><p>10.00-11.47 健身</p>
<p>12.40-12.54 线代第二章</p>
<p>12.55-13.45午觉</p>
<p>13.45-15.30 上课，顺便完成线代第二章</p>
<p>15.30-16.40 打电话与学长</p>
<p>16.40-17.45 看实验</p>
<p>18.30-21.00实验课</p>
<p>21.00-21.52 读书笔记四</p>
<p>22.00-22.30 背单词</p>
<h2 id="4-15"><a href="#4-15" class="headerlink" title="4.15"></a>4.15</h2><p>9.00-10.00 考试</p>
<p>10.2-10.10 单词</p>
<p>10.40-11.00英语听力</p>
<p>12.20-13.48 睡午觉</p>
<p>13.59-14.43 做核酸</p>
<p>14.43-16.05 线代第三章</p>
<p>16.15-</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">中断和异常处理-读书笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-10 19:10:10" itemprop="dateCreated datePublished" datetime="2022-04-10T19:10:10+08:00">2022-04-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-11 09:20:50" itemprop="dateModified" datetime="2022-04-11T09:20:50+08:00">2022-04-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="中断和异常处理"><a href="#中断和异常处理" class="headerlink" title="中断和异常处理"></a>中断和异常处理</h1><h2 id="中断和异常处理概述"><a href="#中断和异常处理概述" class="headerlink" title="中断和异常处理概述"></a>中断和异常处理概述</h2><p>中断和异常是表明在系统、处理器的某个地方存在一个条件的事件，或当前执行的程序或任务中存在需要处理器注意的情况。它们通常会强制将进程从当前运行的程序或任务转移到一个特殊的软件程序或任务上，称为中断处理程序或异常处理程序。处理器为响应中断或异常而采取的行动被称为中断或异常处理。<br>中断在程序执行过程中随机发生，以响应来自硬件的信号。系统硬件使用中断来处理处理器外部的事件，如服务外围设备的请求。软件也可以通过执行INT n指令来产生中断。当处理器在执行指令时检测到一个错误条件，如除以0，就会发生异常。处理器检测各种错误条件，包括违反保护规定、页面故障和内部机器故障。<br>奔腾4、英特尔至强、P6系列和奔腾处理器的机器，当检测到内部硬件错误和总线错误时，也允许产生一个机器检查异常。<br>当处理器执行一个中断或异常处理程序时，当前运行的程序或任务被暂停。当处理程序的执行完成后，处理器恢复被中断的程序或任务的执行。除非无法从异常中恢复，或者中断导致当前运行的程序被终止，否则被中断的程序或任务的恢复不会失去程序的连续性。<br> 在实模式下，中断向量表占据内存最低的1KB，共256个表项。每个表项4子节，包含一个2子节的段地址和2子节的偏移，即中断处理程序的入口地址。但是在保护模式下，中断向量表可以在内存中自由浮动。就像GDT被GDTR指向一样，中断向量表被IDTR(Interrupt Descriptor Table Register，中断描述符表寄存器)指向。该表和GDT非常类似。首先，GDTR和IDTR在格式上完全相同，均包含一个32bit的基地址和16bit的界限。相比之下，CPU中的另外两个关键寄存器LDTR和TR则表现出了相似性，都是16bit大小，分别包含指向LDT和TSS的选择子。从表项上来看，除了指出中断处理程序的目标地址(16bit选择子和32bit偏移)外，IDT表项还为了进行特权级检测而加入的DPL域。此外，IDT表项还包含一个P比特。</p>
<h2 id="有关中断和异常了解性的内容"><a href="#有关中断和异常了解性的内容" class="headerlink" title="有关中断和异常了解性的内容"></a>有关中断和异常了解性的内容</h2><h3 id="中断和异常向量"><a href="#中断和异常向量" class="headerlink" title="中断和异常向量"></a>中断和异常向量</h3><p>为了帮助处理异常和中断，每个架构上定义的异常和每个中断条件都被分配了一个唯一的识别号，称为向量号。处理器使用分配给一个异常或中断的向量号作为中断描述符表（IDT）的索引。该表提供了一个异常或中断处理程序的入口点。矢量号的允许范围是0到255。在0到31的范围内的向量号是由英特尔64和IA-32架构为架构定义的异常和中断保留了向量号。并非所有的向量号在这个范围内，并不是所有的向量号都有一个当前定义的功能。<br>在32到255范围内的向量号被指定为用户定义的中断，不被Intel64和IA-32架构保留。这些中断通常被分配给外部I/O设备，使这些设备能够向处理器发送中断。</p>
<h3 id="中断源和异常源"><a href="#中断源和异常源" class="headerlink" title="中断源和异常源"></a>中断源和异常源</h3><h4 id="中断来源"><a href="#中断来源" class="headerlink" title="中断来源"></a>中断来源</h4><p>处理器接收来自两个来源的中断。</p>
<ul>
<li>外部（硬件产生的）中断。</li>
<li>软件产生的中断</li>
</ul>
<h5 id="外部中断"><a href="#外部中断" class="headerlink" title="外部中断"></a>外部中断</h5><p>外部中断是通过处理器上的引脚或通过本地APIC接收的。Pentium 4、Intel Xeon、P6系列和Pentium处理器的主要中断引脚是LINT[1:0]引脚，它与本地APIC相连。启用时，LINT[1:0]引脚可以通过APIC的本地向量表(LVT)进行编程，以便与处理器的任何异常或故障相关联。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410193839865.png" alt="image-20220410193839865"></p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410193850982.png" alt="image-20220410193850982"></p>
<h5 id="可屏蔽的硬件中断"><a href="#可屏蔽的硬件中断" class="headerlink" title="可屏蔽的硬件中断"></a>可屏蔽的硬件中断</h5><p>任何通过INTR引脚或通过本地APIC传递给处理器的外部中断被称为可屏蔽硬件中断。可以通过INTR引脚传送的可屏蔽硬件中断包括所有IA-32体系结构定义的从0到255的中断向量；那些可通过本地APIC传送的中断包括中断向量16到255。</p>
<h5 id="软件产生的中断"><a href="#软件产生的中断" class="headerlink" title="软件产生的中断"></a>软件产生的中断</h5><p>INT n指令允许通过提供一个中断向量作为操作数，从软件内部产生中断。例如，INT 35指令强制调用35号中断的中断处理程序。任何从0到255的中断向量都可以作为该指令的参数。如果使用了处理器预定义的NMI向量，那么处理器的反应将与正常产生的的NMI中断产生的反应不一样。如果在这条指令中使用了2号向量（NMI向量），就会调用NMI中断处理程序，但处理器的NMI处理硬件没有被激活。用INT n指令在软件中产生的中断不能被EFLAGS寄存器中的IF标志所屏蔽。</p>
<h4 id="异常来源"><a href="#异常来源" class="headerlink" title="异常来源"></a>异常来源</h4><p>处理器接收来自三个来源的异常。</p>
<ul>
<li>处理器检测到的程序错误异常。</li>
<li>软件产生的异常。</li>
<li>机器检查的异常。</li>
</ul>
<h5 id="程序错误异常"><a href="#程序错误异常" class="headerlink" title="程序错误异常"></a>程序错误异常</h5><p>当处理器在应用程序或操作系统或执行程序的执行过程中检测到程序错误时，会产生一个或多个异常。英特尔64和IA-32架构为每个处理器检测到的异常定义了一个向量号。</p>
<h5 id="软件产生的异常"><a href="#软件产生的异常" class="headerlink" title="软件产生的异常"></a>软件产生的异常</h5><p>INTO, INT 3, 和 BOUND 指令允许在软件中产生异常。这些指令允许异常条件的检查在指令流中执行。例如，INT 3产生一个断点异常。INT n指令可以用来模拟软件中的异常；但是有一个限制。如果INT n提供了一个架构定义的异常的向量，处理器会产生一个中断到正确的向量(来访问异常处理程序），但不会在堆栈上推送错误代码。</p>
<h5 id="机器检查异常"><a href="#机器检查异常" class="headerlink" title="机器检查异常"></a>机器检查异常</h5><p>P6系列和奔腾处理器提供内部和外部机器检查机制，用于检查内部芯片硬件和总线交易的操作。这些机制取决于执行情况。当检测到机器检查错误时，处理器发出机器检查异常信号（向量18）并返回一个错误代码。</p>
<h3 id="异常的分类：故障、陷阱和中止"><a href="#异常的分类：故障、陷阱和中止" class="headerlink" title="异常的分类：故障、陷阱和中止"></a>异常的分类：故障、陷阱和中止</h3><p>异常被归类为故障、陷阱或中止，这取决于它们的报告方式以及引起异常的指令是否能在不损失程序或任务连续性的情况下重新启动。</p>
<ul>
<li><strong>故障</strong></li>
</ul>
<p>故障是一种通常可以被纠正的异常，一旦被纠正，就可以在不损失程序或任务连续性的情况下重新启动程序。<br>当一个故障被报告时，处理器将机器状态恢复到在开始执行故障指令之前的状态。故障处理程序的返回地址（保存在CS和EIP寄存器的保存内容）指向故障指令，而不是指向故障指令之后的指令。</p>
<ul>
<li><p><strong>陷阱</strong> </p>
<p>陷阱是在执行陷阱指令后立即报告的异常。陷阱允许程序或任务的执行继续进行而不损失程序的连续性。陷阱处理程序的返回地址指向陷阱指令后要执行的指令。</p>
</li>
<li><p><strong>终止</strong> </p>
<p>终止是一种异常，它并不总是报告引起异常的指令的精确位置，并且不允许重新启动引起异常的程序或任务。中止是用来报告严重的错误，例如硬件错误和系统表中不一致的或非法的值。</p>
</li>
</ul>
<p><strong>注意</strong></p>
<p>一个通常被报告为故障的异常子集是不能重新启动的。这种异常会导致损失一些处理器的状态。例如，在执行POPAD指令时，堆栈框架执行POPAD指令时，堆栈框架越过了堆栈段的末端，导致报告了一个故障。在这种情况下，异常处理程序看到指令指针(CS:EIP)已经被恢复，就像POPAD 指令没有被执行。然而，内部处理器状态（通用寄存器）将被修改。这种情况被认为是编程错误</p>
<h3 id="程序或任务的重新执行"><a href="#程序或任务的重新执行" class="headerlink" title="程序或任务的重新执行"></a>程序或任务的重新执行</h3><p>为了允许在处理异常或中断后重新启动程序或任务，所有的异常(除了中止)都保证在指令边界上报告异常。所有的中断都被保证为在一个指令边界上进行。<br>对于故障类异常，返回指令指针（在处理器产生异常时保存）指向发生故障的指令。因此，当一个程序或任务在处理完故障后被重新启动时，发生故障的指令被重新启动（重新执行）。重启出错指令通常用于处理当对操作数的访问被阻止时产生的异常。这种类型的故障最常见的例子是页面故障异常（#PF），它发生在程序或任务引用位于不在内存中的页面上的操作数时。<br>当页面故障异常发生时，异常处理程序可以将该页面加载到内存中，并通过重启来恢复程序或任务的执行。为了确保重启对当前执行的程序或任务来说是透明的，处理器保存了必要的寄存器和堆栈指针 ，以允许重新启动到执行故障指令之前的状态。<br>对于陷阱类异常，返回指令的指针指向陷阱指令之后的指令。如果在转移执行的指令中检测到一个陷阱，返回指令指针反映了转移。例如，如果在执行JMP指令时检测到一个陷阱，返回指令的指针指向JMP指令的目的地，而不是JMP指令之后的下一个地址。所有的陷阱异常都允许程序或任务的重新启动而不会失去连续性。例如，溢出异常就是一个陷阱异常。在这里，返回指令的指针指向INTO指令之后的指令，该指令测试了EFLAGS.OF（溢出）标志。这个异常的陷阱处理程序解决了溢出的问题。从陷阱处理程序返回后，程序或任务在INTO指令之后的指令继续执行。<br>终止类异常不支持程序或任务的可靠重启。终止处理程序被设计为收集关于终止异常发生时处理器状态的诊断信息，然后尽可能优雅地关闭应用程序和系统。<br>中断程序严格地支持重新启动被中断的程序和任务而不损失连续性。返回为中断保存的返回指令指针指向要在指令边界执行的下一条指令 。如果刚刚执行的指令有一个重复的前缀，那么中断就会在当前迭代结束时进行，寄存器被设置为执行下一个迭代。</p>
<h3 id="开启和禁止中断"><a href="#开启和禁止中断" class="headerlink" title="开启和禁止中断"></a>开启和禁止中断</h3><p>处理器会抑制一些中断的产生，这取决于处理器的状态和EFLAGS寄存器中的IF和RF标志的状态。</p>
<h4 id="屏蔽可屏蔽硬件中断"><a href="#屏蔽可屏蔽硬件中断" class="headerlink" title="屏蔽可屏蔽硬件中断"></a>屏蔽可屏蔽硬件中断</h4><p>IF标志可以禁止对处理器INTR引脚上或通过本地APIC接收的可屏蔽硬件中断进行服务。当IF标志清除时，处理器会抑制传递到INTR引脚或通过本地APIC的中断产生内部中断请求；当IF标志被设置时，传递到INTR或通过本地APIC引脚的中断被作为正常的外部中断处理。<br>IF标志不影响传递到NMI引脚的非屏蔽中断（NMI）或通过本地APIC传递的交付模式NMI消息，也不影响处理器产生的异常。与EFLAGS寄存器中的其他标志一样，处理器在响应硬件复位时清除IF标志。<br>事实上，可屏蔽的硬件中断组包括保留的中断和异常向量0到32可能会引起混淆。从结构上看，当IF标志被设置时，矢量0到32的中断可以通过INTR引脚传递给处理器，而矢量16到32的中断则可以通过本地接口传递。然后，处理器将产生一个中断并调用中断或异常处理程序，该处理程序由矢量编号指向。<br>IF标志可以通过STI（设置中断使能标志）和CLI（清除中断使能标志）指令来设置或清除。这些指令只有在CPL等于或小于IOPL的情况下才能执行。如果在CPL大于IOPL的情况下执行这些指令，会产生一般保护异常（#GP）。<br>IF标志也受到以下操作的影响。</p>
<ul>
<li>PUSHF指令将所有的标志存储在堆栈上，在那里可以检查和修改它们。POPF指令可以用来将修改后的标志加载到EFLAGS寄存器中。</li>
<li>任务开关、POPF和IRET指令加载EFLAGS寄存器；因此，它们可以用来修改IF标志的设置。</li>
<li>当一个中断通过中断门处理时，IF标志会被自动清除，这就禁止了可屏蔽的硬件中断。</li>
</ul>
<h4 id="屏蔽指令断点"><a href="#屏蔽指令断点" class="headerlink" title="屏蔽指令断点"></a>屏蔽指令断点</h4><p>EFLAGS寄存器中的RF（恢复）标志控制处理器对指令断点条件的响应。当设置时，它阻止指令断点产生调试异常（#DB）；当清除时，指令断点将产生调试异常。RF标志的主要功能是防止处理器在以下情况下进入调试异常循环 。</p>
<h4 id="切换堆栈时屏蔽异常和中断"><a href="#切换堆栈时屏蔽异常和中断" class="headerlink" title="切换堆栈时屏蔽异常和中断"></a>切换堆栈时屏蔽异常和中断</h4><p>为了切换到一个不同的堆栈段，软件经常使用一对指令，例如：<br>MOV SS, AX<br>MOV ESP, StackTop<br>如果在段选择器被加载到SS寄存器之后，但在ESP寄存器被加载之前，发生了中断或异常。ESP寄存器中，这两部分进入堆栈空间的逻辑地址在中断或异常处理过程中是不一致的。为了防止这种情况的发生，处理器在MOV到SS指令或POP到SS指令之后，处理器抑制中断、调试异常和单步陷阱异常，直到到达下一条指令后的指令边界。所有其他的故障仍然可以被产生。如果LSS指令被用来修改SS寄存器的内容（推荐的方法），这个问题就不会发生。</p>
<h3 id="异常和中断的优先级"><a href="#异常和中断的优先级" class="headerlink" title="异常和中断的优先级"></a>异常和中断的优先级</h3><p>如果在一个指令边界有一个以上的异常或中断等待处理，处理器会以可预测的顺序处理它们。下表显示了异常和中断源类别之间的优先级。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410202420157.png" alt="image-20220410202420157"></p>
<p><strong>注意</strong>：虽然在表中列出的这些类别的优先级在整个架构中是一致的，但是每个类别中的例外情况是与实现有关的，可能因处理器不同而不同。处理器首先处理来自具有最高优先级的类的未决异常或中断，将执行转移到处理程序的第一条 指令。较低优先级的异常被丢弃；较低优先级的中断被搁置。当中断处理程序将执行返回到程序或任务中出现异常和/或中断的位置时，被丢弃的异常会重新产生。</p>
<h2 id="中断描述符表"><a href="#中断描述符表" class="headerlink" title="中断描述符表"></a>中断描述符表</h2><p>中断描述符表（IDT）将每个异常或中断向量与用于服务相关异常或中断的门描述符联系起来。与GDT和LDT一样，IDT是一个由8字节描述符组成的数组。。与GDT不同，IDT的第一个条目可以包含一个描述符。为了<br>为了形成对IDT的索引，处理器将异常或中断向量按8（门描述符的字节数）的比例进行调整。因为只有256个中断或异常向量，IDT不需要包含多于256个描述符。它可以包含少于256个描述符，因为描述符只需要用于可能发生的中断和可能出现的异常向量需要描述符。IDT中所有空的描述符槽都应该将描述符的当前标志设置为0。<br>IDT的基地址应该在8字节的边界上对齐，以最大限度地提高缓存行的性能 。极限值以字节为单位，并与基地址相加，得到最后一个有效字节的地址。极限值为0时，正好是一个有效的字节。因为IDT条目总是8个字节长，所以极限值应该是始终是8的整数倍（即8N-1）。<br>IDT可以驻留在线性地址空间的任何地方。如图6-1所示，处理器使用IDTR寄存器来定位IDT 。这个寄存器持有32位的基地址和16位的IDT限制。<br>LIDT（加载IDT寄存器）和SIDT（存储IDT寄存器）指令分别加载和存储IDTR的内容。LIDT指令将IDTR寄存器中的基地址和限值加载到一个内存操作数中。这条指令只有在CPL为0时才能被执行。它通常由操作系统的初始化代码在创建IDT时使用。操作系统也可以用它来改变一个IDT到另一个IDT。<br>SIDT指令将IDTR中存储的基数和极限值复制到内存中。这条指令可以在任何权限级别下执行。如果一个向量引用的描述符超过了IDT的限制，就会产生一个一般保护异常（#GP）。<br><strong>注意</strong><br>由于中断只传递给处理器内核一次，一个不正确配置的IDT可能导致不完整的中断处理和/或中断传递的阻塞。在设置IDTR基础/限制/访问字段和门描述符中的每个字段时，需要遵循IA-32架构的规则。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410202728708.png" alt="image-20220410202728708"></p>
<h2 id="IDT-描述符"><a href="#IDT-描述符" class="headerlink" title="IDT 描述符"></a>IDT 描述符</h2><p>IDT可能包含三种门描述符中的任何一种。</p>
<ul>
<li>任务门描述符</li>
<li>中断门描述符</li>
</ul>
<p>陷阱门描述符<br>图6-2显示了任务门、中断门和陷阱门描述符的格式。任务门的格式在IDT中使用的任务门的格式与在GDT或LDT中使用的任务门的格式相同。任务门包含一个异常和/或中断处理任务的TSS的段选择器。<br>中断和陷阱门与调用门非常相似。它们包含一个远指针(段选择器和偏移量)，处理器用它来把程序的执行转移到异常或中断处理程序代码中的一个处理程序。<br>这些门的不同之处在于处理器处理EFLAGS寄存器中的IF标志的方式。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410205107225.png" alt="image-20220410205107225"></p>
<h2 id="中断与异常处理"><a href="#中断与异常处理" class="headerlink" title="中断与异常处理"></a>中断与异常处理</h2><p>处理器处理对异常处理程序和中断处理程序的调用的方式类似于处理对过程或任务的CALL指令来处理对过程或任务的调用。当响应一个异常或中断时，处理器使用异常或中断向量作为IDT中描述符的索引。如果该索引指向一个中断门或陷阱门，处理器调用异常或中断处理程序，其方式类似于调用门的CALL。如果 index 指向一个任务<br>门，处理器将执行一个任务切换到异常或中断处理任务，其方式类似于 CALL到一个任务门</p>
<h3 id="异常或中断处理程序"><a href="#异常或中断处理程序" class="headerlink" title="异常或中断处理程序"></a>异常或中断处理程序</h3><p>中断门或陷阱门引用了一个异常或中断处理程序，该程序在当前执行的任务的上下文中运行（见图6-3）。该门的段选择器指向一个段描述符，该段描述符位于GDT或当前LDT中的一个可执行代码段。门描述符的偏移字段指的是<br>异常或中断处理程序的开头。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410205743923.png" alt="image-20220410205743923"></p>
<p>当处理器执行一个对异常或中断处理程序的调用时。</p>
<ul>
<li>如果处理程序要在一个较低的权限级别上执行，就会发生堆栈切换。<br>当堆栈切换发生时 :<br>a. 处理程序使用的堆栈的段选择器和堆栈指针是从当前执行任务的TSS中获得的。在这个新的堆栈中，处理程序推送了被中断的堆栈段选择器和堆栈指针。<br>b. 然后，处理器将EFLAGS、CS和EIP寄存器的当前状态保存在新的堆栈中（见图6-4）。<br>c. 如果一个异常导致错误代码被保存，它将被推到EIP值之后的新栈上。</li>
<li>如果处理程序要在与被中断程序相同的权限级别下执行。<br>a. 处理器将EFLAGS、CS和EIP寄存器的当前状态保存在当前堆栈中（见图6-4）。<br>b. 如果一个异常导致错误代码被保存，那么它将在EIP值之后被推到当前堆栈中。</li>
</ul>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220410210127965.png" alt="image-20220410210127965"></p>
<p>要从一个异常或中断处理程序中返回，处理程序必须使用IRET（或IRETD）指令。IRET指令与RET指令类似，只是它将保存的标志恢复到EFLAGS寄存器中。只有当CPL为0时，EFLAGS寄存器的IOPL字段才被恢复。</p>
<h4 id="异常和中断处理程序的保护"><a href="#异常和中断处理程序的保护" class="headerlink" title="异常和中断处理程序的保护"></a>异常和中断处理程序的保护</h4><p>异常和中断处理程序的特权级别保护与通过调用门调用普通程序的保护相似。处理器不允许将执行转移到一个异常或中断处理程序中。试图违反这一规则会导致一般保护异常（#GP）。异常处理程序和中断处理程序的保护机制在以下方面有所不同：</p>
<ul>
<li>因为中断和异常向量没有RPL，RPL在隐式调用异常和中断处理程序的隐式调用不检查RPL。</li>
<li>只有在异常或中断产生的时候，处理器才会检查中断或陷阱门的DPL，如果有一个INT n, INT 3, 或 INTO 指令产生的异常或中断，处理器才会检查中断或陷阱门的 DPL。这里，CPL必须小于或等于门的DPL。这一限制防止了运行在权限级别3的应用程序或程序使用软件中断来访问关键的异常处理程序。中断来访问关键的异常处理程序，例如页面故障处理程序，条件是这些处理程序被放在更有权限的代码段中。对于硬件产生的中断和处理器检测到的异常，处理器忽略了中断和陷阱门的DPL。</li>
</ul>
<p>由于异常和中断通常不会在可预测的时间发生，这些特权规则有效地对异常和中断处理程序可以运行的权限级别进行了限制。以下两种技术都可以用来避免违反权限级别：</p>
<ul>
<li>异常或中断处理程序可以放在一个符合要求的代码段中。这种技术可以用于处理程序，这些处理程序只需要访问堆栈上的数据（例如，划分错误异常）。如果处理程序需要来自数据段的数据，数据段需要从权限级别3访问，这将使其不受保护。</li>
<li>处理程序可以被放置在一个特权级别为0的不符合要求的代码段中。这个处理程序将始终运行，不管被中断的程序或任务是在哪个CPL下运行。</li>
</ul>
<h4 id="异常或中断处理程序的标志用法"><a href="#异常或中断处理程序的标志用法" class="headerlink" title="异常或中断处理程序的标志用法"></a>异常或中断处理程序的标志用法</h4><p>当通过中断门或陷阱门访问异常或中断处理程序时，处理器在将EFLAGS寄存器的内容保存在堆栈中后，清除EFLAGS寄存器中的TF标志。(在调用异常和中断处理程序时，处理器也会清除EFLAGS寄存器中的VM、RF和NT标志，然后将它们保存在堆栈中。）清除TF标志可以防止指令跟踪影响中断响应。A 后续的IRET指令将TF（以及VM、RF和NT）标志恢复到堆栈中EFLAGS寄存器的保存内容中的值。<br>中断门和陷阱门的唯一区别是处理器处理IF标志的方式。当通过中断门访问一个异常或中断处理程序时，处理器会清除IF标志以防止 其他中断干扰当前的中断处理程序。随后的IRET指令将IF标志恢复到堆栈上EFLAGS寄存器的保存内容中的值。通过陷阱门访问处理程序并不影响IF标志。</p>
<h3 id="中断任务"><a href="#中断任务" class="headerlink" title="中断任务"></a>中断任务</h3><p>当异常或中断处理程序通过IDT中的任务门被访问时，会产生一个任务切换。处理异常或中断的单独任务有几个优点。</p>
<ul>
<li>被中断的程序或任务的整个上下文被自动保存。</li>
<li>一个新的TSS允许处理程序在处理异常或中断时使用一个新的权限级别0的堆栈。如果异常或中断发生时，当前权限级别0的堆栈被破坏，通过任务门访问处理程序可以通过为处理程序提供一个新的权限级别0的堆栈来防止系统崩溃。</li>
<li>处理程序可以通过给它一个单独的地址空间来进一步与其他任务隔离。这可以通过以下方式实现给它一个单独的LDT。</li>
</ul>
<p>用一个单独的任务来处理中断的缺点是，在任务切换时必须保存大量的机器状态，使得它比使用中断门要慢，从而导致中断延迟的增加。<br>IDT中的任务门引用GDT中的TSS描述符（见图6-5）。切换到处理程序任务的方式与普通任务切换相同。返回到被中断的任务的链接 被存储在处理程序任务的TSS的前一个任务链接域中。如果一个异常导致一个错误代码，这个错误代码被复制到新任务的堆栈中。<br>在操作系统中使用异常或中断处理任务时，实际上有两种机制可以用来调度任务：软件调度器（操作系统的一部分）和硬件调度器（处理器的中断机制的一部分）。软件调度器需要容纳中断任务当中断被激活时，可能会被调度。<br><strong>注意</strong><br>由于IA-32体系结构的任务不是可重入的，一个中断处理程序任务在它完成处理中断和执行IRET指令时，必须禁用中断。这个动作可以防止在中断任务的TSS仍被标记为忙时发生另一个中断，这将导致一般保护（#GP）异常。</p>
<p><img src="/2022/04/10/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220411091420768.png" alt="image-20220411091420768"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">保护模式内存管理-读书笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-03 10:09:18" itemprop="dateCreated datePublished" datetime="2022-04-03T10:09:18+08:00">2022-04-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-04 20:56:32" itemprop="dateModified" datetime="2022-04-04T20:56:32+08:00">2022-04-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="保护模式内存管理"><a href="#保护模式内存管理" class="headerlink" title="保护模式内存管理"></a>保护模式内存管理</h1><h2 id="内存管理概览"><a href="#内存管理概览" class="headerlink" title="内存管理概览"></a>内存管理概览</h2><p>IA-32架构的内存管理设施分为两部分：分段和分页。<br>分段提供了一种隔离单个代码、数据和堆栈模块的机制，以便多个程序（或任务）可以在同一个处理器上运行而不互相干扰。分页提供了一种机制来实现传统的需求分页、虚拟内存系统，其中程序执行环境的部分被映射到物理内存中。分页也可以用来提供多个任务之间的隔离。<br>在保护模式下操作时，必须使用某种形式的分段。没有模式位可以禁用分段。然而，分页的使用是可选的。这两种机制（分段和分页）可以被配置为支持简单的单程序（或单任务）系统，或使用共享内存的多处理器系统。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403145257014.png" alt="image-20220403145257014"></p>
<p>如图所示，分段提供了一种机制来划分处理器的可寻址内存空间（称为线性地址空间），分成更小的受保护的地址空间，称为段。分段可以可以用来保存程序的代码、数据和堆栈，或者保存系统数据结构（如TSS或LDT）。<br>如果一个处理器上有多个程序（或任务）在运行，每个程序可以被分配到它自己的段组。然后，处理器强制执行这些段之间的界限，并确保一个程序不会因为写进另一个程序的段而干扰程序的执行。分段机制还允许对段进行打字。</p>
<p>段落机制也允许段的类型化，这样可以限制对特定类型的段进行的操作。一个系统中的所有段都包含在处理器的线性地址空间中。要在一个特定的段中找到一个字节必须提供一个逻辑地址（也称为远指针）。</p>
<p>一个<strong>逻辑地址</strong>包括一个段选择器和一个偏移量。段选择器是一个段的唯一标识符。在其他方面，它提供了一个<br>在描述符表（如全局描述符表，GDT）中的偏移量，该数据结构称为段描述符。每个网段都有一个网段描述符，它指定了网段的大小，网段的访问权限和段的大小，段的访问权限和特权级别，段的类型，以及段的第一个字节在线性地址空间中的位置（称为段的基址）。逻辑地址的偏移部分被添加到段的基地址中，以定位段的第一个字节。<br>基准地址加上偏移量就形成了处理器线性地址中的一个<strong>线性地址</strong>。<br>如果不使用分页，处理器的线性地址空间将直接被映射到处理器的物理地址空间。<strong>物理地址空间</strong>被定义为处理器可以在其地址总线上产生的地址范围。由于多任务计算系统通常定义的线性地址空间远远大于在物理内存中一次性包含的经济可行性，因此需要一些 “虚拟化 “线性地址空间的方法。这种线性地址空间的虚拟化是通过处理器的分页机制处理的。<br>分页支持 “虚拟内存 “环境，用少量的物理内存（RAM和ROM）和一些磁盘存储来模拟大的线性地址空间。当使用分页时，每个段被划分为若干页（通常每页大小为4KB），这些页存储在物理内存或磁盘上。操作系统或执行器维护一个页面目录和一组页面表，以跟踪这些页面。<em>当一个程序（或任务）试图访问线性地址空间中的一个地址位置时，处理器会使用页目录和页表来将线性地址转换为物理地址</em>，然后执行所要求的操作（读或写）在内存位置上。<br>如果被访问的页面当前不在物理内存中，处理器会中断程序的执行。(通过产生一个页面故障异常)。然后，操作系统或执行程序将该页从磁盘读入物理内存，并继续执行程序。<br>当分页在操作系统或执行系统中被正确实现时，物理内存和磁盘之间的换页对于程序的正确执行是透明的。即使是为16位IA32处理器编写的程序，在虚拟8086模式下运行时也可以进行分页（透明）。</p>
<h3 id="linux下的内存管理"><a href="#linux下的内存管理" class="headerlink" title="linux下的内存管理"></a>linux下的内存管理</h3><p>Linux系统中的物理存储空间和虚拟存储空间的地址范围分别都是从0x00000000到0xFFFFFFFF，共4GB，但物理存储空间与虚拟存储空间布局完全不同。Linux运行在虚拟存储空间，并负责把系统中实际存在的远小于4GB的物理内存根据不同需求映射到整个4GB的虚拟存储空间中。Linux主要工作在保护模式下。80X86从逻辑地址到物理地址变换中经过了两个阶段。第一阶段使用分段机制把程序的逻辑地址变换成处理器可寻址内存空间（称为线性地址空间）中的地址。第二阶段的分页机制把线性地址转换成物理地址。第一阶段的分段变换机制是必须使用的，但是第二阶段的分页机制是可选择的。如果没有开启分页机制，那么分段机制产生的线性地址空间就直接映射到处理器的物理地址空间上。</p>
<h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><p><strong>物理地址</strong>： 放在寻址总线上的地址，用于内存芯片级内存单元寻址。放在寻址总线上，如果是读，电路根据这个地址每位的值就将相应地址的物理内存中的数据放到数据总线中传输。如果是写，电路根据这个地址每位的值就将相应地址的物理内存中放入数据总线上的内容。物理内存是以字节(8位)为单位编址的，是地址变换的最终结果地址，物理地址由32位或36位无符号整数表示。</p>
<p><strong>逻辑地址</strong>：是指由程序产生的与段相关的偏移地址部分，每一个逻辑地址都由一个段和偏移量组成。在进行C语言指针编程中，可以读取指针变量本身值(&amp;操作)，实际上这个值就是逻辑地址，它是相对于你当前进程数据段的地址，不和绝对物理地址相干。只有在Intel实模式下，逻辑地址才和物理地址相等（因为实模式没有分段或分页机制,Cpu不进行自动地址转换）；逻辑也就是在Intel 保护模式下程序执行代码段限长内的偏移地址（假定代码段、数据段如果完全一样）。</p>
<p><strong>线性地址：</strong>是逻辑地址到物理地址变换之间的中间层。程序代码会产生逻辑地址，或者说是段中的偏移地址，加上相应段的基地址就生成了一个线性地址，是一个32位无符号整数，可以用来表示高达4GB的地址，也就是说，高达4294967296个内存单元，以十六进制表示，0x00000000到oxffffffff。如果启用了分页机制，那么线性地址可以再经变换以产生一个物理地址。若没有启用分页机制，那么线性地址直接就是物理地址。Intel 80386的线性地址空间容量为4G（2的32次方即32根地址总线寻址）。</p>
<p><strong>虚拟内存</strong>：是指计算机呈现出要比实际拥有的内存大得多的内存量。因此它允许程序员编制并运行比实际系统拥有的内存大得多的程序。这使得许多大型项目也能够在具有有限内存资源的系统上实现。一个很恰当的比喻是：你不需要很长的轨道就可以让一列火车从上海开到北京。你只需要足够长的铁轨（比如说3公里）就可以完成这个任务。采取的方法是把后面的铁轨立刻铺到火车的前面，只要你的操作足够快并能满足要求，列车就能象在一条完整的轨道上运行。这也就是虚拟内存管理需要完成的任务。在现在操作系统中，都使用了MMU的存储管理技术，而MMU管理的地址是虚拟地址，虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。有时我们也把逻辑地址称为虚拟地址。因为和虚拟内存空间的概念类似，逻辑地址也是和实际物理内存容量无关的。</p>
<h4 id="逻辑地址如何转换为线性地址"><a href="#逻辑地址如何转换为线性地址" class="headerlink" title="逻辑地址如何转换为线性地址"></a>逻辑地址如何转换为线性地址</h4><p> 完整的内存管理，包含保护和地址变换两个关键部分。80386的工作模式包括实地址模式和虚地址模式（保护模式）。Linux主要工作在保护模式下。80X86从逻辑地址到物理地址变换中经过了两个阶段。第一阶段使用分段机制把程序的逻辑地址变换成处理器可寻址内存空间（称为线性地址空间）中的地址。第二阶段的分页机制把线性地址转换成物理地址。第一阶段的分段变换机制是必须使用的，但是第二阶段的分页机制是可选择的。如果没有开启分页机制，那么分段机制产生的线性地址空间就直接映射到处理器的物理地址空间上。</p>
<p>  一个逻辑地址由两部份组成，<strong>段标识符: 段内偏移量</strong>。段标识符是由一个16位长的字段组成，称为段选择符。其中前13位是一个索引号。后面3位包含一些硬件细节，表示具体的是代码段寄存器还是栈段寄存器抑或是数据段寄存器，如图1所示。索引号就是“段描述符(segment descriptor)”的索引，段描述符具体地址描述了一个段。很多个段描述符，就组了一个数组，叫“段描述符表”，这样，<strong>可以通过段标识符的前13位，直接在段描述符表中找到一个具体的段描述符</strong>，这句话很关键，说明段标识符的具体作用，每一个段描述符由8个字节组成，如图2所示，与主题最密切的就是Base字段，她表示的是包含段的首字节的线性地址，也就是一个段的开始位置的线性地址。完全引用书中的一句话，一些全局的段描述符，就放在“全局段描述符表(GDT)”中，一些局部的，例如每个进程自己的，就放在所谓的“局部段描述符表(LDT)”中。那究竟什么时候该用GDT，什么时候该用LDT呢？这是由段选择符中的T1字段表示的，=0，表示用GDT，=1表示用LDT，GDT在内存中的地址和大小存放在CPU的GDTR控制寄存器中，而LDT则在IDTR寄存器中。这个过程中有几个基本的概念，一定要理清楚，如段选择符、段描述符、局部段描述符表、全局段描述符表。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403152513453.png" alt="image-20220403152513453"></p>
<p>上图显示了一个逻辑地址是怎样转换成相应线性地址的，给定一个完整的逻辑地址[段选择符：段内偏移地址]</p>
<p> 1、看段选择符的T1=0还是1，即<strong>先检查段选择符中的TI字段，以决定段描述符保存在哪一个描述符表中</strong>，知道当前要转换是GDT中的段（在这种情况下，分段单元从GDTR寄存器中得到GDT的线性基地址），还是LDT中的段（在这种情况下，分段单元从LDTR寄存器中得到GDT的线性基地址），再根据相应寄存器，得到其地址和大小。<br>2、<strong>由于一个段描述符是8字节长，因此她在GDT或LDT内的相对地址是由段选择符的最高13位的值乘以8得到</strong>，拿出段选择符中前13位，可以在这个数组中，查找到对应的段描述符，这样，它的Offset，即偏移地址就知道了。<br>3、把Base + offset，就是要转换的线性地址了。<br>    对于软件来讲，原则上就需要把硬件转换所需的信息准备好，就可以让硬件来完成这个转换了。下图逻辑地址转换为线性地址实例，段选择符为0x7B，指向用户数据段，段起始地址为0x00000000，逻辑偏移地址为0x80495B0，最终的线性地址为Base + offset=0x80495B0。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403153532441.png" alt="image-20220403153532441"></p>
<h4 id="线性地址转物理地址"><a href="#线性地址转物理地址" class="headerlink" title="线性地址转物理地址"></a>线性地址转物理地址</h4><p>CPU通过地址来访问内存中的单元，地址有虚拟地址和物理地址之分，如果CPU没有MMU（Memory  Management Unit，内存管理单元），或者有MMU但没有启用，CPU核在取指令或访问内存时发出的地址将直接传到CPU芯片的外部地址引脚上，直接被内存芯片（以下称为物理内存，以便与虚拟内存区分）接收，这称为物理地址（Physical Address，以下简称PA），如下图所示。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403155046532.png" alt="image-20220403155046532"></p>
<p>如果CPU启用了MMU，CPU核发出的地址将被MMU截获，从CPU到MMU的地址称为虚拟地址（Virtual Address，以下简称VA），而MMU将这个地址翻译成另一个地址发到CPU芯片的外部地址引脚上，也就是将虚拟地址映射成物理地址，如下图所示</p>
<p> <img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403155108029.png" alt="image-20220403155108029"></p>
<p>虚拟内存地址和物理内存地址的分离，给进程带来便利性和安全性。虚拟地址必须和物理地址建立一一对应的关系，才可以正确的进行地址转换。</p>
<p>记录对应关系最简单的办法，就是把对应关系记录在一张表中。为了让翻译速度足够地快，这个表必须加载在内存中。不过，这种记录方式惊人地浪费。</p>
<p>因此，Linux采用了分页（paging）的方式来记录对应关系。所谓的分页，就是以更大尺寸的单位页（page）来管理内存。在Linux中，通常每页大小为4KB。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403155154004.png" alt="image-20220403155154004"></p>
<p>依据以下步骤进行转换：</p>
<ol>
<li>从cr3中取出进程的页目录地址（操作系统负责在调度进程的时候，把这个地址装入对应寄存器）；</li>
<li>根据线性地址前十位，在数组中，找到对应的索引项，因为引入了二级管理模式，页目录中的项，不再是页的地址，而是一个页表的地址。（又引入了一个数组），页的地址被放到页表中去了。</li>
<li>根据线性地址的中间十位，在页表（也是数组）中找到页的起始地址；</li>
<li>将页的起始地址与线性地址中最后12位相加，得到最终我们想要的；</li>
</ol>
<h2 id="分段机制"><a href="#分段机制" class="headerlink" title="分段机制"></a>分段机制</h2><p>由IA-32体系结构支持的分段机制可以用来实现各种各样的系统设计。这些设计的范围很广，从只极少使用分段的平面模型到保护。这些设计从扁平模型到多分段模型，这些模型采用分段来创建一个强大的操作环境，在其中多个程序和任务可以可靠地执行。</p>
<h3 id="Basic-Flat-Model-基本平坦模型"><a href="#Basic-Flat-Model-基本平坦模型" class="headerlink" title="Basic Flat Model(基本平坦模型)"></a>Basic Flat Model(基本平坦模型)</h3><p>一个系统最简单的内存模型是基本的 “平坦模型”，在这个模型中，操作系统和应用程序可以访问一个连续的、没有分割的地址空间。在最大程度上，这种基本的平坦模型对系统设计者和应用程序都隐藏了架构的分割机制。<br>程序员为了实现IA-32体系结构的基本平坦内存模型，至少要创建两个段描述符，一个用于引用代码段，一个用于引用数据段。这两个段都被映射到整个线性地址空间：也就是说，两个段描述符都有同样的基址值为0，同样的段限制为4GBytes。通过设置段限制为4GBytes，分段机制就不会因为超出限制的内存引用而产生异常，即使在一个特定的地址上没有物理内存存在。ROM（EPROM）通常位于物理地址空间的顶部。因为处理器在FFF_FFF0H开始执行。RAM（DRAM）被放在物理地址空间的底部，因为复位初始化后DS数据段的初始基址是0。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403161325418.png" alt="image-20220403161325418"></p>
<p>​                                                                        flat model</p>
<h3 id="Protected-Flat-Model-受保护的平坦模型"><a href="#Protected-Flat-Model-受保护的平坦模型" class="headerlink" title="Protected Flat Model(受保护的平坦模型)"></a>Protected Flat Model(受保护的平坦模型)</h3><p>受保护的平坦模型与基本平坦模型类似，只是段的限制被设置为只包括物理内存实际存在的的地址范围（见下图）。一个一般保护的异常(#GP)会在任何访问不存在的内存的尝试中产生。这个模型提供了一个最低水平的<br>这种模式提供了最低水平的硬件保护，以防止某些类型的程序错误。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403161745702.png" alt="image-20220403161745702"></p>
<p>​                                                                  Protected Flat Model</p>
<p>更多的复杂性可以被添加到这个受保护的平坦模型中，以提供更多的保护。例如，对于分页机制要在用户和主管的代码和数据之间提供隔离，需要定义四个段。用户的代码和数据段的权限级别为3，而主管的代码和数据段的权限级别为0。通常，这些段都是相互重叠的，并从线性地址空间的地址0开始。这种平坦的分段模型和一个简单的分页结构可以保护操作系统不受应用程序的影响。通过为每个任务或进程增加一个单独的分页结构，它还可以保护应用程序之间的相互影响。类似的设计被几个流行的多任务操作系统所采用。</p>
<h3 id="Multi-Segment-Model-多段模型"><a href="#Multi-Segment-Model-多段模型" class="headerlink" title="Multi-Segment Model(多段模型)"></a>Multi-Segment Model(多段模型)</h3><p>多段模型（如下图）使用分段机制的全部功能，对代码、数据结构、程序和任务提供硬件强制保护。在这里，每个<br>程序（或任务）都有自己的段描述符表和自己的段。这些段可以是对其分配的程序来说是完全私有的，或者在程序之间共享。对所有程序段的访问以及对运行在各个程序上的执行环境都由硬件控制。<br>访问检查不仅可以用来防止引用一个段限制之外的地址，还可以防止在段内进行不允许的操作。例如，由于代码段被指定为只读段，所以可以用硬件来防止向代码段写东西。为段创建的访问权限信息也可以用来设置保护环或保护级别。保护级别可以用来保护操作系统程序免受应用程序的未经授权的访问。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220403163121670.png" alt="image-20220403163121670"></p>
<p>​                                                            Multi-Segment Model</p>
<h3 id="Segmentation-in-IA-32e-Mode"><a href="#Segmentation-in-IA-32e-Mode" class="headerlink" title="Segmentation in IA-32e Mode"></a>Segmentation in IA-32e Mode</h3><p>在英特尔64架构的IA-32e模式下，分段的效果取决于处理器是在兼容模式还是64位模式下运行。在兼容模式下，分段的功能就像使用传统的16位或32位保护模式的语义。在64位模式下，分段功能通常被禁用（但不是完全禁用），创建一个平坦的64位线性地址空间。处理器将CS、DS、ES、SS的段基处理为零，创建一个线性地址，等于<br>有效地址。FS和GS段是个例外。这些段寄存器（存放段基）可以作为线性地址计算中的一个额外的基础寄存器。它们有助于寻址本地数据和某些操作系统的数据结构。注意，在64位模式下，处理器在运行时不执行段限制检查。</p>
<h3 id="Paging-and-Segmentation-分页和分段"><a href="#Paging-and-Segmentation-分页和分段" class="headerlink" title="Paging and Segmentation(分页和分段)"></a>Paging and Segmentation(分页和分段)</h3><p>分页可以与上图中描述的任何一种分段模式一起使用。处理器的分页机制将线性地址空间（段被映射到其中）分为若干页。然后这些线性地址空间的页被映射到物理地址空间的页中。分页机制提供了几个页级的保护设施，可以和段保护设施一起使用，也可以代替段保护设施。例如，它允许在逐页的基础上强制执行读写保护。分页 机制还提供了两级用户-监督者保护，也可以在每页的基础上指定。</p>
<h2 id="逻辑地址和线性地址的转换"><a href="#逻辑地址和线性地址的转换" class="headerlink" title="逻辑地址和线性地址的转换"></a>逻辑地址和线性地址的转换</h2><p>注:之前的内容为自己整理，以下为参考指导书翻译</p>
<p>在保护模式下的系统架构层面，处理器使用两个阶段的地址转换来获得物理地址：逻辑地址转换和线性地址空间分页。<br>物理地址：逻辑地址转换和线性地址空间分页。即使对段的使用降到最低，处理器地址空间中的每一个字节都可以用一个逻辑地址来访问。一个逻辑地址包括一个16位的段选择器和一个32位的偏移量。段选择器确定了字节所处的段，偏移量指定了字节在段中相对于该段的基址的位置。处理器将每个逻辑地址转化为一个线性地址。线性地址是处理器线性地址空间中的一个32位地址。像物理地址空间一样，线性地址空间是一个平面的（未分割的）。232字节的地址空间，地址范围从0到FFFFFFFH。线性地址空间包含所有段和为系统定义的系统表。为了将逻辑地址转换为线性地址，处理器做了以下工作：</p>
<ol>
<li>使用段选择器中的偏移量来定位GDT或LDT中段的段描述符，并将其读入处理器。(只有当一个新的段选择器被加载到段寄存器中时才需要这个步骤。）</li>
<li>检查段描述符，以检查段的访问权限和范围，以确保段是可访问的，并且偏移量在段的限制范围内。</li>
<li>将段描述符中的段基地址加到偏移量上，形成一个线性地址。</li>
</ol>
<p>如果不使用分页，处理器将线性地址直接映射到物理地址上。如果线性地址空间被分页，第二层的地址转换被用来将线性地址转换为物理地址。<br><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404154555152.png" alt="image-20220404154555152"></p>
<h3 id="Logical-Address-Translation-in-IA-32e-Mode-IA-32e-模式下的逻辑地址转换"><a href="#Logical-Address-Translation-in-IA-32e-Mode-IA-32e-模式下的逻辑地址转换" class="headerlink" title="Logical Address Translation in IA-32e Mode(IA-32e 模式下的逻辑地址转换)"></a>Logical Address Translation in IA-32e Mode(IA-32e 模式下的逻辑地址转换)</h3><p>在 IA-32e 模式下，Intel 64 处理器使用上述步骤将逻辑地址转换为线性地址。在64位模式下，段的偏移量和基地址是64位而不是32位。线性地址地址格式也是64位宽，并受制于典型形式的要求。每个代码段描述符都提供一个L位。这个位允许一个代码段执行64位代码或传统的32位代码的代码段。</p>
<h3 id="Segment-Selectors-段选择子"><a href="#Segment-Selectors-段选择子" class="headerlink" title="Segment Selectors(段选择子)"></a>Segment Selectors(段选择子)</h3><p>段选择器是一个段的16位标识符（见下图）。它并不直接指向段，而是指向定义该段的段描述符。一个段选择器包含以下内容 ：</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404154957115.png" alt="image-20220404154957115"></p>
<p>​                                                         Segment Selector</p>
<p><strong>索引</strong>（第3至15位）- 在GDT或LDT中选择8192个描述符之一。处理器将索引值乘以8（段描述符中的字节数），并将结果加到GDT或LDT的基址上（分别来自GDTR或LDTR寄存器）。<br><strong>TI（表指示器）标志</strong><br>(Bit 2) - 指定要使用的描述符表：清除该标志选择GDT；设置该标志选择当前的LDT。</p>
<p><strong>要求的权限级别(RPL)</strong><br>(位0和1) - 指定选择器的权限级别。特权级别范围从0到3，其中0为最高权限级别。</p>
<p>GDT的第一个条目不被处理器使用。指向GDT这个条目的段选择器（即索引为0且TI标志设置为0的段选择器）被用作 “空段选择器”。就是说，一个索引为0且TI标志设置为0的段选择器被用作 “空段选择器”。当一个段寄存器（除了CS或SS寄存器）被载入空段选择器时，处理器不会产生一个异常。然而，当一个持有空段选择器的段寄存器被用来访问内存时，它会产生一个异常。空选择器可以用来初始化未使用的段寄存器。用一个空的段选择器加载CS或SS寄存器会导致一个通用的保护机制。段选择器加载CS或SS寄存器会产生一个通用保护异常（#GP）。段落选择器作为指针变量的一部分对应用程序是可见的，但是选择器的值通常是由链接编辑器分配或修改的，而不是应用程序。</p>
<h3 id="Segment-Registers-段寄存器"><a href="#Segment-Registers-段寄存器" class="headerlink" title="Segment Registers(段寄存器)"></a>Segment Registers(段寄存器)</h3><p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404160315942.png" alt="image-20220404160315942"></p>
<p>为了减少地址转换的时间和编码的复杂性，处理器提供了最多容纳6个段选择器的寄存器。这些段寄存器中的每一个都支持一种特定的内存引用(代码、堆栈或数据)。对于几乎任何一种程序的执行，至少要有代码段（CS），数据段（DS）和堆栈段（SS）寄存器且必须被加载有效的段选择器。处理器还提供了三个额外的数据段寄存器（ES、FS和GS），这些寄存器可以用来为当前执行的程序（或任务）提供额外的数据段。</p>
<p>一个程序要访问一个段，该段的段选择器必须被加载到其中一个段寄存器中。因此，尽管一个系统可以定义数以千计的段，但只有6个可以立即使用。其他的段可以通过在程序执行期间将它们的段选择器加载到这些寄存器中来实现。</p>
<p>每个段寄存器都有一个 “可见 “部分和一个 “隐藏 “部分。(隐藏部分有时被称为”描述符缓存 “或 “阴影寄存器”）。当段选择器被加载到段寄存器的可见部分时，处理器也会在段寄存器的隐藏部分加载基础地址、段限制和段描述符的访问控制信息。这些信息来自段选择器所指向的段描述符。缓存在段寄存器中的信息（可见的和隐藏的）允许处理器翻译地址，而不需要花费额外的总线周期来读取基址和限制。<br>系统中，多个处理器可以访问相同的描述符表，当描述符表被修改时，软件有责任重新加载段寄存器。如果不这样做，缓存在段寄存器中的旧的段描述符就可能在其内存驻留版本被修改后被使用。<br>为加载段寄存器提供了两种类型的加载指令:</p>
<ol>
<li><p>直接加载指令，如MOV, POP, LDS, LES, LSS, LGS和LFS指令。这些指令明确地引用段寄存器。</p>
</li>
<li><p>隐含的加载指令，如CALL、JMP和RET指令的远端指针版本，SYSENTER和SYSEXIT指令，以及IRET、INTn、INTO和INT3指令。<br>这些指令改变了CS寄存器的内容（有时也会改变其他段寄存器的内容），这是其操作的附带部分。MOV指令也可以用来将段寄存器的可见部分存储在通用寄存器中。</p>
</li>
</ol>
<h3 id="Segment-Loading-Instructions-in-IA-32e-Mode-IA-32e模式下的段加载指令"><a href="#Segment-Loading-Instructions-in-IA-32e-Mode-IA-32e模式下的段加载指令" class="headerlink" title="Segment Loading Instructions in IA-32e Mode(IA-32e模式下的段加载指令)"></a>Segment Loading Instructions in IA-32e Mode(IA-32e模式下的段加载指令)</h3><p>由于ES、DS和SS段寄存器在64位模式下不被使用，它们在段描述符寄存器中的字段（base, limit, and attribute）被忽略了。某些形式的段装载指令也是无效的（例如LDS, POP ES）。引用ES、DS或SS段的地址计算被视为段基<br>为零。<br>处理器检查所有线性地址引用都是典型的形式，而不是执行极限检查。模式切换并不改变段寄存器或相关描述符寄存器的内容。在64位模式执行过程中，这些寄存器也不会改变，除非执行显式段加载。<br>为了给应用程序设置兼容模式，段加载指令（MOV to Sreg, POP Sreg）在64位模式下正常工作。从系统描述符表（GDT或LDT）中读取一个条目，并加载到段描述符的隐藏部分。描述符寄存器的基数、极限和属性字段都被加载。然而，数据和堆栈段选择器以及描述符寄存器的内容被忽略。<br>当FS和GS段重写在64位模式下使用时，它们各自的基础地址被用于线性地址计算中使用。(FS或GS).base + index + displacement。然后，FS.base和GS.base会被扩展到整个实现所支持的线性地址大小。由此产生的有效地址计算可以跨越正负地址；产生的线性地址必须是规范的。<br>在64位模式下，使用FS段和GS段覆盖的内存访问不会被检查是否有运行时限制也不受属性检查的影响。正常的段加载（MOV to Sreg和POP Sreg）到FS和GS中加载一个在段描述符寄存器的隐藏部分加载一个标准的32位基础值。标准32位以上的基址位以上的基址位被清除为0，以保证使用少于64位的实现方式的一致性。<br>FS.base和GS.base的隐藏描述符寄存器字段被物理映射到MSR，以便加载64位实现支持的所有地址位。64位实现所支持的所有地址位。CPL=0的软件（特权软件）可以使用WRMSR将所有支持的线性地址位加载到FS.base或GS.base。写入64位FS.base和GS.base寄存器中的地址必须是典型的形式。如果WRMSR指令试图向这些寄存器写入非经典地址的WRMSR指令会导致#GP故障。<br>当处于兼容模式时，FS和GS的重写操作与32位模式行为的定义无关。值加载到隐藏描述符寄存器基字段的前32位线性地址位。兼容性模式在计算有效地址时忽略上面的32位。<br>一个新的64位模式指令，SWAPGS，可以用来加载GS base。SWAPGS将IA32_KernelGSbase MSR中的内核数据结构指针与GS base寄存器交换。然后，内核可以使用GS前缀对正常的内存引用来访问内核的数据结构。试图向IA32_KernelGSbase MSR写一个非正则的值（使用WRMSR）会导致一个#GP故障。</p>
<h3 id="Segment-Descriptors-段描述子"><a href="#Segment-Descriptors-段描述子" class="headerlink" title="Segment Descriptors(段描述子)"></a>Segment Descriptors(段描述子)</h3><p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404161935629.png" alt="image-20220404161935629"></p>
<p>段描述符是GDT或LDT中的一个数据结构，为处理器提供段的大小和位置以及访问控制和状态信息。段落描述符通常是由编译器、链接器、加载器、操作系统或执行器，但不是应用程序创建的。</p>
<p>段落描述符中的标志和字段如下:</p>
<p><strong>分段限制字段</strong><br>指定段的大小。处理器把两个段限制字段放在一起，形成一个 一个20位的值。处理器以两种方式之一解释段限制，这取决于G（粒度）标志的设置：</p>
<ul>
<li>如果粒度标志是清除的，段的大小可以从1字节到1MByte，以字节为单位递增。</li>
<li>如果颗粒度标志被设置，段的大小可以从4KB字节到4GB字节，以4KB字节为增量。</li>
</ul>
<p>处理器以两种不同的方式使用段的限制，取决于段是一个向上扩展的段或一个向下扩展的段。对于扩大的段，<br>在逻辑地址中的偏移量可以从0到段的极限范围。大于段限制的偏移量产生一般保护异常（#GP，用于SS以外的所有段）或堆栈故障异常（#SS用于SS段）。对于向下扩展的段，段限具有相反的功能。<br>偏移量可以从段限加1到FFFFFFFH或FFFFFFH，取决于B标志的设置。小于或等于段限制的偏移量产生一般保护异常或堆栈故障异常。减少一个扩展段的段限值字段的值，在段的地址空间的底部分配新的内存，而不是在顶部。<br>IA-32架构的堆栈总是向下增长，使得这种机制对于可扩展堆栈。</p>
<p><strong>基准地址字段</strong><br>定义段的第0字节在4-GByte线性地址空间中的位置。处理器将三个基础地址字段放在一起，形成一个32位的数值。段的基址应与16字节的边界对齐，尽管16字节对齐不是必须的。这种对齐方式允许程序通过在16字节边界上对齐代码和数据来最大限度地提高性能。</p>
<p><strong>类型字段</strong></p>
<p>表示段或门的类型，并指定可以对该段进行的访问类型和增长方向。这个字段的解释取决于描述符类型标志指定的是应用（代码或数据）描述符还是系统描述符。类型字段的类型字段的编码对代码、数据和系统描述符是不同的。</p>
<p><strong>S（描述符类型）标志</strong><br>指定段描述符是用于系统段（S标志为清除）还是用于代码或数据段（S标志为设置）。<br><strong>DPL（描述符权限级别）字段</strong><br>指定段的权限级别。特权级别的范围是0到3，其中0是最高的级别。<br><strong>P（段存在）标志</strong><br>指示段是否存在于内存中（设置）或不存在（清除）。如果这个标志是清除的，当指向段描述符的段选择器出现时，处理器会产生一个段不存在的异常（#NP）。内存管理软件可以使用这个标志来控制哪些段在给定的时间内被实际加载到物理内存中。它为管理虚拟内存提供了一个除分页之外的控制。当该标志被清除时，操作系统或执行程序可以自由地使用标记为 “可用 “的位置来存储自己的数据，例如关于丢失的段的位置的信息。<br><strong>D/B（默认操作大小/默认堆栈指针大小和/或上界）标志</strong><br>执行不同的功能，取决于段描述符是否是可执行的代码段、扩展的数据段、或者是其他的段，一个扩展的数据段，或者一个堆栈段。(对于32位的代码和数据段，这个标志应该总是设置为1，对于16位的代码和数据段，这个标志应该设置为0）。</p>
<ul>
<li>可执行代码段。该标志被称为D标志，它指示了有效地址和操作数的默认长度。如果该标志被设置，32位的地址和32位或8位的操作数；如果它被清除，16位的地址和16位或8位操作数。指令前缀66H可以用来选择默认以外的操作数，而指令前缀67H可以用来选择一个非默认的地址大小。</li>
<li>堆栈段（由SS寄存器指向的数据段）。该标志被称为B（大）标志。它指定了用于隐式堆栈操作的堆栈指针的大小（如push, pops, and calls）。如果该标志被设置，则使用一个32位的堆栈指针，该指针被存储在32位的ESP寄存器中；如果该标志被清除，则使用16位的堆栈指针，该指针被存储在16位的SP寄存器中。如果堆栈段被设置为一个向下扩展的数据段（在下一段中描述下一段描述），B标志也指定了堆栈段的上界。</li>
<li>扩大-缩小数据段。该标志被称为B标志，它指定了段的上限。如果该标志被设置，上界是FFFFFFFH（4GB字节）；如果该标志被清除，上限是FFFFFFFF（64KB）。</li>
</ul>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404164628034.png" alt="image-20220404164628034"></p>
<h2 id="描述符的分类"><a href="#描述符的分类" class="headerlink" title="描述符的分类"></a>描述符的分类</h2><p>段描述符分类</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404171152577.png" alt="image-20220404171152577"></p>
<p>段描述符是GDT和LDT中的一个数据结构项，用于向处理器提供有关一个段的位置、大小以及访问控制的状态信息。每个段描述符的长度是8个字节，含有3个主要字段：</p>
<ul>
<li>段基地址</li>
<li>段限长</li>
<li>段属性</li>
</ul>
<p>段描述符通常由编译器，链接器，加载器或者操作系统来创建，但绝不是应用程序。</p>
<p>段描述符通用格式如下所示</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404170746133.png" alt="image-20220404170746133"></p>
<p>系统段描述符中各个位的含义如下所示</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404170802198.png" alt="image-20220404170802198"></p>
<h3 id="存储段描述符"><a href="#存储段描述符" class="headerlink" title="存储段描述符"></a>存储段描述符</h3><h4 id="数据段描述符"><a href="#数据段描述符" class="headerlink" title="数据段描述符"></a>数据段描述符</h4><p>当S=1且TYPE字段的最高位（第2个双字的位11）为0时，表明是一个数据段描述符。</p>
<p>下图是数据段描述符的格式。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404171430725.png" alt="image-20220404171430725"></p>
<h4 id="代码段描述符"><a href="#代码段描述符" class="headerlink" title="代码段描述符"></a>代码段描述符</h4><p>当S=1且TYPE字段的最高位（第2个双字的位11）为1时，表明是一个代码段描述符。</p>
<p>下图是代码段描述符的格式。</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404171452192.png" alt="image-20220404171452192"></p>
<h3 id="系统描述符类型"><a href="#系统描述符类型" class="headerlink" title="系统描述符类型"></a>系统描述符类型</h3><p>当段描述符中S标志位(描述符类型)是复位状态(0)的话，那么该描述符是一个系统描述符。处理器能够识别以下一些类型的系统段描述符:</p>
<ul>
<li>局部描述符表(LDT)的段描述符</li>
<li>任务状态段（TSS）描述符</li>
<li>调用门描述符</li>
<li>中断门描述符</li>
<li>陷阱门描述符</li>
<li>任务门描述符</li>
</ul>
<p>这些描述符类型可分为两大类: 系统段描述符和门描述符。系统段描述符指向系统段(如LDT或TSS段)，门描述符也就是一个”门”,对应调用、中断或陷阱门，其中含有代码段的选择符和段中程序入口点的指针；对于任务门，其中含有TSS的段选择符。</p>
<p>系统段描述符和门描述符类型字段的编码如下所示:</p>
<p><img src="/2022/04/03/%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220404170843601.png" alt="image-20220404170843601"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">x86系统架构预览-读书笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-03-28 15:44:58 / Modified: 20:05:31" itemprop="dateCreated datePublished" datetime="2022-03-28T15:44:58+08:00">2022-03-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="x86系统架构概述"><a href="#x86系统架构概述" class="headerlink" title="x86系统架构概述"></a>x86系统架构概述</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>[TOC]</p>
<h2 id="系统级体系架构概述"><a href="#系统级体系架构概述" class="headerlink" title="系统级体系架构概述"></a>系统级体系架构概述</h2><p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328160624845.png" alt="image-20220328160624845"></p>
<h3 id="Global-and-Local-Descriptor-Tables-全局和局部描述符表"><a href="#Global-and-Local-Descriptor-Tables-全局和局部描述符表" class="headerlink" title="Global and Local Descriptor Tables(全局和局部描述符表)"></a>Global and Local Descriptor Tables(全局和局部描述符表)</h3><p>​         当在保护模式下操作时，所有的内存访问都要经过<strong>全局描述符表（GDT）</strong>或可选的<strong>本地描述符表（LDT）</strong>，如图2-1所示。这些表包含的条目描述符称为段 。段描述符提供了段的基本地址以及访问权限、类型和使用信息。<br>​        每个段描述符都有一个相关的段选择器。一个段选择器为使用它的软件提供了 一个GDT或LDT的索引（其相关段描述符的偏移量），一个全局/本地标志（决定选择器是否指向GDT或LDT），以及访问权限信息。<br>​       要访问段中的一个字节，必须提供一个段选择器和一个偏移量。段选择器提供访问该段的段描述符（在GDT或LDT中）。从段描述符中，处理器获得该段在线性地址空间中的基本地址。然后，偏移量提供了字节相对于基址的位置。这种机制可以用来访问任何有效的代码、数据或堆栈段。只要该段可以从处理器所处的当前权限级别（CPL）访问。CPL被定义为当前执行的代码段的保护级别。<br>​       见图2-1。图中的实心箭头表示一个线性地址，虚线表示一个段选择器。而点状箭头表示物理地址。为了简单起见，许多段选择器被显示为 直接指向一个段。然而，从段选择器到其相关段的实际路径总是通过GDT或LDT。GDT的基址的线性地址包含在GDT寄存器（GDTR）中；LDT的线性地址包含在LDT寄存器（LDTR）中。</p>
<h4 id="Global-and-Local-Descriptor-Tables-in-IA-32e-Mode"><a href="#Global-and-Local-Descriptor-Tables-in-IA-32e-Mode" class="headerlink" title="Global and Local Descriptor Tables in IA-32e Mode"></a>Global and Local Descriptor Tables in IA-32e Mode</h4><p>​        GDTR 和 LDTR 寄存器在 IA-32e 子模式（64 位模式和兼容模式）中都被扩展到 64 位宽。全局和局部描述符表在64位模式下被扩展以支持64位基地址，（16字节的LDT 描述符持有一个64位的基本地址和各种属性）。在兼容模式下，描述符不被扩展 。</p>
<h3 id="System-Segments-Segment-Descriptors-and-Gates-系统段，段描述符和门"><a href="#System-Segments-Segment-Descriptors-and-Gates-系统段，段描述符和门" class="headerlink" title="System Segments, Segment Descriptors, and Gates(系统段，段描述符和门)"></a>System Segments, Segment Descriptors, and Gates(系统段，段描述符和门)</h3><p>​       除了构成程序或过程执行环境的代码、数据和堆栈段之外，架构还定义了两个系统段：<strong>任务状态段（TSS）</strong>和<strong>LDT</strong>。GDT不被视为。<br>因为它不是通过段选择器和段描述符访问的。TSSs和LDTs有为它们定义了段描述符。该体系结构还定义了一组特殊的描述符，称为门[调用门（call gates），中断门（interrupt gates），陷阱门（trap gates），和 任务门（task gates）]。这些描述符为系统程序和处理程序提供了受保护的通道，这些程序和处理程序可能在与应用程序不同的权限级别上运行。例如，一个调用门的CALL可以提供访问一个代码段中的程序，该代码段与当前代码段处于相同或更低的权限级别（更多权限）。<br>​        为了通过调用门访问一个过程，调用过程提供了调用门的选择器。然后，处理器对调用门进行访问权限检查，将CPL与调用门和调用门所指向的目标代码段的权限级别进行比较。如果对目标代码段的访问是允许的，处理器就会得到目标代码段的段选择器和该代码段的偏移。如果调用需要改变权限级别，处理器也会切换到目标权限级别的堆栈。新堆栈的段选择器是从当前运行任务的TSS中获得的。门也促进了16位和32位代码段之间的转换，反之亦然。</p>
<h4 id="Gates-in-IA-32e-Mode"><a href="#Gates-in-IA-32e-Mode" class="headerlink" title="Gates in IA-32e Mode"></a>Gates in IA-32e Mode</h4><p>在IA-32e模式下，以下描述符是16字节的描述符（扩大到允许64位基数）。LDT描述符、64位TSS、调用门、中断门和陷阱门。调用门促进了64位模式和兼容模式之间的转换。在IA32e模式下不支持任务门。在权限级别改变时，堆栈段选择器不从TSS中读取。相反，它们被设置为NULL。</p>
<h3 id="Task-State-Segments-and-Task-Gates-任务状态段任务门"><a href="#Task-State-Segments-and-Task-Gates-任务状态段任务门" class="headerlink" title="Task-State Segments and Task Gates(任务状态段任务门)"></a>Task-State Segments and Task Gates(任务状态段任务门)</h3><p>​       TSS（见图2-1）定义了一个任务的执行环境的状态。它包括通用寄存器、段寄存器、EFLAGS寄存器、EIP寄存器和段选择器的状态-指向三个堆栈段（每个权限级别有一个堆栈）。TSS还包括段选择器 ，用于与任务相关的LDT和分页结构层次的基址。<br>​       所有受保护模式下的程序执行都发生在一个任务（称为当前任务）的上下文中。<br>​      当前任务的TSS的段选择器被存储在任务寄存器中。最简单的切换方法是调用或跳转到一个新的任务。这里，新任务的TSS的段选择器是在CALL或JMP指令中给出的。在切换任务时，处理器会执行以下动作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 将当前任务的状态存储在当前TSS中。</span><br><span class="line">2. 用新任务的段选择器加载任务寄存器。</span><br><span class="line">3. 通过GDT中的段描述符访问新的TSS。</span><br><span class="line">4. 将新任务的状态从新的TSS加载到通用寄存器、段寄存器中、LDTR，控制寄存器CR3（分页结构层次的基址），EFLAGS寄存器，以及EIP寄存器。</span><br><span class="line">5. 开始执行新的任务。一个任务也可以通过一个任务门来访问。任务门类似于调用门，只是它提供了访问 (通过段选择器)访问一个TSS而不是一个代码段。</span><br></pre></td></tr></table></figure>
<h4 id="Task-State-Segments-in-IA-32e-Mode"><a href="#Task-State-Segments-in-IA-32e-Mode" class="headerlink" title="Task-State Segments in IA-32e Mode"></a>Task-State Segments in IA-32e Mode</h4><p>在IA-32e模式下不支持硬件任务开关。然而，TSSs继续存在。TSS的基本地址由其描述符指定。一个64位的TSS持有以下对64位操作很重要的信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 每个特权级别的堆栈指针地址</span><br><span class="line">- 中断堆栈表的指针地址</span><br><span class="line">- IO-permission位图的偏移地址（从TSS基数开始）。</span><br><span class="line">  在IA-32e模式下，任务寄存器被扩展为容纳64位基址。</span><br></pre></td></tr></table></figure>
<h3 id="Interrupt-and-Exception-Handling-中断和异常处理"><a href="#Interrupt-and-Exception-Handling-中断和异常处理" class="headerlink" title="Interrupt and Exception Handling(中断和异常处理)"></a>Interrupt and Exception Handling(中断和异常处理)</h3><p>​          外部中断、软件中断和异常是通过中断描述符表（IDT）处理的。IDT存储了一个门描述符的集合，提供对中断和异常处理程序的访问。与 GDT一样，IDT不是一个段。IDT基础的线性地址包含在IDT寄存器（IDTR）中。IDT中的门描述符可以是中断、陷阱、或任务门描述符。要访问一个中断或异常处理程序 ，处理器首先从内部硬件、外部中断控制器或软件中接收一个中断向量（中断号）。中断控制器，或通过INT、INTO、INT 3或BOUND指令从软件接收一个中断向量（中断号）。中断向量 提供了一个进入IDT的索引。如果选择的门描述符是一个中断门或陷阱门，相关的处理程序就会被访问。处理程序的访问方式与通过调用门调用程序的方式类似。如果描述符是一个<br>任务门，处理程序将通过一个任务开关被访问。</p>
<h4 id="Interrupt-and-Exception-Handling-IA-32e-Mode"><a href="#Interrupt-and-Exception-Handling-IA-32e-Mode" class="headerlink" title="Interrupt and Exception Handling IA-32e Mode"></a>Interrupt and Exception Handling IA-32e Mode</h4><p>在IA-32e模式下，中断描述符被扩展到16个字节，以支持64位基本地址。IDTR寄存器被扩展为容纳64位基地址。不支持任务门。</p>
<h3 id="Memory-Management-内存管理"><a href="#Memory-Management-内存管理" class="headerlink" title="Memory Management(内存管理)"></a>Memory Management(内存管理)</h3><p>​        系统架构支持内存的直接物理寻址或虚拟内存（通过分页）。<br>​        当使用物理寻址时，线性地址被当作物理地址处理。当使用分页时：所有的代码、数据、堆栈和系统段（包括GDT和IDT）可以被分页，只有最近访问的 页被保存在物理内存中。物理内存中的页面（有时称为页框）的位置包含在分页结构中。这些结构位于物理内存中。<br>​        分页结构层次结构的基本物理地址包含在控制寄存器CR3中。分页结构中的条目决定了 一个分页框的物理地址、访问权限和内存管理信息。为了使用这种分页机制，一个线性地址被分解成几个部分。这些部分提供了进入分页结构和页框的单独偏移。一个系统可以有一个单一的分页结构层次，也可以有几个。例如 ，每个任务可以有自己的层次结构。</p>
<h4 id="Memory-Management-in-IA-32e-Mode"><a href="#Memory-Management-in-IA-32e-Mode" class="headerlink" title="Memory Management in IA-32e Mode"></a>Memory Management in IA-32e Mode</h4><p>在IA-32e模式下，物理内存页由一组系统数据结构管理。在兼容模式 和64位模式下，使用四级系统数据结构。这些结构包括 ：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 第4级页面映射（PML4）--PML4表中的一个条目包含了一个页面的基点的物理地址目录指针表、访问权限和内存管理信息。PML4的基本物理地址被存储在CR3中。</span><br><span class="line">- 一组页目录指针表 - 页目录指针表中的一个条目包含了页目录指针表基的物理地址。</span><br><span class="line">- 一组页目录 - 页目录表中的一个条目包含了一个页目录表基的物理地址、访问权限和内存管理信息。</span><br><span class="line">- 成套的页表 - 一个页表中的条目包含了一个页框的物理地址，访问权限和内存管理信息。</span><br></pre></td></tr></table></figure>
<h3 id="System-Registers-系统寄存器"><a href="#System-Registers-系统寄存器" class="headerlink" title="System Registers(系统寄存器)"></a>System Registers(系统寄存器)</h3><p>为了帮助初始化处理器和控制系统操作，系统结构在EFLAGS寄存器中提供了系统标志和几个系统寄存器：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- EFLAGS寄存器中的系统标志和IOPL字段控制任务和模式的切换，中断处理，指令跟踪和访问权限。</span><br><span class="line">- 控制寄存器（CR0、CR2、CR3和CR4）包含各种控制系统级操作的标志和数据域。这些寄存器中的其他标志被用来表示对操作系统或执行器中特定处理器能力的支持。</span><br><span class="line">- 调试寄存器允许设置断点以用于调试程序和系统软件。</span><br><span class="line">- GDTR、LDTR和IDTR寄存器包含了它们各自表的线性地址和大小（限制）。</span><br><span class="line">- 任务寄存器包含了当前任务的线性地址和TSS的大小。</span><br><span class="line">- 特定型号的寄存器。这些寄存器控制一些项目，如调试扩展。</span><br><span class="line">  这些寄存器的数量和功能在英特尔64和IA-32处理器系列的不同成员中是不同的。</span><br></pre></td></tr></table></figure>
<h4 id="System-Registers-in-IA-32e-Mode"><a href="#System-Registers-in-IA-32e-Mode" class="headerlink" title="System Registers in IA-32e Mode"></a>System Registers in IA-32e Mode</h4><p>​        在IA-32e模式下，四个系统描述符表寄存器（GDTR、IDTR、LDTR和TR）在硬件上被扩展为<br>以容纳64位的基本地址。EFLAGS成为64位的RFLAGS寄存器。CR0-CR4被扩展到64位。CR8变得可用。CR8提供了对任务优先级寄存器（TPR）的读写访问，这样操作系统就可以控制外部设备的优先级。在64位模式下，调试寄存器DR0-DR7为64位。在兼容模式下，DR0-DR3的地址匹配也是以64位粒度进行的。在支持IA-32e模式的系统上，扩展功能启用寄存器（IA32_EFER）是可用的。这个特定型号的寄存器控制IA-32e模式的激活和其他IA-32e模式的操作。此外，还有几个特定型号的寄存器管理 IA-32e 模式指令。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- IA32_KernelGSbase - 由 SWAPGS 指令使用。</span><br><span class="line">- IA32_LSTAR - 由 SYSCALL 指令使用。</span><br><span class="line">- IA32_SYSCALL_FLAG_MASK - 由SYSCALL指令使用。</span><br><span class="line">- IA32_STAR_CS - 由SYSCALL和SYSRET指令使用。</span><br></pre></td></tr></table></figure>
<h3 id="Other-System-Resources"><a href="#Other-System-Resources" class="headerlink" title="Other System Resources"></a>Other System Resources</h3><p>除了前几节描述的系统寄存器和数据结构，系统结构还提供了以下的额外资源。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 操作系统指令</span><br><span class="line">- 性能监测计数器</span><br><span class="line">- 内部缓存和缓冲区</span><br><span class="line">  等</span><br></pre></td></tr></table></figure>
<h2 id="实模式和保护模式转换"><a href="#实模式和保护模式转换" class="headerlink" title="实模式和保护模式转换"></a>实模式和保护模式转换</h2><p>二者根本区别为：进程内存受保护与否</p>
<p> 保护模式 - 这是处理器的原生操作模式。它提供了一套丰富的结构特性、灵活性、高性能和对现有软件基础的向后兼容性。</p>
<p>真实地址模式 - 这种操作模式提供了英特尔8086处理器的编程环境，并有一些扩展（如切换到受保护或系统管理模式的能力）。</p>
<h3 id="实模式工作原理"><a href="#实模式工作原理" class="headerlink" title="实模式工作原理"></a>实模式工作原理</h3><p>实模式出现于早期8088CPU时期。当时由于CPU的性能有限，一共只有20位地址线（所以地址空间只有1MB），以及8个16位的通用寄存器，以及4个16位的段寄存器。所以为了能够通过这些16位的寄存器去构成20位的主存地址，必须采取一种特殊的方式。当某个指令想要访问某个内存地址时，它通常需要用下面的这种格式来表示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(段基址：段偏移量)</span><br></pre></td></tr></table></figure>
<p>其中第一个字段是段基址，它的值是由段寄存器提供的。</p>
<p>第二字段是段内偏移量，代表你要访问的这个内存地址距离这个段基址的偏移。它的值就是由通用寄存器来提供的，所以也是16位。</p>
<p>CPU采用把段寄存器所提供的段基址先向左移4位。这样就变成了一个20位的值，然后再与段偏移量相加，即可组合成一个二十位的地址。即：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">物理地址 = 段基址&lt;&lt;4 + 段内偏移</span><br></pre></td></tr></table></figure>
<h3 id="保护模式工作原理"><a href="#保护模式工作原理" class="headerlink" title="保护模式工作原理"></a>保护模式工作原理</h3><p>随着CPU的发展，CPU的地址线的个数也从原来的20根变为现在的32根，所以可以访问的内存空间也从1MB变为现在4GB，寄存器的位数也变为32位。所以实模式下的内存地址计算方式就已经不再适合了。所以就引入了现在的保护模式，实现更大空间的，更灵活也更安全的内存访问。</p>
<p>在保护模式下，CPU的32条地址线全部有效，可寻址高达4G字节的物理地址空间; 但是我们的内存寻址方式还是得兼容老办法，即(段基址：段偏移量)的表示方式。当然此时CPU中的通用寄存器都要换成32位寄存器(除了段寄存器)来保证寄存器能访问所有的4GB空间。</p>
<p>我们的偏移值和实模式下是一样的，就是变成了32位而已，而段值仍旧是存放在原来16位的段寄存器中，但是这些段寄存器存放的却不再是段基址了，毕竟之前说过实模式下寻址方式不安全，我们在保护模式下需要加一些限制，而这些限制可不是一个寄存器能够容纳的，于是我们把这些关于内存段的限制信息放在一个叫做<strong>全局描述符表(GDT)</strong>的结构里。全局描述符表中含有一个个表项，每一个表项称为<strong>段描述符。</strong>而段寄存器在保护模式下存放的便是相当于一个数组索引的东西，通过这个索引，可以找到对应的表项。段描述符存放了段基址、段界限、内存段类型属性(比如是数据段还是代码段,注意<strong>一个段描述符只能用来定义一个内存段</strong>)等许多属性,具体信息见下图：</p>
<p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328193206147.png" alt="image-20220328193206147"></p>
<p>其中，段界限表示段边界的扩张最值，即最大扩展多少或最小扩展多少，用20位来表示，它的单位可以是字节，也可以是4KB，这是由G位决定的(G为1时表示单位为4KB)。</p>
<p>实际段界限边界值=(描述符中的段界限+1)*（段界限的单位大小(即字节或4KB))-1，如果偏移地址超过了段界限，CPU会抛出异常。</p>
<p>全局描述符表位于内存中，需要用专门的寄存器指向它后， CPU 才知道它在哪里。这个专门的寄存器便是<strong>GDTR</strong>(一个48位的寄存器),专门用来存储 GDT 的内存地址及大小。</p>
<p>还需要介绍一个新的概念：段的选择子。段寄存器 CS、 DS、 ES、 FS、 GS、 SS，在实模式下时，段中存储的是段基地址，即内存段的起始地址。 而在保护模式下时，由于段基址已经存入了段描述符中，所以段寄存器中再存放段基址是没有意义的，在段寄存器中存入的是一个叫作选择子的东西。选择子“基本上”是个索引值。由于段寄存器是 16 位，所以选择子也是 16 位，在其低 2 位即第 0～1 位， 用来存储 RPL，即请求特权级，可以表示 0、 1、 2、 3 四种特权级。在选择子的第 2 位是 TI 位，即 Table Indicator，用来指示选择子是在 GDT 中，还是 LDT 中索引描述符。 TI 为 0 表示在 GDT 中索引描述符， TI 为 1 表示在 LDT 中索引描述符。选择子的高 13 位，即第 3～15 位是 描述符的索引值，用此值在 GDT 中索引描述符。前面说过 GDT 相当于一个描述符数组，所以此选择子中的索引值就是 GDT 中的下标。选择子结构如下：</p>
<p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328193601767.png" alt="image-20220328193601767"></p>
<p>此外， 扩充的存储器分段管理机制和可选的存储器分页管理机制，不仅为存储器共享和保护提供了硬件支持，而且为实现虚拟存储器提供了硬件支持; 支持多任务，能够快速地进行任务切换(switch)和保护任务环境(context); 4个特权级和完善的特权检查机制，既能实现资源共享又能保证代码和数据的安全和保密及任务的隔离; 支持虚拟8086方式，便于执行8086程序。</p>
<h3 id="实模式到保护模式的切换"><a href="#实模式到保护模式的切换" class="headerlink" title="实模式到保护模式的切换"></a>实模式到保护模式的切换</h3><p>从实模式切换到保护模式大致可以分为以下几个步骤：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1、屏蔽中断</span><br><span class="line"></span><br><span class="line">2、初始化全局描述符表（GDT）</span><br><span class="line"></span><br><span class="line">3、将CR0寄存器最低位置1</span><br><span class="line"></span><br><span class="line">4、执行远跳转</span><br><span class="line"></span><br><span class="line">5、初始化段寄存器和栈指针</span><br></pre></td></tr></table></figure>
<h4 id="屏蔽中断"><a href="#屏蔽中断" class="headerlink" title="屏蔽中断"></a>屏蔽中断</h4><p>在16位实模式下的中断由BIOS处理，进入保护模式后，中断将交给中断描述符表IDT里规定的函数处理，在刚进入保护模式时IDTR寄存器的初始值为0，一旦发生中断（例如BIOS的时钟中断）就将导致CPU发生异常，所以需要首先屏蔽中断。屏蔽中断可以使用cli指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cli</span><br></pre></td></tr></table></figure>
<h4 id="初始化GDT"><a href="#初始化GDT" class="headerlink" title="初始化GDT"></a>初始化GDT</h4><p>在32位保护模式中，段与段之间是互相隔离的，当访问的地址超出段的界限时处理器就会阻止这种访问，因此每个段都需要有起始地址、范围、访问权限以及其他属性四个部分，这四个部分合在一起叫做段描述符（Segment Descriptor），总共需要8个字节来描述。但Intel为了保持向后兼容，将段寄存器仍然规定为16-bit，显然我们无法用16-bit的段寄存器来直接存储64-bit的段描述符。 </p>
<p>解决的办法是将所有64-bit的段描述符放到一个数组中，将16-bit段寄存器的值作为下标来访问这个数组（以字节为单位），获取64-bit的段描述符，这个数组就叫是全局描述符表</p>
<h4 id="将CR0最低位置1"><a href="#将CR0最低位置1" class="headerlink" title="将CR0最低位置1"></a>将CR0最低位置1</h4><p>CR0是系统内的32位控制寄存器之一，可以控制CPU的一些重要特性。其中最低位是保护允许位（Protected Mode Enable, PE），PE位置1后CPU进入保护模式（注意此时还是16位保护模式，不是32位保护模式），置0时则为实模式。现在我们要进入保护模式，即将CR0的最低位置1，汇编代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-把 cr0 的最低位置为 1，开启保护模式</span><br><span class="line">mov eax, cr0</span><br><span class="line">or eax, 0x1</span><br><span class="line">mov cr0, eax</span><br></pre></td></tr></table></figure>
<h4 id="执行远跳转"><a href="#执行远跳转" class="headerlink" title="执行远跳转"></a>执行远跳转</h4><p>将cr0最低位置1后，CPU就进入了保护模式，此时需要马上执行一条远跳转指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmp 08h:PModeMain</span><br></pre></td></tr></table></figure>
<p>这条指令有两个作用，第一个作用是将cs段寄存器的值修改为08h，切换到保护模式后，CPU寻址的方式就从实模式中的段地址 * 16 + 偏移地址改为了通过gdt寻址，所以这里的08h是段选择子而不是段地址，并且远跳转指令会自动将cs的值修改为对应的段选择子，这里是08h。</p>
<p>远跳转的另一个作用是清空CPU的流水线，流水线的作用在计组中有提到过，为了加速指令的执行，CPU在执行当前指令时会同时加载并解析接下来的一些指令，在进入保护模式之前，已经有许多指令进入了流水线，这些指令都是按16位模式处理的，而进入保护模式后的指令都是32位，所以这里通过一个远跳转来让CPU清空流水线。</p>
<p>切换到32位模式后，就应该执行32位的指令了，所以从PModeMain开始的指令都采用32位模式编译，通过[bits 32]这个标记实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[bits 32]</span><br><span class="line">PModeMain:</span><br></pre></td></tr></table></figure>
<h4 id="初始化段寄存器和栈指针"><a href="#初始化段寄存器和栈指针" class="headerlink" title="初始化段寄存器和栈指针"></a>初始化段寄存器和栈指针</h4><p>上一步中我们将代码段寄存器cs初始化成了0x08，现在我们还需要初始化其他的段寄存器如数据段寄存器ds，拓展段寄存器es，栈段ss以及fs，gs两个由操作系统使用的段。 </p>
<p>另外我们还需要初始化栈指针ebp和esp，代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[bits 32]</span><br><span class="line">PModeMain:</span><br><span class="line">    mov ax, 0x10        ; 将数据段寄存器ds和附加段寄存器es置为0x10</span><br><span class="line">    mov ds, ax         </span><br><span class="line">    mov es, ax</span><br><span class="line">    mov fs, ax          ; fs和gs寄存器由操作系统使用，这里统一设成0x10</span><br><span class="line">    mov gs, ax</span><br><span class="line">    mov ax, 0x18        ; 将栈段寄存器ss置为0x18</span><br><span class="line">    mov ss, ax</span><br><span class="line">    mov ebp, 0x7c00     ; 现在栈顶指向 0x7c00</span><br><span class="line">    mov esp, ebp</span><br></pre></td></tr></table></figure>
<h3 id="需要修改的内容"><a href="#需要修改的内容" class="headerlink" title="需要修改的内容"></a>需要修改的内容</h3><ul>
<li><p>GDT初始化：定义段描述符、定义GDTR的数据结构、定义GDT选择子</p>
</li>
<li><p>数据段+堆栈段</p>
</li>
<li><p>16位代码段（实模式下）的定义</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.设置代码运行环境，即给相关寄存器赋值；</span><br><span class="line">2.初始化16位代码段描述符 + 32位代码段描述符 + 堆栈段描述符 +数据段描述符；</span><br><span class="line">3.初始化全局描述符表寄存器GDTR的内容，因为其基地址还没有初始化， 然后通过lgdt [GdtPtr]，将内存中GDTR的内容加载到GDTR中，重点在于保存 GDT的基地址；</span><br><span class="line">4.关中断， 即设置CPU不响应任何其他的外部中断，因为CPU现在的时间片只属于当前加载的程序；</span><br><span class="line">5.打开地址线A20；</span><br><span class="line">6将CR0的 PE 位置1；PE位==1，表明CPU运行在保护模式下；</span><br><span class="line">7.跳转到保护模式： jmp dword SelectorCode32:0 ，这里的代码指提供了选择子，（2.3）末部分，已经说明了为什么通过选择子就可以索引到 32位代码段 LABEL_SEG_CODE32；（这就是从实模式跳入保护模式）</span><br></pre></td></tr></table></figure>
</li>
<li><p>32位代码段（由实模式跳入，即保护模式）的定义</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.将对应选择子赋值到 对应寄存器， 即设置任务代码的运行环境，不得不提的是本段代码还改变了ss和esp，则在32位代码段中所有的堆栈操作将会在新增的堆栈段中进行；</span><br><span class="line">2.做任务；</span><br><span class="line">3.任务做完后，跳转到16位代码段，因为从保护模式跳回实模式，只能从16位代码段中跳回；</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="80x86系统指令寄存器"><a href="#80x86系统指令寄存器" class="headerlink" title="80x86系统指令寄存器"></a>80x86系统指令寄存器</h2><h3 id="标志寄存器"><a href="#标志寄存器" class="headerlink" title="标志寄存器"></a>标志寄存器</h3><p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328194436597.png" alt="image-20220328194436597"></p>
<p>  EFLAGS系统标志和IOPL字段控制I/O，可屏蔽的硬件中断、调试、任务切换和虚拟8086模式。仅允许特权代码（通常为操作系统过执行代码）修改这些位。</p>
<p>​       在64位模式下，RFLAGS寄存器扩展为64位，保留高32位。PFLAGS中系统标志（64位模式）或EFLAGS（兼容模式）。在IA-32e模式下，处理器不允许设置VM位，因为不支持virtual-8086模式（尝试设置该位将被忽略）。同样，处理器将不会设置NT位。但是处理器确实允许软件将NT位置1（请注意，如果将NT位置1，则IRET会在IA-32e模式下引起一般性保护故障）。在IA-32e模式下，YSCALL/SYSRET指令具有一种可编程的方法来指定哪些位是已RFLAGS/EFLAGS中清除。这些说明保存/恢复EFLAGS/RFLAGS。</p>
<h3 id="内存管理寄存器"><a href="#内存管理寄存器" class="headerlink" title="内存管理寄存器"></a>内存管理寄存器</h3><p><img src="/2022/03/28/x86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E9%A2%84%E8%A7%88-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/image-20220328194633100.png" alt="image-20220328194633100"></p>
<h4 id="GDTR"><a href="#GDTR" class="headerlink" title="GDTR"></a>GDTR</h4><p>保存基地址（在保护模式下为32位，在IA-32e模式下为64位）和16位表GDT的限制。基地址指定GDT字节0的线性地址；表格限制指定了表中的字节数。LGDT和SGDT指令分别加载和存储GDTR寄存器。开机或重置在处理器中，基地址设置为默认值0，限制设置为0FFFFH。必须有新的基本地址将其作为保护模式操作的处理器初始化过程的一部分加载的GDTR。</p>
<h4 id="LDTR"><a href="#LDTR" class="headerlink" title="LDTR"></a>LDTR</h4><p>​       保留16位段选择器的结伴地址（在保护模式下为32位，在IA-32e模式下为64位）段限制和LDT的描述符属性。基地址指定字节的线性地址LDT段的0，段限制指定段中的字节数。LLDT和SLDT指令分别加载和存储LDTR寄存器的段选择器部分的包含LDT的段必须在GDT中具有段描述符。当LLDT指令加载一个LDTR中的段选择器：LDT描述符中的基地址、限制和描述符属性会自动加载到LDTR中。<br>​       发生任务切换时，LDTR会自动加载LDT的段选择器和描述符为新任务。在写入新的LDT信息之前，不会自动保存LDTR的内容进入寄存器。在处理器加电或重置时，段选择器和基地址被设置为默认值0和限制设置为0FFFFH。</p>
<h4 id="IDTR"><a href="#IDTR" class="headerlink" title="IDTR"></a>IDTR</h4><p>​        寄存器保存基地址（保护模式下为32位，IA-32e模式下为64位）和16位表限制IDT。基地址指定IDT字节0的线性地址，表限制指定数量表中的字节数。LIDT和SIDT指令分别加载和存储IDTR寄存器。开机或重置处理器后，基地址设置为默认值0，限制设置为0FFFFH。然后可以在处理器初始化过程中更改寄存器中的地址和限制。</p>
<h4 id="TR"><a href="#TR" class="headerlink" title="TR"></a>TR</h4><p>​        任务寄存器包含16位段选择器，基地址（在保护模式下为32位，在IA-32e中为64位），段限制和当前任务的TSS的描述符属性。选择器引用TSS、GDT的描述符。基地址指定TSS字节0的线性地址；段限制指定TSS中的字节数。LTR和STR指令分别加载和存储任务寄存器的段选择器部分。当LTR指令将段选择器加载到任务寄存器中时，基址、限制和描述符属性从TSS描述符将自动加载到任务寄存器中。处理器加电或重置时，基地址设置为默认值0，限制设置为0FFFFH。发生任务切换时，任务寄存器会自动加载段选择器和描述符新任务的TSS。在写入的新的TSS之前，不会自动保存任务寄存器的内容信息进去寄存器。</p>
<h3 id="控制寄存器"><a href="#控制寄存器" class="headerlink" title="控制寄存器"></a>控制寄存器</h3><h4 id="CR0"><a href="#CR0" class="headerlink" title="CR0"></a>CR0</h4><p>包含控制处理器的操作模式和状态的系统控制标志。</p>
<h4 id="CR3"><a href="#CR3" class="headerlink" title="CR3"></a>CR3</h4><p>包含分页结构层次结构基础的物理地址和两个标志（PCD和PWT）。仅指定基址的最高有效位（减去低12位）；低12位地址“0”假定为0.因此，第一个分页结构必须与页面（4KB）对齐边界。PCT和PWT标志控制处理器内部数据中该分页结构的缓存（它们不控制页面目录信息的TLB缓存）。使用物理地址扩展中，CR3寄存器包含页面目录指针表的基地址。在IA-32e模式下，CR3寄存器包含PML4表的基地址。</p>
<h2 id="系统指令"><a href="#系统指令" class="headerlink" title="系统指令"></a>系统指令</h2><p>LGDT加载GDTR寄存器——将GDT基址和限制从内存加载到GDTR寄存器。<br>SGDT存储GDTR寄存器——将GDT基址和GDTR寄存器中的限制存储到内存。<br>LIDT加载IDTR寄存器——将IDT基址和限制从存储器加载到IDTR寄存器中。<br>SIDT加载IDTR寄存器——将IDT寄存器的IDT基址和限制存储到内存中。<br>LLDT加载LDT寄存器——将LDT段选择器和段描述符从内存加载到LDTR，段选择器操作数也可以位于通用寄存器中。<br>SLDT存储LDT寄存器——将LDTR寄存器中的LDT段选择器存储到存储器或存储器中。<br>LTR记载任务寄存器——将TSS的段选择器和段描述符从内存加载到任务寄存器，段选择器操作数也可以位于通用寄存器中。<br>STR存储任务寄存器——将当前任务TSS的段选择器从任务存储器存储到存储器或通用寄存器。</p>
<h2 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://zhuanlan.zhihu.com/p/42309472</span><br><span class="line">https://mp.weixin.qq.com/s/VGhpbZaeyVwq3Ghs2E6eEw</span><br><span class="line">https://zhuanlan.zhihu.com/p/412845339</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/" class="post-title-link" itemprop="url">解决广告弹窗</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-03-12 20:00:20 / Modified: 20:25:48" itemprop="dateCreated datePublished" datetime="2022-03-12T20:00:20+08:00">2022-03-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="解决广告弹窗"><a href="#解决广告弹窗" class="headerlink" title="解决广告弹窗"></a>解决广告弹窗</h1><p>对于广告弹窗，我们采取安装火绒安全软件的方式来解决。具体流程如下</p>
<p>打开网站</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.huorong.cn/</span><br></pre></td></tr></table></figure>
<p><img src="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/image-20220312201421955.png" alt="image-20220312201421955"></p>
<p>点击上方一栏的个人产品</p>
<p><img src="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/image-20220312201439903.png" alt="image-20220312201439903"></p>
<p>点击免费下载</p>
<p>下载安装等步骤正常进行。</p>
<p>安装好之后如下</p>
<p><img src="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/image-20220312201528490.png" alt="image-20220312201528490"></p>
<p>点击安全工具</p>
<p>点击右上方的弹窗拦截</p>
<p><img src="/2022/03/12/%E8%A7%A3%E5%86%B3%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97/image-20220312201548894.png" alt="image-20220312201548894"></p>
<p>注：首次点击需要应该需要下载，为正常现象。</p>
<p>到此工作完成。</p>
<p>注：完成之后建议把其他杀毒软件全部卸载。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/02/21/CTR%E5%B7%A5%E4%BD%9C%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/02/21/CTR%E5%B7%A5%E4%BD%9C%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">CTR工作介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-02-21 17:42:21" itemprop="dateCreated datePublished" datetime="2022-02-21T17:42:21+08:00">2022-02-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-02-22 09:12:54" itemprop="dateModified" datetime="2022-02-22T09:12:54+08:00">2022-02-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="中文"><a href="#中文" class="headerlink" title="中文"></a>中文</h2><p>点击率（CTR）的预测在网络广告中至关重要[McMahan等人，2013[1]；Juan等人，2016[2]；Wen等人，2019[3]]，其中的任务是估计用户点击推荐广告或物品的概率。在在线广告中，广告商向出版商付费，在出版商的网站上展示他们的广告。一种流行的支付模式是每次点击成本（CPC）模式[Zhou等人，2018[4]；Zhou等人，2019[5]]，广告商只有在点击发生时才会被收费。因此，出版商的收入在很大程度上依赖于准确预测CTR的能力[Wang等人，2017[6]] 。</p>
<p>如今，各种CTR模型层出不穷，从 Linear到 TreeBased ，再到Embedding和MLP，随着深度学习网络的推进，CTR模型也得到了充分的发展。每个模型都有其优点，例如自适应因子化网络（AFN）可以从数据中自适应地学习任意等级的交叉特征，双输入感知因式分解机（DIFM）能在矢量级有效地学习输入感知因子（用于重新加权原始特征表示）。但是CTR预测的情况总是多种多样，有时我们会面临大量的用户数据需要快速处理，有时又会缺乏用户历史信息而面临冷启动的问题。没有一种CTR模型会很好地适应所有的情况。</p>
<p>基于自动机器学习的启发，我们将创建一个CTR库，里面包含着目前世界上表现优异的各种CTR模型。主要根据预测时所面临的情况，根据传入的参数，来自适应地判断并且选择适当的CTR模型进行预测，以此来提高预测精度，缩短预测时间，最大化企业效率。</p>
<p>[1] [McMahan et al., 2013] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al. Ad click prediction: a view from the trenches. In <em>Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, pages 1222–1230. ACM, 2013.</p>
<p>[2] [Juan et al., 2016] Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. Field-aware factorization machines for ctr prediction. In <em>Proceedings of the 10th ACM Conference on Recommender Systems</em>, pages 43–50. ACM, 2016.</p>
<p>[3] [Wen et al., 2019] Hong Wen, Jing Zhang, Quan Lin, Keping Yang, and Pipei Huang. Multi-level deep cascade trees for conversion rate prediction in recommendation system. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 33, pages 338–345, 2019</p>
<p>[4] [Zhou et al., 2018] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. Deep interest network for click-through rate prediction. In <em>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, pages 1059–1068. ACM, 2018.</p>
<p>[5] [Zhou et al., 2019] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. Deep interest evolution network for click-through rate prediction. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 33, pages 5941–5948, 201</p>
<p>[6] [Wang et al., 2017] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. Deep &amp; cross network for ad click predictions. In <em>Proceedings of the ADKDD’17</em>, page 12. ACM, 2017.</p>
<h2 id="英文"><a href="#英文" class="headerlink" title="英文"></a>英文</h2><p>The prediction of click-through rate (CTR) is crucial in online advertising [McMahan et al., 2013[1]; Juan et al., 2016[2]; Wen et al., 2019[3]], where the mission is to estimate the probability that users click on a recommended ad or item. In online advertising, advertisers pay publishers to display their ads on publishers’ sites. One popular payment model is the cost-per-click (CPC) model [Zhou et al., 2018[4]; Zhou et al., 2019[5]], where advertisers are charged only when a click occurs. As a consequence, a publisher’s revenue relies heavily on the ability to predict CTR accurately [Wang et al., 2017[6]].</p>
<p>Nowadays, various CTR models have emerged, from Linear to TreeBased , to Embedding and MLP. With the advancement of deep learning networks, the CTR model has also been fully developed. Each model has its merits. For Instance, Adaptive Factorization Network (AFN) can adaptively learn cross features of any level from data, and Dual Input Perceptual Factorization Machine (DIFM) can effectively learn input perception factors at vector level (used to reweight original feature representations). Nevertheless, there are always various situations for CTR prediction. We are faced with a large amount of user data that needs to be processed quickly at times, and a cold boot due to the lack of user history information at others.  There is no CTR model that fits well in all situations.</p>
<p>Inspired by automated machine learning, we will create a CTR library containing a variety of CTR models that are currently performing well in the world. Based on the incoming parameters, we will self-adaptively determine and select the appropriate CTR model for forecasting according to the situation, in order to improve forecasting accuracy, shorten forecasting time, and maximize business efficiency.</p>
<p>[1] [McMahan et al., 2013] H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al. Ad click prediction: a view from the trenches. In <em>Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, pages 1222–1230. ACM, 2013.</p>
<p>[2] [Juan et al., 2016] Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. Field-aware factorization machines for ctr prediction. In <em>Proceedings of the 10th ACM Conference on Recommender Systems</em>, pages 43–50. ACM, 2016.</p>
<p>[3] [Wen et al., 2019] Hong Wen, Jing Zhang, Quan Lin, Keping Yang, and Pipei Huang. Multi-level deep cascade trees for conversion rate prediction in recommendation system. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 33, pages 338–345, 2019</p>
<p>[4] [Zhou et al., 2018] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. Deep interest network for click-through rate prediction. In <em>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, pages 1059–1068. ACM, 2018.</p>
<p>[5] [Zhou et al., 2019] Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. Deep interest evolution network for click-through rate prediction. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 33, pages 5941–5948, 201</p>
<p>[6] [Wang et al., 2017] Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. Deep &amp; cross network for ad click predictions. In <em>Proceedings of the ADKDD’17</em>, page 12. ACM, 2017.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/24/CTR%E4%BC%98%E5%8A%A3%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/24/CTR%E4%BC%98%E5%8A%A3%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">CTR优劣总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-24 18:26:09" itemprop="dateCreated datePublished" datetime="2022-01-24T18:26:09+08:00">2022-01-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-26 17:27:32" itemprop="dateModified" datetime="2022-01-26T17:27:32+08:00">2022-01-26</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="CTR各模型优劣总结"><a href="#CTR各模型优劣总结" class="headerlink" title="CTR各模型优劣总结"></a>CTR各模型优劣总结</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文是依照上一篇文章的顺序来进行整理，现附上上一篇链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://perfect-player.github.io/2021/09/27/CTR/</span><br></pre></td></tr></table></figure>
<p>本文参考原论文（主）与网络资料（次）编写而成。</p>
<h3 id="Convolutional-Click-Prediction-Model-卷积点击预测模型CCPM"><a href="#Convolutional-Click-Prediction-Model-卷积点击预测模型CCPM" class="headerlink" title="Convolutional Click Prediction Model(卷积点击预测模型CCPM)"></a>Convolutional Click Prediction Model(卷积点击预测模型CCPM)</h3><p>由于循环神经网络在连续广告印象上的不可改变的传播方式，在有效建模动态点击预测方面有局限性，而深度CNN架构的池化和卷积层可以从连续的广告印象中充分提取局部-全局的关键特征。</p>
<p>CCPM就是基于CNN的一个架构，CCPM可以从具有不同元素的输入实例中提取局部-全局关键特征，这不仅可以针对单个广告印象，也可以针对连续的广告印象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">CCPM can extract local-global key features from an input instance with varied elements, which can be implemented for not only single ad impression but also sequential ad impression.</span><br></pre></td></tr></table></figure>
<h3 id="Factorization-supported-Neural-Network-因子分解支持的神经网络FNN"><a href="#Factorization-supported-Neural-Network-因子分解支持的神经网络FNN" class="headerlink" title="Factorization-supported Neural Network(因子分解支持的神经网络FNN)"></a>Factorization-supported Neural Network(因子分解支持的神经网络FNN)</h3><p>出发点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.之前运用的CTR模型大多是线性的，都是基于大量的稀疏特征的编码。性能相对较低，因为在学习非微观模式时，无法捕捉到假定的（有条件的）独立原始特征之间的相互作用。</span><br><span class="line">2.当时的非线性模型不能利用所有可能的不同特征的组合。</span><br><span class="line">3.大多数预测模型有浅层的结构，对复杂的海量数据的基础模型表达有限，数据建模和泛化能力仍然受到限制。</span><br></pre></td></tr></table></figure>
<p>基于上述出发点引入了深度学习模型。</p>
<p>带有监督学习嵌入层的FNN使用因子化机器被提出来，以有效地减少从稀疏特征到密集的连续特征。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">Specifically,FNN with a supervised-learning embedding layer using factorisation machines is proposed to efficiently reduce the dimension from sparse features to dense continuous features. </span><br></pre></td></tr></table></figure>
<h3 id="Product-based-Neural-Network-PNN"><a href="#Product-based-Neural-Network-PNN" class="headerlink" title="Product-based Neural Network(PNN)"></a>Product-based Neural Network(PNN)</h3><p>背景</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">深度神经网络（DNNs）在分类和回归任务中显示了巨大的能力，在用户反应预测中采用DNNs是很有前途的。之前为了改善多领域分类数据的交互，提出的一种基于因子预训练的方法，基于串联的嵌入向量，构建多层感知器（MLPs）来探索特征的相互作用。嵌入初始化的质量在很大程度上受到因式分解机的限制。</span><br></pre></td></tr></table></figure>
<p>为了利用神经网络的学习能力和挖掘以一种比MLPs更有效的方式挖掘数据的潜在模式，所以提出PNN。PNN有望在多领域的分类数据上学习高阶潜在模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">To utilize the learning ability of neural networks and mine the latent patterns of data in a more effective way than MLPs,in this paper we propose Product-based Neural Network。</span><br><span class="line">PNN is promising to learn high-order latent patterns on multi-field categorical data. </span><br></pre></td></tr></table></figure>
<h3 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide &amp; Deep"></a>Wide &amp; Deep</h3><p>谷歌曾经的主流推荐模型，业界影响巨大。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">记忆能力：可以被理解为模型直接学习并利用历史数据中物品和特征的“共现频率”的能力</span><br></pre></td></tr></table></figure>
<p>提出动机</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">利用手工构造的交叉组合特征来使线性模型具有记忆性会得到一个不错的效果，但特征工程需要耗费大量精力，对于未曾出现过的特征组合，权重系数为0，无法进行泛化。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">线性模型，记忆力较强，但泛化能力弱</span><br><span class="line">embedding模型，记忆能力弱，泛化能力强</span><br></pre></td></tr></table></figure>
<p>基于优势互补，提出Wide &amp; Deep，左边Wide部分是一个简单的线性模型，右边Deep部分是一个经典的DNN模型。</p>
<p>WDL的深层部分将稀疏的特征嵌入连接起来作为MLP的输入，宽层部分使用手工制作的特征作为输入。深度部分和宽度部分的对数相加，得到预测概率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">WDL’s deep part concatenates sparse feature embeddings as the input of MLP,the wide part use handcrafted feature as input. The logits of deep part and wide part are added to get the prediction probability.</span><br></pre></td></tr></table></figure>
<h3 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h3><p>整合了FM和深度神经网络（DNN）的架构。它像FM一样对低阶特征的交互进行建模，像DNN一样对高阶特征的交互进行建模。不同于</p>
<p>Wide &amp; Deep，DeepFM可以在没有任何特征工程的情况下进行端到端训练。但复杂性较大。</p>
<p>优点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.它不需要任何预训练</span><br><span class="line">2.它同时学习高阶和低阶特征的相互作用；</span><br><span class="line">3.它引入了特征嵌入的共享策略以避免特征工程</span><br></pre></td></tr></table></figure>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1) it does not need any pre-training; </span><br><span class="line">2) it learns both high- and loworder feature interactions; </span><br><span class="line">3) it introduces a sharing strategy of feature embedding to avoid feature engineering</span><br></pre></td></tr></table></figure>
<p>DeepFM可以看作是WDL和FNN的改进。与WDL相比，DeepFM在广义部分使用FM而不是LR，在深义部分使用嵌入向量的连接作为MLP的输入。与FNN相比，FM的嵌入向量和MLP的输入是相同的。而且它们不需要FM预训练向量来初始化，它们是端对端学习。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">DeepFM can be seen as an improvement of WDL and FNN.Compared with WDL,DeepFM use FM instead of LR in the wide part and use concatenation of embedding vectors as the input of MLP in the deep part. Compared with FNN,the embedding vector of FM and input to MLP are same. And they do not need a FM pretrained vector to initialiaze,they are learned end2end.</span><br></pre></td></tr></table></figure>
<h3 id="Piece-wise-Linear-Model"><a href="#Piece-wise-Linear-Model" class="headerlink" title="Piece-wise Linear Model"></a>Piece-wise Linear Model</h3><p>背景</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CTR预测问题是一个高度非线性的问题。LR很难抓住非线性因素，基于树的方法不适合非常稀疏和高维的数据，FM不能适应数据中所有的一般非线性模式</span><br></pre></td></tr></table></figure>
<p>提出了一个用于大规模数据的片状线性模型及其训练算法LS-PLM,遵循分而治之的策略。首先将特征空间划分为几个局部区域，然后在每个区域内拟合一个线性模型。结果是输出加权线性预测的组合。它可以从稀疏数据中捕捉到稀疏数据中的非线性模式，并将我们从繁重的特征工程工作中解救出来，这对于实际的工业应用是至关重要的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">优势</span><br><span class="line">LS-PLM的优势在于在三个方面对网络规模的数据挖掘具有优势。</span><br><span class="line">非线性。有了足够的划分区域，LS-PLM可以适应任何复杂的非线性函数。</span><br><span class="line">可扩展性。与LR模型类似，LS-PLM可以扩展到大量样本和高维特征。</span><br><span class="line">稀疏性。</span><br><span class="line">工业模型，可以处理具有1000万个参数的10亿个样本的问题，这就是典型的工业数据量。</span><br></pre></td></tr></table></figure>
<p>由于其能够捕获非线性模式的能力和对海量数据的可扩展性，LS-PLMs已经成为在线显示广告系统中主要的CTR预测榜样，自2012年以来为数亿用户提供服务，成为阿里巴巴在线展示广告系统中主要的点击率预测模型。</p>
<h3 id="Deep-amp-Cross-Network"><a href="#Deep-amp-Cross-Network" class="headerlink" title="Deep &amp; Cross Network"></a>Deep &amp; Cross Network</h3><p>applies feature crossing in an automatic fashion.</p>
<p>以自动的方式进行特征交叉，可以处理大量的稀疏和密集的特征集，并与传统的深层网络共同学习程度有限的显性交叉特征。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">can handle a large set of sparse and dense features, and learns explicit cross features</span><br><span class="line">of bounded degree jointly with traditional deep representations.</span><br></pre></td></tr></table></figure>
<h3 id="Attentional-Factorization-Machine-AFM"><a href="#Attentional-Factorization-Machine-AFM" class="headerlink" title="Attentional Factorization Machine(AFM)"></a>Attentional Factorization Machine(AFM)</h3><p>AFM是FM的一个变种，传统的FM是将嵌入向量的内积均匀地加起来。AFM可以被看作是特征相互作用的加权和。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">AFM is a variant of FM,tradional FM sums the inner product of embedding vector uniformly. AFM can be seen as weighted sum of feature interactions.The weight is learned by a small MLP.</span><br></pre></td></tr></table></figure>
<p>AFM弥补了FM对于不同的特征交互不能赋予不同权重的问题。</p>
<h3 id="Neural-Factorization-Machine"><a href="#Neural-Factorization-Machine" class="headerlink" title="Neural Factorization Machine"></a>Neural Factorization Machine</h3><p>NFM使用一个双交互池层来学习嵌入向量之间的特征交互，并将结果压缩成一个单一的向量，其大小与单一嵌入向量相同。MLP的输出对数和线性部分的输出对数相加，得到预测概率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">原文表述</span><br><span class="line">NFM use a bi-interaction pooling layer to learn feature interaction between embedding vectors and compress the result into a singe vector which has the same size as a single embedding vector. And then fed it into a MLP.The output logit of MLP and the output logit of linear part are added to get the prediction probability.</span><br></pre></td></tr></table></figure>
<p>FM的性能可能受到其线性的限制，以及仅对成对（即二阶）特征的相互作用进行建模。特别是，对于具有复杂和非线性基础结构的真实世界数据，FM可能无法表达。</p>
<p>NFMs:一个用于稀疏数据预测的新模型,将线性分解机的有效性与非线性神经网络的强大表示能力结合起来，用于稀疏预测分析。通过对高阶和非线性特征的相互作用的建模，增强了FMs的功能。NFM结构的关键是新提出的双交互操作。</p>
<h3 id="xDeepFM"><a href="#xDeepFM" class="headerlink" title="xDeepFM"></a>xDeepFM</h3><p>xDeepFM可以自动学习显性和隐性的高阶特征交互，这对于减少人工特征工程的工作具有重要意义。它是将一个CIN和一个DNN纳入一个端到端的框架中所产生的。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Thus xDeepFM can automatically learn high-order feature interactions in both explicit and implicit fashions, which is of great significance to reducing manual feature engineering work.</span><br></pre></td></tr></table></figure>
<p>xDeepFM使用压缩交互网络（CIN）来显式学习低阶和高阶特征交互，并使用MLP来隐式学习特征交互。在CIN的每一层，首先计算$x^k$和$x<em>0$之间的外积，得到一个张量$Z</em>{k+1}$，然后使用1DConv来学习这个张量上的特征图$H_{k+1}$。最后，对所有的特征图$H_k$应用总和池，得到一个向量。该向量用于计算CIN的贡献对数。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xDeepFM use a Compressed Interaction Network (CIN) to learn both low and high order feature interaction explicitly,and use a MLP to learn feature interaction implicitly. In each layer of CIN,first compute outer products between $x^k$ and $x_0$ to get a tensor $Z_&#123;k+1&#125;$,then use a 1DConv to learn feature maps $H_&#123;k+1&#125;$ on this tensor. Finally,apply sum pooling on all the feature maps $H_k$ to get one vector.The vector is used to compute the logit that CIN contributes.</span><br></pre></td></tr></table></figure>
<h3 id="Deep-Interest-Network"><a href="#Deep-Interest-Network" class="headerlink" title="Deep Interest Network"></a>Deep Interest Network</h3><p>出发点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在传统的深度CTR模型中，使用固定长度的表示法是捕捉用户兴趣多样性的一个瓶颈。用户的各种兴趣被压缩到一个固定长度的向量中，这限制了嵌入和MLP方法的表达能力。</span><br></pre></td></tr></table></figure>
<p>深度兴趣网络（DIN），它通过考虑到候选广告的历史行为的相关性，自适应地计算用户兴趣的表示向量。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Deep Interest Network (DIN), which adaptively calculates the representation vector of user interests by taking into consideration the relevance of historical behaviors given a candidate ad. </span><br></pre></td></tr></table></figure>
<p>DIN引入了一种注意力方法来学习序列（多值）特征。传统的方法通常在序列特征上使用和/均值池。DIN使用一个局部激活单元来获得候选项目和历史项目之间的激活分数。用户的兴趣由用户行为的加权和表示，用户的兴趣向量和其他嵌入向量被连接起来，并输入MLP得到预测。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DIN introduce a attention method to learn from sequence(multi-valued) feature. Tradional method usually use sum/mean pooling on sequence feature. DIN use a local activation unit to get the activation score between candidate item and history items. User’s interest are represented by weighted sum of user behaviors. user’s interest vector and other embedding vectors are concatenated and fed into a MLP to get the prediction.</span><br></pre></td></tr></table></figure>
<h3 id="Deep-Interest-Evolution-Network"><a href="#Deep-Interest-Evolution-Network" class="headerlink" title="Deep Interest Evolution Network"></a>Deep Interest Evolution Network</h3><p>出发点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.包括DIN在内的大多数兴趣模型都将行为直接视为兴趣，而潜在的兴趣则很难通过显性行为完全反映出来。</span><br><span class="line">2.用户的兴趣是不断变化的，捕捉兴趣的动态对于兴趣的表达是非常重要的。</span><br></pre></td></tr></table></figure>
<p>深度兴趣进化网络（DIEN）使用兴趣提取器层，从历史行为序列中捕捉时间性兴趣。在这一层，提出了一个辅助损失来监督每一步的兴趣提取。由于用户的兴趣是多样化的，特别是在电子商务系统中，兴趣演化层被提出来捕捉与目标项目有关的兴趣演化过程。在兴趣演化层，注意力机制被新颖地嵌入到顺序结构中，并且在兴趣演化过程中加强了相对兴趣的影响。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Deep Interest Evolution Network (DIEN) uses interest extractor layer to capture temporal interests from history behavior sequence. At this layer, an auxiliary loss is proposed to supervise interest extracting at each step. As user interests are diverse, especially in the e-commerce system, interest evolving layer is proposed to capture interest evolving process that is relative to the target item. At interest evolving layer, attention mechanism is embedded into the sequential structure novelly, and the effects of relative interests are strengthened during interest evolution.</span><br></pre></td></tr></table></figure>
<p>关于DIEN详情可参照本人的另一篇博客</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://perfect-player.github.io/2022/01/09/DIEN/</span><br></pre></td></tr></table></figure>
<h3 id="AutoInt"><a href="#AutoInt" class="headerlink" title="AutoInt"></a>AutoInt</h3><p>该模型能够以明确的方式自动学习高阶特征的相互作用。方法的关键的关键是新引入的交互层，它允许每个特征与其他特征交互，并通过学习来确定相关性。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The key to our method is the newly-introduced interacting layer, which allows each feature to interact with the others and to determine the relevance through learning.</span><br></pre></td></tr></table></figure>
<p>AutoInt使用交互层来模拟不同特征之间的相互作用。在每个交互层中，每个特征都被允许与其他所有的特征进行交互，并且能够自动识别相关的特征，通过多头关注机制形成有意义的高阶特征。通过堆叠多个交互层，AutoInt能够对不同等级的特征交互进行建模。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AutoInt use a interacting layer to model the interactions between different features. Within each interacting layer, each feature is allowed to interact with all the other features and is able to automatically identify relevant features to form meaningful higher-order features via the multi-head attention mechanism. By stacking multiple interacting layers,AutoInt is able to model different orders of feature interactions.</span><br></pre></td></tr></table></figure>
<h3 id="ONN"><a href="#ONN" class="headerlink" title="ONN"></a>ONN</h3><p>出发点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">很少有工作专注于改进由嵌入层学习的特征表示</span><br></pre></td></tr></table></figure>
<p>与传统的特征嵌入方法相比，操作感知嵌入方法为所有操作学习一种表征。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Compared with the traditional feature embedding method which learns one representation for all operations, operation-aware embedding can learn various representations for different operations.</span><br></pre></td></tr></table></figure>
<p>ONN对二阶特征交互进行建模，就像FFM一样，并尽可能地保留二阶交互信息。此外，深度神经网络被用来学习高阶特征交互。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ONN models second order feature interactions like like FFM and preserves second-order interaction information as much as possible.Further more,deep neural network is used to learn higher-ordered feature interactions.</span><br></pre></td></tr></table></figure>
<h3 id="FiBiNET-Feature-Importance-and-Bilinear-feature-Interaction-NETwork"><a href="#FiBiNET-Feature-Importance-and-Bilinear-feature-Interaction-NETwork" class="headerlink" title="FiBiNET(Feature Importance and Bilinear feature Interaction NETwork)"></a>FiBiNET(Feature Importance and Bilinear feature Interaction NETwork)</h3><p>提出了特征重要性和双线性特征交互网络，以动态学习特征重要性和细粒度的特征交互。一方面，FiBiNET可以通过Squeeze-Excitation网络（SENET）机制动态地学习特征的重要性；另一方面，它能够通过双线性函数有效地学习特征的相互作用。</p>
<p>原文表述</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Feature Importance and Bilinear feature Interaction NETwork is proposed to dynamically learn the feature importance and fine-grained feature interactions. On the one hand, the FiBiNET can dynamically learn the importance of fea- tures via the Squeeze-Excitation network (SENET) mechanism; on the other hand, it is able to effectively learn the feature interactions via bilinear function.</span><br></pre></td></tr></table></figure>
<p>目的</p>
<p>于动态学习特征重要性和细粒度的特征相互作用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proposed to dynamically learn the feature importance and finegrained feature interactions. </span><br></pre></td></tr></table></figure>
<p>优势</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.对于CTR任务。SENET模块可以动态地学习特征的重要性。它提高了重要特征的权重，抑制了不重要特征的权重。</span><br><span class="line">2.引入了三种类型的双线性交互层来学习特征的交互作用，而不是通过计算特征的交互作用。</span><br><span class="line">3.在浅层模型中，将SENET机制与双线性特征交互结合起来，优于其他浅层、</span><br><span class="line">4.将经典的深度神经网络（DNN）组件与浅层模型相结合，成为一个深度模型。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> 1) For CTR task,the SENET module can learn the importance of features dynamically. It boosts the weight of the important feature and suppresses the weight of unimportant features. </span><br><span class="line"> 2) We introduce three types of Bilinear-Interaction layers to learn feature interaction rather</span><br><span class="line">than calculating the feature interactions with Hadamard product or inner product.</span><br><span class="line">3) Combining the SENET mechanism with bilinear feature interaction in our shallow model outperforms other shallow models such as FM and FFM.</span><br><span class="line">4) In order to improve performance further, we combine a classical deep neural network(DNN) component with the shallow model to be a deep model. The deep FiBiNET consistently outperforms the other state-of-the-art deep models such as DeepFM and XdeepFM.</span><br></pre></td></tr></table></figure>
<h3 id="IFM"><a href="#IFM" class="headerlink" title="IFM"></a>IFM</h3><p>输入感知因子机（IFM）通过神经网络为不同实例中的同一特征学习一个独特的输入感知因子。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Input-aware Factorization Machine (IFM) learns a unique input-aware factor for the same feature in different instances via a neural network.</span><br></pre></td></tr></table></figure>
<p>适用于稀疏的数据集。它的目的是通过有目的地学习更灵活、更准确的特征，来增强传统的FM。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">It aims to enhance traditional FMs by purposefully learning more flexible and accurate representation of features for different instances with the help of a factor estimating network. </span><br></pre></td></tr></table></figure>
<p>IFM的两个主要优势</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.与现有的技术相比，它能产生更好的预测结果</span><br><span class="line">2.它能更深入地了解每个特征在预测任务中的作用。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">i). it produces better prediction results compared to existing techniques</span><br><span class="line">ii). it provides deeper insights into the role that each feature plays in the prediction task.</span><br></pre></td></tr></table></figure>
<h3 id="DCN-V2"><a href="#DCN-V2" class="headerlink" title="DCN V2"></a>DCN V2</h3><p>以一种富有表现力而又简单的方式为显式交叉建模，观察到交叉网络中权重矩阵的低秩性质。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Observing the low-rank nature of the weight matrix in the cross network</span><br></pre></td></tr></table></figure>
<h3 id="DIFM"><a href="#DIFM" class="headerlink" title="DIFM"></a>DIFM</h3><p>双输入感知因式分解机（DIFM）可以同时在比特级和矢量级对原始特征表示进行自适应的重新加权。此外，DIFM战略性地将包括多头自适应、残差网络和DNN在内的各种组件整合到一个统一的端到端模型中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Dual Inputaware Factorization Machines (DIFM) can adaptively reweight the original feature representations at the bit-wise and vector-wise levels simultaneously.Furthermore, DIFMs strategically integrate various components including Multi-Head Self-Attention, Residual Networks and DNNs into a unified end-to-end model.</span><br></pre></td></tr></table></figure>
<p>目的是根据不同的输入实例，借助DIFMs，自适应地学习一个给定特征的灵活表示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">It aims to adaptively learn flexible representations of a given feature according to different input instances with the help of the Dual-Factor Estimating Network (Dual-FEN).</span><br></pre></td></tr></table></figure>
<p>主要优点是它不仅能在比特级，而且能在矢量级同时有效地学习输入感知因子（用于重新加权原始特征表示）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The major advantage of DIFM is that it can effectively learn the inputaware factors (used to reweight the original feature representations) not only at the bit-wise level but also at the vectorwise level imultaneously.</span><br></pre></td></tr></table></figure>
<h3 id="AFN"><a href="#AFN" class="headerlink" title="AFN"></a>AFN</h3><p>自适应因子化网络（AFN）可以从数据中自适应地学习任意等级的交叉特征。AFN的核心是一个对数转换层，将特征组合中每个特征的功率转换成要学习的系数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Adaptive Factorization Network (AFN) can learn arbitrary-order cross features adaptively from data. The core of AFN is a logarith- mic transformation layer to convert the power of each feature in a feature combination into the coefficient to be learned.</span><br></pre></td></tr></table></figure>
<p>AFN能够从数据中自适应地学习任意顺序的特征互动。而不是在一个固定的最大顺序内对所有的交叉特征进行明确的建模。<br>AFN能够自动生成辨别性的交叉特征和相应特征的权重。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learns arbitrary-order feature interactions adaptively from data. Instead of explicitly modeling all the cross features within a fixed maximum order,AFN is able to generate discriminative cross features and</span><br><span class="line">the weights of the corresponding features automatically.</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/09/DIEN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/09/DIEN/" class="post-title-link" itemprop="url">DIEN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-09 20:04:42" itemprop="dateCreated datePublished" datetime="2022-01-09T20:04:42+08:00">2022-01-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-11 09:53:17" itemprop="dateModified" datetime="2022-01-11T09:53:17+08:00">2022-01-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Deep-Interest-Evolution-Network-for-Click-Through-Rate-Prediction"><a href="#Deep-Interest-Evolution-Network-for-Click-Through-Rate-Prediction" class="headerlink" title="Deep Interest Evolution Network for Click-Through Rate Prediction"></a>Deep Interest Evolution Network for Click-Through Rate Prediction</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>阿里CTR预估模型—-DIEN（深度兴趣演化网络）</p>
<p>这是一篇一篇阿里2019发表在AAAI上的CTR预估的论文，本文亮点主要是作者提出了兴趣提取层与兴趣演化层两个网络层。</p>
<p>附一个原文链接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://arxiv.org/abs/1809.03672v1</span><br></pre></td></tr></table></figure>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p><strong>每点击付费(CPC)</strong> 是广告系统中最常见的计费形式之一，广告商对广告的每次点击进行收费。在CPC广告系统中，点击率(CTR)预测的效果不仅影响整个平台的最终收益，还会影响用户体验和满意度。</p>
<p>在大多数<strong>非搜索</strong>的电子商务场景中，用户不主动表达自己当前的意愿。因此设计能够捕捉用户动态兴趣的模型是提高CTR预测性能的关键。</p>
<h3 id="研究状态"><a href="#研究状态" class="headerlink" title="研究状态"></a>研究状态</h3><p>注，本文的研究状态为到2019年以前。</p>
<p>a.由于深度学习在特征表示上的强学习能力，目前大部分CTR模型从传统的线性或非线性模型（例如FM）转换到深度模型。</p>
<p>b.大多数深度模型遵循Embedding+多层感知器(MLP)的结构， 但这些模型只关注从不同的领域捕获特征之间的交互，【没有考虑到用户兴趣的表示】。</p>
<p>c.DIN引入了一个attention机制来激活具有意义的历史行为。但</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DIN很难捕捉潜在的用户兴趣；</span><br><span class="line">用户兴趣是不断发展，DIN在捕获用户序列的行为之间的依赖有所欠缺。</span><br></pre></td></tr></table></figure>
<p>d.大多数基于RNN的模型都【连续且均等地处理相邻行为之间的所有依赖关系】。但并非所有用户的行为都严格取决于每个相邻的行为。 每个用户都有不同的兴趣，并且每个兴趣都有其自己的发展轨迹，例如书籍和衣服的发展过程几乎是各自独立的。 对于目标物品，这些模型只能获得一个固定的兴趣演化轨迹，可能会受到兴趣漂移的干扰。【简而言之，就是缺少Attention机制】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">兴趣漂移：兴趣漂移对行为的影响是用户可能在一段时间内对各种书籍产生兴趣，在另一段时间内又需要衣服。</span><br></pre></td></tr></table></figure>
<h3 id="创新"><a href="#创新" class="headerlink" title="创新"></a>创新</h3><p>a.兴趣提取器层（interest extractor layer）：首先DIEN选择GRU来建模两行为之间的依赖性。其次由于隐藏状态缺乏对兴趣表示的监督，作者提出了<strong>辅助损失</strong>，即<strong>使用下一个行为来监督当前隐藏状态的学习</strong>。作者把这些有额外监督的隐藏状态称为【兴趣状态】，有助于捕获更多的语义意义用于兴趣表示，推动GRU的隐藏状态，从而有效地表示兴趣。</p>
<p>b.兴趣演化层（interest evolving layer）：兴趣的多样性会导致兴趣偏移的现象。在相邻的访问中，用户的意图可能非常不同，用户的一个行为可能依赖于很久以前的行为。因此，作者提出<strong>建立与目标物相关的兴趣演化轨迹模型</strong>，设计了带有注意力机制更新门的GRU—-AUGRU。<strong>运用兴趣状态和目标物体去计算相关性</strong>。AUGRU增强了在兴趣演化中相关兴趣的影响，同时削弱了兴趣漂移所产生的非相关兴趣效应。通过在更新门中引入注意机制，AUGRU可以实现针对不同目标物体的特定兴趣演化过程。</p>
<h3 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h3><p>a.提出一个新的网络结构来对兴趣演化过程进行建模。兴趣表示更具有表达性，CTR预估更精确。</p>
<p>b.设计了一个兴趣提取层。指出GRU对兴趣表示的针对性弱，故提出辅助损失。</p>
<p>c.设计了一个兴趣演化层，AUGRU增强了相关兴趣对目标物体的影响。</p>
<h3 id="具体细节"><a href="#具体细节" class="headerlink" title="具体细节"></a>具体细节</h3><h4 id="DIN与DIEN的总体思路"><a href="#DIN与DIEN的总体思路" class="headerlink" title="DIN与DIEN的总体思路"></a>DIN与DIEN的总体思路</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在MLP的基础上，引入先验知识，加速模型训练，提高模型准确性。</span><br></pre></td></tr></table></figure>
<p><img src="/2022/01/09/DIEN/image-20220110103347882.png" alt="image-20220110103347882" style="zoom: 25%;">到<img src="/2022/01/09/DIEN/image-20220110103434044.png" alt="image-20220110103434044" style="zoom:25%;"></p>
<p>兴趣</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">兴趣是用来表达行为，行为则是挖掘兴趣。</span><br><span class="line">对兴趣建模的任务就是从用户的历史行为中，挖掘出用户的兴趣，将兴趣</span><br><span class="line">这个抽象的概念量化表达。</span><br><span class="line">因此训练数据中，需要引入用户的历史点击行为。</span><br></pre></td></tr></table></figure>
<p>DIN与DIEN的区别就是兴趣的建模方式不同。</p>
<h4 id="DIN兴趣建模思路与缺点"><a href="#DIN兴趣建模思路与缺点" class="headerlink" title="DIN兴趣建模思路与缺点"></a>DIN兴趣建模思路与缺点</h4><p><img src="/2022/01/09/DIEN/image-20220110104128810.png" alt="image-20220110104128810" style="zoom:50%;"></p>
<p>在DIN中，直接将每个历史行为等价于用户兴趣(方框处)。然后通过注意力机制，模拟处候选广告与每个历史点击之间的相关性，从而判断用户对候选广告感兴趣的程度。</p>
<p>缺点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">对兴趣的表达，不能完全贴合实际情况。</span><br><span class="line">a.直接吧行为等价成兴趣</span><br><span class="line">b.很难通过已表现出来的行为，来反映出用户的潜在兴趣</span><br><span class="line">c.之前的方法，忽略了去挖掘潜藏在用户行为背后的兴趣</span><br><span class="line">eg:假设你当下点击了鞋子，则DIN认为你是对于鞋子感兴趣的，但是你背后的兴趣可能是多样的，例如还可能对衣服感兴趣。</span><br><span class="line">DIN忽略了序列信息，容易基于用户所有购买历史行为综合推荐，而不是针对下一次购买推荐。</span><br></pre></td></tr></table></figure>
<p>兴趣的实际情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a.人的兴趣是多样的，在同一个时刻，拥有多种不同的兴趣应该用兴趣状态来描述。但是DIN只能捕捉到用户的一个兴趣。</span><br><span class="line">b.兴趣是动态变换，都有属于自己的演化过程。但是DIN没有动态演化过程，例如你买完鞋子以后你可能对鞋子不感兴趣了，但是DIN还是会认为你对鞋子感兴趣。</span><br><span class="line">c.兴趣的发展是有前后关联的</span><br><span class="line">d.兴趣会存在兴趣漂移</span><br></pre></td></tr></table></figure>
<h4 id="DIEN对兴趣的建模思路"><a href="#DIEN对兴趣的建模思路" class="headerlink" title="DIEN对兴趣的建模思路"></a>DIEN对兴趣的建模思路</h4><p>循环神经网络满足上述兴趣的特点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.使用循环神经网络，从用户的序列行为信息中，提取出用户的兴趣状态</span><br><span class="line">b.每个时刻下的兴趣状态用一个向量来表征，这个向量相当于一个黑盒，当中包含了丰富的语义信息，例如用户当前有哪些兴趣、对各个兴趣的强烈程度。</span><br><span class="line">c.利用循环神经网络的串联结构，以及记忆特性，找到用户兴趣演化的规律。</span><br></pre></td></tr></table></figure>
<p>步骤</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a.从用户历史行为中提取出每个时刻的兴趣状态</span><br><span class="line">b.利用注意力机制，找到与候选广告相关的那部分兴趣的演化过程，判断用户下一时刻对该兴趣的感兴趣程度</span><br></pre></td></tr></table></figure>
<h4 id="DIEN详解"><a href="#DIEN详解" class="headerlink" title="DIEN详解"></a>DIEN详解</h4><p><img src="/2022/01/09/DIEN/image-20220110115254821.png" alt="image-20220110115254821"></p>
<p>核心为历史行为处理部分，往右依次是目标广告，上下文特征，用户行为特征。</p>
<p>核心部分分为三层，从下到上为行为序列层，兴趣抽取层，兴趣进化层</p>
<h5 id="兴趣抽取层"><a href="#兴趣抽取层" class="headerlink" title="兴趣抽取层"></a>兴趣抽取层</h5><p>作用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">挖缺并提取出每个时刻下，用户行为背后潜藏的兴趣状态。</span><br></pre></td></tr></table></figure>
<p>采用的序列模型为GRU，具有记忆特性，可以缓解梯度消失，训练参数小于LSTM。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">具体可参考：</span><br><span class="line">https://zhuanlan.zhihu.com/p/32481747</span><br></pre></td></tr></table></figure>
<p>结构：多输入，多输出</p>
<p>为更好的提取，设计了auxiliary loss</p>
<p><img src="/2022/01/09/DIEN/image-20220110120300856.png" alt="image-20220110120300856" style="zoom: 50%;"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">这里设计了一个二分类模型来计算兴趣抽取的准确性，</span><br><span class="line">我们将用户下一时刻真实的行为e(t+1)作为正例，</span><br><span class="line">负采样得到的行为作为负例e(t+1)&#x27;，</span><br><span class="line">分别于抽取出的兴趣h(t)结合输入到设计的辅助网络中，得到预测结果，并通过logloss计算一个辅助的损失</span><br></pre></td></tr></table></figure>
<p>原因</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果只采用最后的label去监督，则隐藏层所有状态都是为最后一个状态服务，则提取出的隐藏层状态显然失真。</span><br></pre></td></tr></table></figure>
<p>训练方式：引入负采样训练</p>
<h5 id="兴趣进化层"><a href="#兴趣进化层" class="headerlink" title="兴趣进化层"></a>兴趣进化层</h5><p>兴趣演化的特点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">存在兴趣漂移，每个兴趣都有自己的演化过程</span><br></pre></td></tr></table></figure>
<p>作用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">模拟出与目标广告相关的进化机制</span><br></pre></td></tr></table></figure>
<p>DIEN创新点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">把这个注意力操作嵌入到GRU的更新门里面去，形成了一个AUGRU的结构，用这个层来更有针对性的模拟与目标广告相关的兴趣进化路径</span><br></pre></td></tr></table></figure>
<p>得到过程</p>
<h6 id="AIGRU"><a href="#AIGRU" class="headerlink" title="AIGRU"></a>AIGRU</h6><p><img src="/2022/01/09/DIEN/image-20220110122005893.png" alt="image-20220110122005893"></p>
<p><img src="/2022/01/09/DIEN/image-20220110122133352.png" alt="image-20220110122133352"></p>
<p>直接拿$a_t$乘上了兴趣抽取层的隐藏兴趣状态，但会使不相干的兴趣会影响到兴趣演化层的学习</p>
<h6 id="AGRU"><a href="#AGRU" class="headerlink" title="AGRU"></a>AGRU</h6><p><img src="/2022/01/09/DIEN/image-20220110122118801.png" alt="image-20220110122118801"></p>
<p>拿$a_t$替换掉了更新门。</p>
<p>若某个时刻t的兴趣$h_t$与当前候选广告一点关系没有，即$a_t$为0，这个时候的隐藏状态会直接使用上一时刻的。</p>
<p>通过这种机制保障只关注和当前候选广告相关的兴趣演化过程。</p>
<p>问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在替换时用标量替换向量，忽视了不同维度上值的重要性</span><br></pre></td></tr></table></figure>
<h6 id="AUGRU"><a href="#AUGRU" class="headerlink" title="AUGRU"></a>AUGRU</h6><p><img src="/2022/01/09/DIEN/image-20220110122639019.png" alt="image-20220110122639019"></p>
<p>克服了AGRU忽略维度的问题。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文提出了一种新的深层网络结构，即深层兴趣演化网络(DIEN)，来模拟兴趣的演化过程。在在线广告系统中，DIEN极大地提高了CTR预测的性能。具体地说，作者设计了</p>
<ul>
<li>兴趣提取层来捕获兴趣序列，利用辅助损失来提供对兴趣状态的更多监督。</li>
<li>兴趣演化层，使用带有注意力更新门(AUGRU)的GRU来模拟与目标物品相关的兴趣演化过程。在AUGRU的帮助下，DIEN克服了兴趣漂移的干扰。兴趣演化建模有助于有效捕获兴趣，进一步提高CTR预测的性能。</li>
</ul>
<h3 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h3><p>B站，老弓的学习日记</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">操作系统</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-07 19:05:41" itemprop="dateCreated datePublished" datetime="2022-01-07T19:05:41+08:00">2022-01-07</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
